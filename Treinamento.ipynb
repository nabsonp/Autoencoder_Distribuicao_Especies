{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Lambda, Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras import regularizers\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from keras.losses import mse, binary_crossentropy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atmes = pd.read_csv(\"americanToadPadraoLimpa.csv\")\n",
    "df_atmess = pd.read_csv(\"americanToadPadraoMes.csv\")\n",
    "#df_gfmes = pd.read_csv(\"greenFrogPadraoMes.csv\")\n",
    "#df_spmes = pd.read_csv(\"springPeeperPadraoMes.csv\")\n",
    "#df_atest = pd.read_csv(\"americanToadPadraoEstacao.csv\")\n",
    "#df_gfest = pd.read_csv(\"greenFrogPadraoEstacao.csv\")\n",
    "#df_spest = pd.read_csv(\"springPeeperPadraoEstacao.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc93ad94d50>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHJRJREFUeJzt3XuQlPWd7/H3t+cioNwCYwbkMqJoIZhCQSEnlpJSkgFTQso9WXUTk1Ma1xzdOjnJSR3WuGaP0RyyrnuyKSmVRCsxJcFscsJy4uAlWQhrDCOMssql0HGEcRTk4oAXwJmhv+eP7h67e/ryzExfZp7+vKoo+unnR/fvmRk+/Zvv83t+j7k7IiISLpFyd0BERApP4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCqLpcbzxx4kRvaGgo19uLiAxLLS0th929Ll+7soV7Q0MD27ZtK9fbi4gMS2a2L0g7lWVEREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGUN9zN7FEzO2hmO7LsNzP7sZm1mtnLZnZx4bspIiL9EWTk/jOgMcf+JcDM+J9bgAcH3y0RERmMvOHu7puBd3M0WQY85jFbgHFmNqlQHRSR8mvZ18mqja207Ossd1ckoEJcoXoW8GbSdkf8uf0FeG0RKbOWfZ381U+30NUTpbY6wuM3L2Te9PHl7pbkUdITqmZ2i5ltM7Nthw4dKuVbi8gAbWk7QldPlKhDd0+ULW1Hyt0lCaAQ4f4WMDVpe0r8uT7cfbW7z3f3+XV1ede9EZEhYOGMCdRWR6gyqKmOsHDGhHJ3SQIoRFlmPXC7ma0FFgDH3F0lGZGQmDd9PI/fvJAtbUdYOGOCSjLDRN5wN7NfAouAiWbWAXwPqAFw94eAJmAp0AocB/5LsTorIuUxb/p4hfowkzfc3f36PPsduK1gPRIRkUHTFaoiIiGkcBcRCSGFu4hICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQkhhbuISAgVYlXIirKmuZ0NO/azZM4kXnjjCL/f/Q5Tx4/ini9eqIWVRGTIsNi6X6U3f/5837ZtW1nee6DWNLdzx29fybr/N9/4Twp4ESkqM2tx9/n52lVEWSb5/o+DuRfkE1vbc+5/+I+vA7CyaTeL7tvIyqbdA+qviMhghb4sk3z/x+qIgRk9pzLfC7JlX2fWGxK07Otk59vHcr7XO++dZGXTbh7a3AbQ+/eKpbMKfFQiIrmFfuSecv/HU053lntBJj4E/vHpPfzlw39mTXN7n9eJ5qlgfXrGBJ7aeSDlufRtEZFSCH24p9z/scqoyXIvyC1tR/ioO4oDPVHnznWvpAT8whkTYiP/HEaPrKFxdn3Kc+nbIiKlEPqyTPr9H4GMpZfxo2oxg8T55ajD3/3rDs6vH937bxadfybP7Hon63slv+ZTOw/QOLu+ZCWZXCUlEak8mi3DxyWZk93RPvs+d8En2bTnIN2nnEgETvVt0us7nz+/LOGafF4h07kEEQmPoLNlQj9yDyJRl8/kxTc76ToV+wBMDnYD0j8W73t6DwCXz5zIYzctKEJPM0s5rxA/l6BwF6lsoa+559Oyr5P7nt6T9WTpe8e7Mz6f6/edza8d5ptrXxp85wJKOa+Qdi5BRCpTRYd7y75Orn3w+ZxtEqP2dAY5T7D+7uX9g+lavyTOK3zrc+erJCMiQIWE+5rmdr7ySHOf6Y2/ebFjQK8XAaoi0DDx9KxteqJe0ouY5k0fz22fPVfBLiJABdTck5cM+PfXDgNwfv1otrQd4fD7H/X79caNrOaSsyfw7K53aD34AZC5/g6xi5imTTidGxZMG2j3RUQGJPThvmFHannkia3t7Hj7GKeisVDur6Mneng2bTpkrvr7hh37Fe4iUvLpyqEK90xfvCVzJvWO2AGOnejunfVSikmgS+ZMKsG7iMhQVo7pyqEJ92xfvMSoObFM7/fW7yhZn8498wwAvvJIM0vmTMo5gs/2qa6Lk0SGv3JMVw5NuOf64t2wYBo3LJjG8geeozvL7JdimDN5TJ96f6aAz/bBpIuTRMIhMV25uydasunKoQn3fF+8Nc3tbO/IvapjNlUGk8aOoOPoyaxtqiPwl5dMY/Rp1ezc/x5L5kzqU+/PVn/P9sGki5NEwiF9GRTV3Psh1xevZV8nd/3rwMsxp5ycwV5l0BOFJ19+m+3f+3zKvuR6f7b6e7YPpnJ82otIccybPr6kg7NAa8uYWSPwz0AV8FN3X5m2fxrwc2BcvM0Kd2/K9ZqlXFtm1cZW/vHpPSknUOdOGcvCGRN611wHGFlTxSUN41kwYwLvn+jmp8+9QU++dX7TjBtZnRLwybflU81dRAarYGvLmFkVsApYDHQAW81svbvvSmp2J/Ard3/QzC4AmoCGAfW8CBbOmMBpNRG6uqNEIsbdy+b0Bu20Caf3Cd81ze2968T019ETPSnbiXp/Ptk+1Uv9aS8i4RCkLHMp0OrubQBmthZYBiSHuwNj4o/HAm8XspODlatkkyl802vl1RHjC5+axN7DH+at248bGZpKl4gMY0GS6CzgzaTtDiB9ycO/B54xs78BTgeuKkjvCqg/I+D0ufHJI/2E5Q88x8tvHWNUTRWnos6Jnmifkkw6lVhEpFQKNcy8HviZu99vZp8GfmFmc9w9ZR1dM7sFuAVg2rShe9Vm+tz4TGWVdbdf1q/X1LRGESmlIOH+FjA1aXtK/LlkNwGNAO7+ZzMbAUwEDiY3cvfVwGqInVAdYJ9LImitPKjBTmsMemJWRASChftWYKaZnU0s1K8Dbkhr0w5cCfzMzGYBI4BDhezocDeYaY2ZFj9TwItILnnD3d17zOx24Gli0xwfdfedZnY3sM3d1wPfBn5iZv+d2MnVr3m57t83RGU7qZteh89Ulw96MZSISEKgmnt8znpT2nN3JT3eBXymsF0Ln/STuul1+Lu+MJu7f7ezT10+/QSvFiMTkXw0b68Acs2CybUvvQ6/Ycf+jHX5ICd4RUSSKdwHKdcsmHwzZNLr8EvmTGLr3ncz1uULfYJXRMJN4T5IuWbBJO872R3l4T++zuobP75qOFMd/vz60Tz8x9d5572T7DnwvqZLisiAKNz7IdPJz017DuLE7upUUx3hvqf3cN/TezBg2dzJJC9N88yud1jT3J4yAk+vw+858D7PxO/09B8dsRkyGrGLSH8p3APKdPLz79a9QvLy8Ce7P75my4F12/uuwvDE1vacYf393+3ss61wF5H+Urhn0bDiyd7HP/jihX1Odj6xtZ2B3PfjzDEjcu4/0R3NuS0iEoTCPYPkYAd6LyACiFis/PLJMSOA/t/849Yrzsm5f2bd6bx26MPe7XEjq1l030ZqIsahD7tYdF4dP7ruon6/r4hUlki5OzDcfObciTx+80L++opzqK3u35fvB1+8MO8J0me/vYiZdacTsViwHz3Rw94jx3nt0IccPd7Nuu1v8821Lw3mEESkAijc++mbV53XexL0l19fGPjf1Y85jfYjH+ZvSCzg2/731YwbVZtx/6ZXtbKDiOSmcM9g78qrs+679sHnOTtetpk3fTzVEQv0mgfe+4iHNrexsml34H40zq7P+Pyi8+oCv4aIVCaFexa3Xj4j6z4nVpdf2bSbkbVV/Xrdp3YeCNx2xdJZ3Hr5DBomjGJm3emMG1XD8rmTVXMXkbwC3UO1GEp5D9WBOnvFkxT6q3Pr5TNYsXRWgV9VRCpFwe6hWqlWNu3GDAb72VdbHWHpnHq2v3mUxtn1CnYRKQmFewZrmtt5aHNbQV7r1KkoMz85WqUUESkp1dwz+F//b2f+RlncevkM6secRlXEqIrPie/PjTlERApBI/cMPurJf1XorPrRdB7v4sB7H/U+l5hls2LpLN0MW0TKSuEet7JpN0/tPMDeI8cD/5sRNVVZT5CmLwgmIlJKFRvuNz7SzAt7301Z7Ks/dh94H6C3Nq8TpSIylFRkzX3x/ZvY/NrhAQd7uv7MXRcRKYWKGrmnLwhWKNM+MaoorysiMlAVM3IvVrADBb/QSURksCom3Itp9qQx5e6CiEgKhXsBjB5ZU+4uiIikqJhwz7XS42BURyzjRUqX3PMsDSue5JJ7ni3K+4qI5FJRJ1QLKQJEIsbdy+b0mc9+yT3PcuiDLgAOfdDFjBVPgsE5E0/n2W8vKn1nRaTiVEy4F+qEagT41JSxLJ5dn/Xq00SwJ0QBHF479CGL79+kgBeRogtNuN/4SDObXzvcu/2DL17IDQumAYWdKRMFtnccY3vHMerOqGXrnYuBj69wbZxdT90ZtX0CPuH1w8HuxiQiMhihWM89PdhLqe6MWq69eErKKpLL505m3fa3M7afMm4E1y+YrjVnRGRAKmI998TiXOUKdoiVYNKvUP3dy/t7H1cZjB1Zw9ET3UweO4LDH3Zx/zN7qK2O8PjNsXuwJhYYS36s4BeRwRi24d6yr5MvPfw8pwqzgsCgpC821hON/TZkxJb8/clXL2He9PGs2tjK/c/sIerQ3RPlNy928H9f7KCrJ0p1VQTc6Yl6b/Ar4EVkoAJNhTSzRjPbY2atZrYiS5svmdkuM9tpZmsK282+frhh95AI9lymTxiVEtILZ0ygtjrSu867AV090d6w7z7lvY+3tB2hZV8nqza20rKvs7wHIiLDTt6Ru5lVAauAxUAHsNXM1rv7rqQ2M4G/BT7j7p1mdmaxOpzQ/m7wpXnLZe+R4ymj73nTx/P4zQtTyjC/ebGD7p4oVfGR+6moU1Md4cGNrdz39B4ARtRoJC8i/ROkLHMp0OrubQBmthZYBuxKavN1YJW7dwK4+8FCdzRd8k0yhrKWfZ19Aj55Oz3st7Qd4SebX+foiZ7eNie7YyN5hbuIBBWkLHMW8GbSdkf8uWTnAeeZ2Z/MbIuZNRaqg5kUcxGwXGbVj07Z/s7nz8/7BdzSdiTn/nnTx3PbZ8/tDf3bPntuSrAn6FZ9ItIfhVp+oBqYCSwCrgd+Ymbj0huZ2S1mts3Mth06dKhAb106nce7GFETIWIQMXhwUyvXzJ3M3pVXM7K675eypirz0gT51J1Rm7I9bmS1Ru0i0i9ByjJvAVOTtqfEn0vWATS7ezfwhpm9SizstyY3cvfVwGqIzXMfaKcHau/Kq1nT3M6GHft549AH7D92kiixT7ia6gh3fWE2nce7GD+qlh///lUOvJ9a+pn6iVEc3NdJfDIMH3x0qnc+++57lgCwprmdJ7a288kxI/jrK84ZUChvvXNx7xIGyRdKiYgElfciJjOrBl4FriQW6luBG9x9Z1KbRuB6d/+qmU0EXgLmunvWmsRgLmJa2bQ75aKhILItHJbvRtbJV54unl3PtQ8+n/F1GiaMonF2vW63JyJFFfQipkBXqJrZUuBHQBXwqLvfa2Z3A9vcfb2ZGXA/0AicAu5197W5XnOwV6gmQvfo8a4+NeoRNZGUW+gVckXIfPX+y2dO5LGbFmRsX6yVKUWkchQ03IuhkMsPLL5/E68f/pDJY4t/aX/yio/Z3Hr5DFYsnZXxg0ABLyKDURHLDySUcpXF5Hp4Ng9tbmPx7PqS9UlEJF0owr3Ukk9wLn/gObZ3HOvTJlttXkSkFCrmTkzFsuPt9wK3LVRJZk1zO195pJk1ze0FeT0RCR+N3AdpzuQxGUfuCYWusa9pbueO374CwL/HV8NMrFsPMOvODZzoiTKyOtI7PVNEKo9G7oO07vbLmDtlbMneb8OO/Vm3E8EOcKInyqw7N5SsXyIytGjkXgDrbr+s93Gxpz4umTOpd8Se2E5IBHu2bRGpHAr3Aiv2VMdECWbDjv0smTMppSQzsjqSEuiZlkQQkcoQinnu8jHV3EXCraLmucvHFOgiAjqhKiISSgp3EZEQUriLiISQwl1EJIQU7sOAlhsQkf7SbJkhLt9yAyIimSjch5AbH2lmc9LVp5c2jGf7m0dT2mzYsV/hLiJ5KdyHiPRgB3hhb2efdsnLDYiIZKNwHyJe2Ptuzv0jamI38NaoXUSC0AnVAWrZ18mqja207Os7uh6ISxs+kXP/1z7doGAXkcA0ch+Aln2d/NVPt9DVE6W2OsLjNy8c9D1bH7tpAZet/AMdR0/2Plc/5jQAls89ixVLZw3q9UWksijcB2BL2xG6eqJEHbp7omxpO1KQG3I/t+JKVjbt5qmdB2icXa9AF5EBU7gPwMIZE6itjtDdE6WmOsLCGRMK9torls5KCfU5dz3FB12nALh85kQeu2lBwd5LRMJLS/4OUMu+Tra0HWHhjAkFGbVnkhzsCQp4kcqmJX+LbN708UUL9YT0YIf8s2pERECzZYadfLNqRERA4T6kLZ87OWW77oxalWREJBCVZYawH113EQCbXj3EovPqerdFRPJRuA9xxQr0UpwQFpHyUbgPY+d9t4muU05tlfHqvUsD/7tiXIQlIkOLau7DVCLYAbpOOef87ZOB13zPdBGWiIRLoHA3s0Yz22NmrWa2Ike7a83MzSzvHEwZnESwJ5zy2Hrvd/z2lbwBn7gIq8oo+EVYIjI05C3LmFkVsApYDHQAW81svbvvSms3GvhvQHMxOiqpaqusT8AnZFvz/cZHmnlh77tc2vAJHr95oWruIiEWZOR+KdDq7m3u3gWsBZZlaPd94IfAyQz7pMBevXcptVUGQPyvXpnWfE+sF3+yO8rm1w7zz79/lds+e66CXSSkgpxQPQt4M2m7A0iZbG1mFwNT3f1JM/tOAfsnOSSfRF3T3M6GHftZMmdSxlH7868fybktIuEy6NkyZhYB/gn4WoC2twC3AEybprXJC+mGBdNyrvd++mlVHDvRk7ItIuEVpCzzFjA1aXtK/LmE0cAcYJOZ7QUWAusznVR199XuPt/d59fV1Q2815LRmub23hkz6TcT+Z+NqcsHp2+LSLgEGblvBWaa2dnEQv064IbETnc/BkxMbJvZJuB/uPvwXfJxGFrT3M4dv30FiM2aqYqAO73z2BOj+lylGxEJj7zh7u49ZnY78DRQBTzq7jvN7G5gm7uvL3YnJb8NO/anbJ+Kxv4+2f3xzUTylW5EJDy0nntINKx4Muf+vSuvLlFPRKSYgq7nritURURCSOEeEpa/iYhUEIV7SLyx8uregE8PepVkRCqPVoUMkTcU4iISp5G7iEgIKdxFREJI4S4iEkIKdxGREFK4iwwz6esGiWSi2TIiw4jufytBaeQuMozo/rcSlMJdZBjR/W8lKJVlRIaRedPH6/63EojCXWSYmTd9vEJd8lJZRkQkhBTuIiIhpHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEUKBwN7NGM9tjZq1mtiLD/m+Z2S4ze9nM/mBm0wvfVRERCSpvuJtZFbAKWAJcAFxvZhekNXsJmO/unwJ+DfxDoTsqIiLBBRm5Xwq0unubu3cBa4FlyQ3cfaO7H49vbgGmFLabIiLSH0HC/SzgzaTtjvhz2dwEbBhMp0REZHAKeoNsM/syMB+4Isv+W4BbAKZNm1bItxYRkSRBRu5vAVOTtqfEn0thZlcB3wWucfePMr2Qu6929/nuPr+urm4g/RURkQCChPtWYKaZnW1mtcB1wPrkBmZ2EfAwsWA/WPhuiohIf+QNd3fvAW4HngZ2A79y951mdreZXRNvdh9wBvAvZrbdzNZneTkRESmBQDV3d28CmtKeuyvp8VUF7peIiAyCrlAVEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIaRwFxEJIYW7iEgIKdxFREJI4S4iEkIKdxGREFK4i4iEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCSOEuIhJCCncRkRBSuIuIhJDCXUQkhBTuIiIhpHAXEQkhhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiIRQoHA3s0Yz22NmrWa2IsP+08zsifj+ZjNrKHRH5WPLH3iOc+9oYvkDz5W7KyIyROUNdzOrAlYBS4ALgOvN7IK0ZjcBne5+LvB/gB8WuqMSs/yB59jecYyeqLO945gCXkQyCjJyvxRodfc2d+8C1gLL0tosA34ef/xr4Eozs8J1UxJ2vP1exu2VTbtZdN9GVjbtLke3RGSICRLuZwFvJm13xJ/L2Mbde4BjwIRCdFBSzZk8ps/2yqbdPLS5jb1HjvPQ5jYFvIiU9oSqmd1iZtvMbNuhQ4dK+dahse72y5g7ZSzVEWPulLGsu/0yntp5IKVN+raIVJ7qAG3eAqYmbU+JP5epTYeZVQNjgSPpL+Tuq4HVAPPnz/eBdFhiAZ+scXY9D21uS9kWkcoWJNy3AjPN7GxiIX4dcENam/XAV4E/A38B/Ju7K7xLZMXSWUBsxN44u753W0QqlwXJYDNbCvwIqAIedfd7zexuYJu7rzezEcAvgIuAd4Hr3L0t+yvGRu7btm0b9AGIiFQSM2tx9/n52gUZuePuTUBT2nN3JT0+Cfzn/nZSRESKQ1eoioiEkMJdRCSEFO4iIiGkcBcRCSGFu4hICCncRURCKNA896K8sdkhYN8gX2YicLgA3RkudLzhV2nHrOPtv+nuXpevUdnCvRDMbFuQyfxhoeMNv0o7Zh1v8agsIyISQgp3EZEQGu7hvrrcHSgxHW/4Vdox63iLZFjX3EVEJLPhPnIXEZEMhny4m1mjme0xs1YzW5Fh/2lm9kR8f7OZNZS+l4UV4Ji/ZWa7zOxlM/uDmU0vRz8LJd/xJrW71szczIb17Iogx2tmX4p/j3ea2ZpS97HQAvxMTzOzjWb2Uvznemk5+lkIZvaomR00sx1Z9puZ/Tj+tXjZzC4uSkfcfcj+IbZ+/OvADKAW+A/ggrQ2/xV4KP74OuCJcve7BMf8WWBU/PE3hvMxBzneeLvRwGZgCzC/3P0u8vd3JvASMD6+fWa5+12CY14NfCP++AJgb7n7PYjjvRy4GNiRZf9SYANgwEKguRj9GOoj90uBVndvc/cuYC2wLK3NMuDn8ce/Bq40MythHwst7zG7+0Z3Px7f3ELs1ofDVZDvMcD3gR8CJ0vZuSIIcrxfB1a5eyeAux8scR8LLcgxO5C4+/tY4O0S9q+g3H0zsZsWZbMMeMxjtgDjzGxSofsx1MP9LODNpO2O+HMZ27h7D3AMmFCS3hVHkGNOdhOxUcBwlfd447+2TnX3J0vZsSIJ8v09DzjPzP5kZlvMrLFkvSuOIMf898CXzayD2I2B/qY0XSuL/v4fH5BAd2KSocnMvgzMB64od1+KxcwiwD8BXytzV0qpmlhpZhGx38o2m9mF7n60rL0qruuBn7n7/Wb2aeAXZjbH3aPl7thwNdRH7m8BU5O2p8Sfy9jGzKqJ/Up3pCS9K44gx4yZXQV8F7jG3T8qUd+KId/xjgbmAJvMbC+xGuX6YXxSNcj3twNY7+7d7v4G8CqxsB+ughzzTcCvANz9z8AIYuuwhFGg/+ODNdTDfSsw08zONrNaYidM16e1WQ98Nf74L4B/8/hZi2Eq7zGb2UXAw8SCfbjXY3Mer7sfc/eJ7t7g7g3EzjFc4+7D9e7qQX6m1xEbtWNmE4mVaXLecH6IC3LM7cCVAGY2i1i4HyppL0tnPXBjfNbMQuCYu+8v+LuU+8xygDPPS4mNXF4Hvht/7m5i/8Eh9kPwL0Ar8AIwo9x9LsEx/x54B9ge/7O+3H0u5vGmtd3EMJ4tE/D7a8RKUbuAV4Dryt3nEhzzBcCfiM2k2Q58rtx9HsSx/hLYD3QT+y3sJuBW4Nak7++q+NfilWL9POsKVRGREBrqZRkRERkAhbuISAgp3EVEQkjhLiISQgp3EZEQUriLiISQwl1EJIQU7iIiIfT/ASZHpt4EPuvdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_spmes = pd.read_csv(\"springPeeperPadraoMes.csv\")\n",
    "plt.scatter(df_spmes[\"lat\"], df_spmes[\"lng\"],marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc93addc3d0>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_gfest = pd.read_csv(\"greenFrogPadraoEstacao.csv\")\n",
    "plt.scatter(df_gfest[\"lat\"], df_gfest[\"lng\"],marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc9406cf090>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_atmes[\"lat\"], df_atmes[\"lng\"],marker=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atmes.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(df_atmes.columns)\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_gfmes.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(df_spmes.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com somente uma camada escondida e Dropout\n",
    "encoding_dim1 = 12\n",
    "entrada = Input(shape=(input_dim,))\n",
    "dp1 = Dropout(0.3)(entrada)\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(dp1)\n",
    "dp2 = Dropout(0.3)(encoded1)\n",
    "decoded2 = Dense(input_dim,activation=\"sigmoid\")(dp2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com 3 camadas escondidas para a base em ºC\n",
    "encoding_dim1 = 12\n",
    "encoding_dim2 = 6\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "dpen1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(encoding_dim2,activation=\"relu\")(dpen1)\n",
    "dpen2 = Dropout(0.1)(encoded2)\n",
    "decoded1 = Dense(encoding_dim1,activation=\"relu\")(dpen2) #sigmoid antes\n",
    "decoded2 = Dense(input_dim,activation=\"sigmoid\")(decoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede com somente uma camada escondida para a base limpa\n",
    "encoding_dim1 = 12\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "decoded2 = Dense(input_dim,activation=\"linear\")(encoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(entrada,decoded2)\n",
    "#codificador = Model(entrada,encoded)\n",
    "#cod = Input(shape=(encoding_dim,))\n",
    "#dec = autoencoder.layers[-1]\n",
    "#decodificador = Model(cod,dec(cod))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ajusta as funções de otimização e de perda\n",
    "#Prof. Juan prefere o adam, então vamo lá\n",
    "#autoencoder.compile(optimizer='adadelta', loss='mse')\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Toad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa o train_set do teste_set\n",
    "# Passa o dataset e ele retorna teste_size% dele pelo segundo retorno para teste e o resto pelo primeiro p treino\n",
    "# random_state é a semente do gerador de pseudoaleatórios para que seja sempre o mesmo testset\n",
    "# dessa forma, não acontece de acabar pegando todo o dataset se chamar esse método várias vezes\n",
    "X_trainAtMes, X_testAtMes = train_test_split(df_atmes, test_size=0.30, random_state=42)\n",
    "#X_trainAtEst, X_testAtEst = train_test_split(df_atest, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrain_dim = len(X_trainAtMes)\n",
    "attrain_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = attrain_dim//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1103"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attest_dim = len(X_testAtMes)\n",
    "attest_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2572 samples, validate on 1103 samples\n",
      "Epoch 1/3000\n",
      "2572/2572 [==============================] - 1s 229us/step - loss: 2.8410 - val_loss: 2.4945\n",
      "Epoch 2/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 2.6190 - val_loss: 2.3100\n",
      "Epoch 3/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 2.4395 - val_loss: 2.1630\n",
      "Epoch 4/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 2.3016 - val_loss: 2.0379\n",
      "Epoch 5/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 2.1709 - val_loss: 1.9309\n",
      "Epoch 6/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 2.0600 - val_loss: 1.8349\n",
      "Epoch 7/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 1.9579 - val_loss: 1.7446\n",
      "Epoch 8/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 1.8712 - val_loss: 1.6532\n",
      "Epoch 9/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 1.7710 - val_loss: 1.5679\n",
      "Epoch 10/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 1.6744 - val_loss: 1.4827\n",
      "Epoch 11/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 1.5897 - val_loss: 1.4121\n",
      "Epoch 12/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 1.5147 - val_loss: 1.3479\n",
      "Epoch 13/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 1.4467 - val_loss: 1.2893\n",
      "Epoch 14/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 1.3857 - val_loss: 1.2307\n",
      "Epoch 15/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 1.3193 - val_loss: 1.1679\n",
      "Epoch 16/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 1.2538 - val_loss: 1.1140\n",
      "Epoch 17/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 1.1952 - val_loss: 1.0608\n",
      "Epoch 18/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 1.1391 - val_loss: 1.0062\n",
      "Epoch 19/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 1.0821 - val_loss: 0.9619\n",
      "Epoch 20/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 1.0365 - val_loss: 0.9163\n",
      "Epoch 21/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.9774 - val_loss: 0.8664\n",
      "Epoch 22/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.9305 - val_loss: 0.8214\n",
      "Epoch 23/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.8838 - val_loss: 0.7817\n",
      "Epoch 24/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.8416 - val_loss: 0.7476\n",
      "Epoch 25/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.8029 - val_loss: 0.7166\n",
      "Epoch 26/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.7672 - val_loss: 0.6855\n",
      "Epoch 27/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.7323 - val_loss: 0.6567\n",
      "Epoch 28/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.7001 - val_loss: 0.6289\n",
      "Epoch 29/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.6691 - val_loss: 0.6021\n",
      "Epoch 30/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.6425 - val_loss: 0.5736\n",
      "Epoch 31/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.6114 - val_loss: 0.5478\n",
      "Epoch 32/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.5813 - val_loss: 0.5231\n",
      "Epoch 33/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.5537 - val_loss: 0.5012\n",
      "Epoch 34/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.5294 - val_loss: 0.4774\n",
      "Epoch 35/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.4944 - val_loss: 0.4468\n",
      "Epoch 36/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.4706 - val_loss: 0.4249\n",
      "Epoch 37/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.4451 - val_loss: 0.4082\n",
      "Epoch 38/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.4269 - val_loss: 0.3929\n",
      "Epoch 39/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.4117 - val_loss: 0.3773\n",
      "Epoch 40/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.3937 - val_loss: 0.3635\n",
      "Epoch 41/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.3772 - val_loss: 0.3510\n",
      "Epoch 42/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.3639 - val_loss: 0.3378\n",
      "Epoch 43/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.3489 - val_loss: 0.3257\n",
      "Epoch 44/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.3355 - val_loss: 0.3141\n",
      "Epoch 45/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.3234 - val_loss: 0.3025\n",
      "Epoch 46/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.3094 - val_loss: 0.2931\n",
      "Epoch 47/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2999 - val_loss: 0.2831\n",
      "Epoch 48/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2869 - val_loss: 0.2736\n",
      "Epoch 49/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2772 - val_loss: 0.2657\n",
      "Epoch 50/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.2682 - val_loss: 0.2573\n",
      "Epoch 51/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2583 - val_loss: 0.2497\n",
      "Epoch 52/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2498 - val_loss: 0.2422\n",
      "Epoch 53/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2413 - val_loss: 0.2360\n",
      "Epoch 54/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.2352 - val_loss: 0.2300\n",
      "Epoch 55/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2282 - val_loss: 0.2244\n",
      "Epoch 56/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.2217 - val_loss: 0.2196\n",
      "Epoch 57/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2171 - val_loss: 0.2143\n",
      "Epoch 58/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2108 - val_loss: 0.2098\n",
      "Epoch 59/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2051 - val_loss: 0.2054\n",
      "Epoch 60/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2005 - val_loss: 0.2009\n",
      "Epoch 61/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1955 - val_loss: 0.1966\n",
      "Epoch 62/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1913 - val_loss: 0.1931\n",
      "Epoch 63/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1874 - val_loss: 0.1901\n",
      "Epoch 64/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1834 - val_loss: 0.1864\n",
      "Epoch 65/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1794 - val_loss: 0.1831\n",
      "Epoch 66/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1759 - val_loss: 0.1797\n",
      "Epoch 67/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1722 - val_loss: 0.1771\n",
      "Epoch 68/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.1691 - val_loss: 0.1743\n",
      "Epoch 69/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.1660 - val_loss: 0.1711\n",
      "Epoch 70/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.1627 - val_loss: 0.1680\n",
      "Epoch 71/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.1597 - val_loss: 0.1654\n",
      "Epoch 72/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.1567 - val_loss: 0.1627\n",
      "Epoch 73/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.1541 - val_loss: 0.1601\n",
      "Epoch 74/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1515 - val_loss: 0.1578\n",
      "Epoch 75/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1493 - val_loss: 0.1559\n",
      "Epoch 76/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1469 - val_loss: 0.1535\n",
      "Epoch 77/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1446 - val_loss: 0.1514\n",
      "Epoch 78/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1425 - val_loss: 0.1491\n",
      "Epoch 79/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1402 - val_loss: 0.1469\n",
      "Epoch 80/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1381 - val_loss: 0.1449\n",
      "Epoch 81/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1360 - val_loss: 0.1428\n",
      "Epoch 82/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1340 - val_loss: 0.1410\n",
      "Epoch 83/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1322 - val_loss: 0.1394\n",
      "Epoch 84/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1305 - val_loss: 0.1378\n",
      "Epoch 85/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1288 - val_loss: 0.1360\n",
      "Epoch 86/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1271 - val_loss: 0.1342\n",
      "Epoch 87/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1255 - val_loss: 0.1329\n",
      "Epoch 88/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1242 - val_loss: 0.1321\n",
      "Epoch 89/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1227 - val_loss: 0.1303\n",
      "Epoch 90/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1212 - val_loss: 0.1289\n",
      "Epoch 91/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1196 - val_loss: 0.1271\n",
      "Epoch 92/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1181 - val_loss: 0.1258\n",
      "Epoch 93/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1166 - val_loss: 0.1241\n",
      "Epoch 94/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1151 - val_loss: 0.1228\n",
      "Epoch 95/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1138 - val_loss: 0.1219\n",
      "Epoch 96/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1126 - val_loss: 0.1208\n",
      "Epoch 97/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1112 - val_loss: 0.1195\n",
      "Epoch 98/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1100 - val_loss: 0.1184\n",
      "Epoch 99/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1086 - val_loss: 0.1169\n",
      "Epoch 100/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1073 - val_loss: 0.1156\n",
      "Epoch 101/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1059 - val_loss: 0.1141\n",
      "Epoch 102/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1047 - val_loss: 0.1128\n",
      "Epoch 103/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.1035 - val_loss: 0.1115\n",
      "Epoch 104/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1023 - val_loss: 0.1106\n",
      "Epoch 105/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1013 - val_loss: 0.1095\n",
      "Epoch 106/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1002 - val_loss: 0.1083\n",
      "Epoch 107/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0994 - val_loss: 0.1078\n",
      "Epoch 108/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0991 - val_loss: 0.1073\n",
      "Epoch 109/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0977 - val_loss: 0.1057\n",
      "Epoch 110/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1076 - val_loss: 0.1265\n",
      "Epoch 111/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1222 - val_loss: 0.1225\n",
      "Epoch 112/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.120 - 0s 9us/step - loss: 0.1135 - val_loss: 0.1148\n",
      "Epoch 113/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.1063 - val_loss: 0.1100\n",
      "Epoch 114/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.1009 - val_loss: 0.1060\n",
      "Epoch 115/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0970 - val_loss: 0.1032\n",
      "Epoch 116/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0943 - val_loss: 0.1013\n",
      "Epoch 117/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0925 - val_loss: 0.0998\n",
      "Epoch 118/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0909 - val_loss: 0.0982\n",
      "Epoch 119/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0894 - val_loss: 0.0969\n",
      "Epoch 120/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0882 - val_loss: 0.0957\n",
      "Epoch 121/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0871 - val_loss: 0.0948\n",
      "Epoch 122/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0861 - val_loss: 0.0938\n",
      "Epoch 123/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0851 - val_loss: 0.0929\n",
      "Epoch 124/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0844 - val_loss: 0.0922\n",
      "Epoch 125/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0836 - val_loss: 0.0912\n",
      "Epoch 126/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0827 - val_loss: 0.0903\n",
      "Epoch 127/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0819 - val_loss: 0.0896\n",
      "Epoch 128/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0812 - val_loss: 0.0888\n",
      "Epoch 129/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0804 - val_loss: 0.0881\n",
      "Epoch 130/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0797 - val_loss: 0.0873\n",
      "Epoch 131/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0789 - val_loss: 0.0864\n",
      "Epoch 132/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0782 - val_loss: 0.0858\n",
      "Epoch 133/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0776 - val_loss: 0.0851\n",
      "Epoch 134/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0769 - val_loss: 0.0845\n",
      "Epoch 135/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0764 - val_loss: 0.0842\n",
      "Epoch 136/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0757 - val_loss: 0.0831\n",
      "Epoch 137/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0750 - val_loss: 0.0823\n",
      "Epoch 138/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0743 - val_loss: 0.0817\n",
      "Epoch 139/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0738 - val_loss: 0.0816\n",
      "Epoch 140/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0733 - val_loss: 0.0810\n",
      "Epoch 141/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0727 - val_loss: 0.0805\n",
      "Epoch 142/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0722 - val_loss: 0.0797\n",
      "Epoch 143/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0715 - val_loss: 0.0789\n",
      "Epoch 144/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0709 - val_loss: 0.0784\n",
      "Epoch 145/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0703 - val_loss: 0.0777\n",
      "Epoch 146/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0696 - val_loss: 0.0770\n",
      "Epoch 147/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0690 - val_loss: 0.0765\n",
      "Epoch 148/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0686 - val_loss: 0.0759\n",
      "Epoch 149/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0682 - val_loss: 0.0762\n",
      "Epoch 150/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0680 - val_loss: 0.0753\n",
      "Epoch 151/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0674 - val_loss: 0.0744\n",
      "Epoch 152/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0665 - val_loss: 0.0734\n",
      "Epoch 153/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0658 - val_loss: 0.0728\n",
      "Epoch 154/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0651 - val_loss: 0.0722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0646 - val_loss: 0.0716\n",
      "Epoch 156/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0646 - val_loss: 0.0713\n",
      "Epoch 157/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0645 - val_loss: 0.0707\n",
      "Epoch 158/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0637 - val_loss: 0.0698\n",
      "Epoch 159/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0629 - val_loss: 0.0692\n",
      "Epoch 160/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0622 - val_loss: 0.0687\n",
      "Epoch 161/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0617 - val_loss: 0.0683\n",
      "Epoch 162/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0612 - val_loss: 0.0678\n",
      "Epoch 163/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0609 - val_loss: 0.0677\n",
      "Epoch 164/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0606 - val_loss: 0.0672\n",
      "Epoch 165/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0602 - val_loss: 0.0668\n",
      "Epoch 166/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0596 - val_loss: 0.0662\n",
      "Epoch 167/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0593 - val_loss: 0.0657\n",
      "Epoch 168/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0589 - val_loss: 0.0653\n",
      "Epoch 169/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0583 - val_loss: 0.0648\n",
      "Epoch 170/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0580 - val_loss: 0.0645\n",
      "Epoch 171/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0576 - val_loss: 0.0642\n",
      "Epoch 172/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0577 - val_loss: 0.0648\n",
      "Epoch 173/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0574 - val_loss: 0.0640\n",
      "Epoch 174/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0569 - val_loss: 0.0636\n",
      "Epoch 175/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0564 - val_loss: 0.0628\n",
      "Epoch 176/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0559 - val_loss: 0.0622\n",
      "Epoch 177/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0555 - val_loss: 0.0620\n",
      "Epoch 178/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0550 - val_loss: 0.0614\n",
      "Epoch 179/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0546 - val_loss: 0.0611\n",
      "Epoch 180/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0544 - val_loss: 0.0608\n",
      "Epoch 181/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0541 - val_loss: 0.0603\n",
      "Epoch 182/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0536 - val_loss: 0.0601\n",
      "Epoch 183/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0533 - val_loss: 0.0599\n",
      "Epoch 184/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0530 - val_loss: 0.0595\n",
      "Epoch 185/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0528 - val_loss: 0.0592\n",
      "Epoch 186/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0524 - val_loss: 0.0590\n",
      "Epoch 187/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0520 - val_loss: 0.0584\n",
      "Epoch 188/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0516 - val_loss: 0.0580\n",
      "Epoch 189/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0517 - val_loss: 0.0581\n",
      "Epoch 190/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0513 - val_loss: 0.0576\n",
      "Epoch 191/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0511 - val_loss: 0.0578\n",
      "Epoch 192/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0506 - val_loss: 0.0570\n",
      "Epoch 193/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0502 - val_loss: 0.0566\n",
      "Epoch 194/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0499 - val_loss: 0.0564\n",
      "Epoch 195/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0496 - val_loss: 0.0560\n",
      "Epoch 196/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0495 - val_loss: 0.0559\n",
      "Epoch 197/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0523 - val_loss: 0.0602\n",
      "Epoch 198/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0515 - val_loss: 0.0561\n",
      "Epoch 199/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0492 - val_loss: 0.0557\n",
      "Epoch 200/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0488 - val_loss: 0.0551\n",
      "Epoch 201/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0483 - val_loss: 0.0546\n",
      "Epoch 202/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0479 - val_loss: 0.0543\n",
      "Epoch 203/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0476 - val_loss: 0.0540\n",
      "Epoch 204/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0473 - val_loss: 0.0536\n",
      "Epoch 205/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0474 - val_loss: 0.0538\n",
      "Epoch 206/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0477 - val_loss: 0.0542\n",
      "Epoch 207/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0473 - val_loss: 0.0533\n",
      "Epoch 208/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0466 - val_loss: 0.0529\n",
      "Epoch 209/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0462 - val_loss: 0.0525\n",
      "Epoch 210/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0459 - val_loss: 0.0523\n",
      "Epoch 211/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0458 - val_loss: 0.0521\n",
      "Epoch 212/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0462 - val_loss: 0.0525\n",
      "Epoch 213/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0456 - val_loss: 0.0516\n",
      "Epoch 214/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0451 - val_loss: 0.0512\n",
      "Epoch 215/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0448 - val_loss: 0.0509\n",
      "Epoch 216/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0445 - val_loss: 0.0508\n",
      "Epoch 217/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0474 - val_loss: 0.0551\n",
      "Epoch 218/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0469 - val_loss: 0.0513\n",
      "Epoch 219/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0445 - val_loss: 0.0507\n",
      "Epoch 220/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0440 - val_loss: 0.0503\n",
      "Epoch 221/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0438 - val_loss: 0.0501\n",
      "Epoch 222/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0435 - val_loss: 0.0496\n",
      "Epoch 223/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0431 - val_loss: 0.0494\n",
      "Epoch 224/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0429 - val_loss: 0.0491\n",
      "Epoch 225/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0427 - val_loss: 0.0489\n",
      "Epoch 226/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0425 - val_loss: 0.0487\n",
      "Epoch 227/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0423 - val_loss: 0.0484\n",
      "Epoch 228/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0420 - val_loss: 0.0482\n",
      "Epoch 229/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0419 - val_loss: 0.0481\n",
      "Epoch 230/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0417 - val_loss: 0.0478\n",
      "Epoch 231/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0414 - val_loss: 0.0476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 232/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0413 - val_loss: 0.0474\n",
      "Epoch 233/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0411 - val_loss: 0.0471\n",
      "Epoch 234/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0409 - val_loss: 0.0469\n",
      "Epoch 235/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0408 - val_loss: 0.0469\n",
      "Epoch 236/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0406 - val_loss: 0.0465\n",
      "Epoch 237/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0403 - val_loss: 0.0463\n",
      "Epoch 238/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0402 - val_loss: 0.0461\n",
      "Epoch 239/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0403 - val_loss: 0.0462\n",
      "Epoch 240/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0400 - val_loss: 0.0459\n",
      "Epoch 241/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0413 - val_loss: 0.0472\n",
      "Epoch 242/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0412 - val_loss: 0.0461\n",
      "Epoch 243/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0402 - val_loss: 0.0457\n",
      "Epoch 244/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0396 - val_loss: 0.0451\n",
      "Epoch 245/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0392 - val_loss: 0.0448\n",
      "Epoch 246/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0391 - val_loss: 0.0448\n",
      "Epoch 247/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0390 - val_loss: 0.0449\n",
      "Epoch 248/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0387 - val_loss: 0.0444\n",
      "Epoch 249/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0387 - val_loss: 0.0442\n",
      "Epoch 250/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0384 - val_loss: 0.0438\n",
      "Epoch 251/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0380 - val_loss: 0.0438\n",
      "Epoch 252/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0379 - val_loss: 0.0436\n",
      "Epoch 253/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0377 - val_loss: 0.0434\n",
      "Epoch 254/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0376 - val_loss: 0.0434\n",
      "Epoch 255/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0381 - val_loss: 0.0435\n",
      "Epoch 256/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0375 - val_loss: 0.0430\n",
      "Epoch 257/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0372 - val_loss: 0.0428\n",
      "Epoch 258/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0369 - val_loss: 0.0424\n",
      "Epoch 259/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0369 - val_loss: 0.0425\n",
      "Epoch 260/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0368 - val_loss: 0.0424\n",
      "Epoch 261/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0364 - val_loss: 0.0418\n",
      "Epoch 262/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0361 - val_loss: 0.0417\n",
      "Epoch 263/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0361 - val_loss: 0.0416\n",
      "Epoch 264/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0357 - val_loss: 0.0410\n",
      "Epoch 265/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0354 - val_loss: 0.0408\n",
      "Epoch 266/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0353 - val_loss: 0.0408\n",
      "Epoch 267/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0352 - val_loss: 0.0404\n",
      "Epoch 268/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0348 - val_loss: 0.0405\n",
      "Epoch 269/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0392 - val_loss: 0.0458\n",
      "Epoch 270/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0383 - val_loss: 0.0403\n",
      "Epoch 271/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0346 - val_loss: 0.0401\n",
      "Epoch 272/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0344 - val_loss: 0.0397\n",
      "Epoch 273/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0339 - val_loss: 0.0391\n",
      "Epoch 274/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0336 - val_loss: 0.0388\n",
      "Epoch 275/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0333 - val_loss: 0.0385\n",
      "Epoch 276/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0331 - val_loss: 0.0382\n",
      "Epoch 277/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0329 - val_loss: 0.0380\n",
      "Epoch 278/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0327 - val_loss: 0.0378\n",
      "Epoch 279/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0324 - val_loss: 0.0376\n",
      "Epoch 280/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 0.0373\n",
      "Epoch 281/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0322 - val_loss: 0.0374\n",
      "Epoch 282/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0326 - val_loss: 0.0377\n",
      "Epoch 283/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0321 - val_loss: 0.0368\n",
      "Epoch 284/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0317 - val_loss: 0.0366\n",
      "Epoch 285/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0313 - val_loss: 0.0363\n",
      "Epoch 286/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0311 - val_loss: 0.0360\n",
      "Epoch 287/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0308 - val_loss: 0.0356\n",
      "Epoch 288/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0306 - val_loss: 0.0355\n",
      "Epoch 289/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0306 - val_loss: 0.0360\n",
      "Epoch 290/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0399 - val_loss: 0.0463\n",
      "Epoch 291/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0366 - val_loss: 0.0360\n",
      "Epoch 292/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0312 - val_loss: 0.0356\n",
      "Epoch 293/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 294/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0298 - val_loss: 0.0342\n",
      "Epoch 295/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0296 - val_loss: 0.0339\n",
      "Epoch 296/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0293 - val_loss: 0.0337\n",
      "Epoch 297/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0290 - val_loss: 0.0334\n",
      "Epoch 298/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0291 - val_loss: 0.0334\n",
      "Epoch 299/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0287 - val_loss: 0.0331\n",
      "Epoch 300/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0285 - val_loss: 0.0329\n",
      "Epoch 301/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0282 - val_loss: 0.0327\n",
      "Epoch 302/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0283 - val_loss: 0.0326\n",
      "Epoch 303/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0279 - val_loss: 0.0322\n",
      "Epoch 304/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0277 - val_loss: 0.0320\n",
      "Epoch 305/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0276 - val_loss: 0.0321\n",
      "Epoch 306/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0273 - val_loss: 0.0318\n",
      "Epoch 307/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0273 - val_loss: 0.0317\n",
      "Epoch 308/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0270 - val_loss: 0.0317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 309/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0269 - val_loss: 0.0313\n",
      "Epoch 310/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0265 - val_loss: 0.0309\n",
      "Epoch 311/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0263 - val_loss: 0.0307\n",
      "Epoch 312/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0260 - val_loss: 0.0305\n",
      "Epoch 313/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0258 - val_loss: 0.0303\n",
      "Epoch 314/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0257 - val_loss: 0.0301\n",
      "Epoch 315/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0255 - val_loss: 0.0299\n",
      "Epoch 316/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0254 - val_loss: 0.0297\n",
      "Epoch 317/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0254 - val_loss: 0.0298\n",
      "Epoch 318/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0253 - val_loss: 0.0296\n",
      "Epoch 319/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0248 - val_loss: 0.0292\n",
      "Epoch 320/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 0.0290\n",
      "Epoch 321/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0244 - val_loss: 0.0289\n",
      "Epoch 322/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0246 - val_loss: 0.0291\n",
      "Epoch 323/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0243 - val_loss: 0.0289\n",
      "Epoch 324/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0315 - val_loss: 0.0363\n",
      "Epoch 325/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0289 - val_loss: 0.0294\n",
      "Epoch 326/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0251 - val_loss: 0.0290\n",
      "Epoch 327/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0244 - val_loss: 0.0283\n",
      "Epoch 328/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0240 - val_loss: 0.0279\n",
      "Epoch 329/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0237 - val_loss: 0.0277\n",
      "Epoch 330/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0234 - val_loss: 0.0275\n",
      "Epoch 331/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0232 - val_loss: 0.0273\n",
      "Epoch 332/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0230 - val_loss: 0.0271\n",
      "Epoch 333/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 0.0270\n",
      "Epoch 334/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0228 - val_loss: 0.0270\n",
      "Epoch 335/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0226 - val_loss: 0.0268\n",
      "Epoch 336/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0224 - val_loss: 0.0266\n",
      "Epoch 337/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0223 - val_loss: 0.0265\n",
      "Epoch 338/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0222 - val_loss: 0.0263\n",
      "Epoch 339/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0219 - val_loss: 0.0262\n",
      "Epoch 340/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0218 - val_loss: 0.0261\n",
      "Epoch 341/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0217 - val_loss: 0.0259\n",
      "Epoch 342/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0215 - val_loss: 0.0257\n",
      "Epoch 343/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0214 - val_loss: 0.0256\n",
      "Epoch 344/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0212 - val_loss: 0.0255\n",
      "Epoch 345/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0210 - val_loss: 0.0254\n",
      "Epoch 346/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0211 - val_loss: 0.0253\n",
      "Epoch 347/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0213 - val_loss: 0.0254\n",
      "Epoch 348/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0209 - val_loss: 0.0250\n",
      "Epoch 349/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0208 - val_loss: 0.0252\n",
      "Epoch 350/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0206 - val_loss: 0.0248\n",
      "Epoch 351/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0206 - val_loss: 0.0248\n",
      "Epoch 352/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0203 - val_loss: 0.0247\n",
      "Epoch 353/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0202 - val_loss: 0.0245\n",
      "Epoch 354/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0200 - val_loss: 0.0244\n",
      "Epoch 355/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0200 - val_loss: 0.0243\n",
      "Epoch 356/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0199 - val_loss: 0.0242\n",
      "Epoch 357/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0197 - val_loss: 0.0241\n",
      "Epoch 358/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0196 - val_loss: 0.0240\n",
      "Epoch 359/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0195 - val_loss: 0.0239\n",
      "Epoch 360/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0193 - val_loss: 0.0238\n",
      "Epoch 361/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0193 - val_loss: 0.0238\n",
      "Epoch 362/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0193 - val_loss: 0.0237\n",
      "Epoch 363/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0192 - val_loss: 0.0237\n",
      "Epoch 364/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0190 - val_loss: 0.0235\n",
      "Epoch 365/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0189 - val_loss: 0.0234\n",
      "Epoch 366/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0189 - val_loss: 0.0234\n",
      "Epoch 367/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0188 - val_loss: 0.0234\n",
      "Epoch 368/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 369/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0187 - val_loss: 0.0232\n",
      "Epoch 370/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0185 - val_loss: 0.0231\n",
      "Epoch 371/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0185 - val_loss: 0.0230\n",
      "Epoch 372/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0184 - val_loss: 0.0230\n",
      "Epoch 373/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 0.0229\n",
      "Epoch 374/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0182 - val_loss: 0.0228\n",
      "Epoch 375/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0181 - val_loss: 0.0227\n",
      "Epoch 376/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0183 - val_loss: 0.0228\n",
      "Epoch 377/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0181 - val_loss: 0.0226\n",
      "Epoch 378/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0179 - val_loss: 0.0225\n",
      "Epoch 379/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0178 - val_loss: 0.0225\n",
      "Epoch 380/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.014 - 0s 23us/step - loss: 0.0177 - val_loss: 0.0224\n",
      "Epoch 381/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0177 - val_loss: 0.0224\n",
      "Epoch 382/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0176 - val_loss: 0.0223\n",
      "Epoch 383/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0176 - val_loss: 0.0222\n",
      "Epoch 384/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0175 - val_loss: 0.0223\n",
      "Epoch 385/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0177 - val_loss: 0.0222\n",
      "Epoch 386/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0175 - val_loss: 0.0222\n",
      "Epoch 387/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0176 - val_loss: 0.0221\n",
      "Epoch 388/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0173 - val_loss: 0.0219\n",
      "Epoch 389/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0172 - val_loss: 0.0219\n",
      "Epoch 390/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0171 - val_loss: 0.0218\n",
      "Epoch 391/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0171 - val_loss: 0.0218\n",
      "Epoch 392/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0171 - val_loss: 0.0218\n",
      "Epoch 393/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0170 - val_loss: 0.0217\n",
      "Epoch 394/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0171 - val_loss: 0.0217\n",
      "Epoch 395/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0169 - val_loss: 0.0216\n",
      "Epoch 396/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0168 - val_loss: 0.0215\n",
      "Epoch 397/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0170 - val_loss: 0.0216\n",
      "Epoch 398/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0168 - val_loss: 0.0217\n",
      "Epoch 399/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0169 - val_loss: 0.0214\n",
      "Epoch 400/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0168 - val_loss: 0.0213\n",
      "Epoch 401/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 402/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 403/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0167 - val_loss: 0.0214\n",
      "Epoch 404/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0213\n",
      "Epoch 405/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0166 - val_loss: 0.0213\n",
      "Epoch 406/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0164 - val_loss: 0.0213\n",
      "Epoch 407/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0164 - val_loss: 0.0211\n",
      "Epoch 408/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0210\n",
      "Epoch 409/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0211\n",
      "Epoch 410/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 411/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0162 - val_loss: 0.0209\n",
      "Epoch 412/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 413/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0161 - val_loss: 0.0208\n",
      "Epoch 414/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0163 - val_loss: 0.0209\n",
      "Epoch 415/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0161 - val_loss: 0.0207\n",
      "Epoch 416/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0207\n",
      "Epoch 417/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0164 - val_loss: 0.0208\n",
      "Epoch 418/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0160 - val_loss: 0.0207\n",
      "Epoch 419/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0205\n",
      "Epoch 420/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0158 - val_loss: 0.0204\n",
      "Epoch 421/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0157 - val_loss: 0.0204\n",
      "Epoch 422/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0157 - val_loss: 0.0204\n",
      "Epoch 423/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0156 - val_loss: 0.0203\n",
      "Epoch 424/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0204\n",
      "Epoch 425/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0156 - val_loss: 0.0202\n",
      "Epoch 426/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 427/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 428/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0156 - val_loss: 0.0201\n",
      "Epoch 429/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0201\n",
      "Epoch 430/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0157 - val_loss: 0.0201\n",
      "Epoch 431/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0201\n",
      "Epoch 432/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0155 - val_loss: 0.0200\n",
      "Epoch 433/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0154 - val_loss: 0.0200\n",
      "Epoch 434/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0154 - val_loss: 0.0199\n",
      "Epoch 435/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0154 - val_loss: 0.0201\n",
      "Epoch 436/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0161 - val_loss: 0.0203\n",
      "Epoch 437/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0162 - val_loss: 0.0204\n",
      "Epoch 438/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0157 - val_loss: 0.0201\n",
      "Epoch 439/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 440/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 441/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 442/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 443/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 444/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0198\n",
      "Epoch 445/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0150 - val_loss: 0.0197\n",
      "Epoch 446/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0149 - val_loss: 0.0196\n",
      "Epoch 447/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0195\n",
      "Epoch 448/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0154 - val_loss: 0.0195\n",
      "Epoch 449/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0150 - val_loss: 0.0196\n",
      "Epoch 450/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0150 - val_loss: 0.0195\n",
      "Epoch 451/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0148 - val_loss: 0.0194\n",
      "Epoch 452/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0149 - val_loss: 0.0194\n",
      "Epoch 453/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0195\n",
      "Epoch 454/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0193\n",
      "Epoch 455/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0193\n",
      "Epoch 456/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0192\n",
      "Epoch 457/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0191\n",
      "Epoch 458/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0191\n",
      "Epoch 459/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0191\n",
      "Epoch 460/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0191\n",
      "Epoch 461/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0190\n",
      "Epoch 462/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0145 - val_loss: 0.0190\n",
      "Epoch 463/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0189\n",
      "Epoch 464/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 465/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0189\n",
      "Epoch 466/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 467/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0188\n",
      "Epoch 468/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0143 - val_loss: 0.0189\n",
      "Epoch 469/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0189\n",
      "Epoch 470/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0145 - val_loss: 0.0189\n",
      "Epoch 471/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0188\n",
      "Epoch 472/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0186\n",
      "Epoch 473/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0144 - val_loss: 0.0189\n",
      "Epoch 474/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0148 - val_loss: 0.0191\n",
      "Epoch 475/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0189\n",
      "Epoch 476/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0143 - val_loss: 0.0187\n",
      "Epoch 477/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0142 - val_loss: 0.0185\n",
      "Epoch 478/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0185\n",
      "Epoch 479/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0146 - val_loss: 0.0185\n",
      "Epoch 480/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0141 - val_loss: 0.0184\n",
      "Epoch 481/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0184\n",
      "Epoch 482/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 483/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0139 - val_loss: 0.0183\n",
      "Epoch 484/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 485/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 486/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 487/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0182\n",
      "Epoch 488/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0139 - val_loss: 0.0182\n",
      "Epoch 489/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 490/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 491/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 492/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0180\n",
      "Epoch 493/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0181\n",
      "Epoch 494/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0180\n",
      "Epoch 495/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0180\n",
      "Epoch 496/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 497/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0139 - val_loss: 0.0180\n",
      "Epoch 498/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0181\n",
      "Epoch 499/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0179\n",
      "Epoch 500/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 501/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 502/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 503/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0139 - val_loss: 0.0179\n",
      "Epoch 504/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 505/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 506/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0178\n",
      "Epoch 507/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 508/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0178\n",
      "Epoch 509/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0135 - val_loss: 0.0176\n",
      "Epoch 510/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 511/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 512/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 513/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0179\n",
      "Epoch 514/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0177\n",
      "Epoch 515/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0135 - val_loss: 0.0176\n",
      "Epoch 516/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0175\n",
      "Epoch 517/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0175\n",
      "Epoch 518/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0175\n",
      "Epoch 519/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0175\n",
      "Epoch 520/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0175\n",
      "Epoch 521/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0175\n",
      "Epoch 522/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0134 - val_loss: 0.0174\n",
      "Epoch 523/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 524/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0174\n",
      "Epoch 525/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 526/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0173\n",
      "Epoch 527/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0173\n",
      "Epoch 528/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0173\n",
      "Epoch 529/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0134 - val_loss: 0.0174\n",
      "Epoch 530/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 531/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 532/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0135 - val_loss: 0.0173\n",
      "Epoch 533/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0174\n",
      "Epoch 534/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0173\n",
      "Epoch 535/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0172\n",
      "Epoch 536/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0172\n",
      "Epoch 537/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0172\n",
      "Epoch 538/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 539/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0131 - val_loss: 0.0172\n",
      "Epoch 540/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 541/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 542/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0172\n",
      "Epoch 543/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0171\n",
      "Epoch 544/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 545/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.011 - 0s 9us/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 546/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 547/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 548/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0172\n",
      "Epoch 549/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0180\n",
      "Epoch 550/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0140 - val_loss: 0.0174\n",
      "Epoch 551/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0171\n",
      "Epoch 552/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0170\n",
      "Epoch 553/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0169\n",
      "Epoch 554/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0169\n",
      "Epoch 555/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0170\n",
      "Epoch 556/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0169\n",
      "Epoch 557/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0169\n",
      "Epoch 558/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0169\n",
      "Epoch 559/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0133 - val_loss: 0.0169\n",
      "Epoch 560/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0170\n",
      "Epoch 561/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0168\n",
      "Epoch 562/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 563/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 564/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 565/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 566/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 567/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 568/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 569/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 570/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 571/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 572/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 573/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 574/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0167\n",
      "Epoch 575/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0169\n",
      "Epoch 576/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0168\n",
      "Epoch 577/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 578/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 579/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 580/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 581/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 582/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0167\n",
      "Epoch 583/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0167\n",
      "Epoch 584/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0168\n",
      "Epoch 585/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 586/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0167\n",
      "Epoch 587/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 588/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0167\n",
      "Epoch 589/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0166\n",
      "Epoch 590/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0165\n",
      "Epoch 591/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 592/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 593/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0167\n",
      "Epoch 594/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 595/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 596/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0165\n",
      "Epoch 597/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0164\n",
      "Epoch 598/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 599/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 600/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 601/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0130 - val_loss: 0.0165\n",
      "Epoch 602/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 603/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 604/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 605/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 606/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 607/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 608/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 609/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 610/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 611/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 612/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0167\n",
      "Epoch 613/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0173\n",
      "Epoch 614/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0136 - val_loss: 0.0170\n",
      "Epoch 615/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 616/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 617/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0166\n",
      "Epoch 618/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 619/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 620/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 621/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0163\n",
      "Epoch 622/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 623/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 624/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 625/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 626/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 627/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 628/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 629/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 630/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0165\n",
      "Epoch 631/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0134 - val_loss: 0.0166\n",
      "Epoch 632/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0164\n",
      "Epoch 633/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 634/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 635/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 636/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 637/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0162\n",
      "Epoch 638/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 639/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 640/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 641/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 642/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 643/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0163\n",
      "Epoch 644/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 645/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 646/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 647/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 648/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 649/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 650/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 651/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 652/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0165\n",
      "Epoch 653/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0163\n",
      "Epoch 654/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 655/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 656/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0162\n",
      "Epoch 657/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 658/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 659/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0162\n",
      "Epoch 660/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0164\n",
      "Epoch 661/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 662/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 663/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 664/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 665/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 666/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 667/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 668/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0124 - val_loss: 0.0164\n",
      "Epoch 669/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 670/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0166\n",
      "Epoch 671/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0164\n",
      "Epoch 672/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0163\n",
      "Epoch 673/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0173\n",
      "Epoch 674/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0209 - val_loss: 0.0216\n",
      "Epoch 675/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0158 - val_loss: 0.0173\n",
      "Epoch 676/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0136 - val_loss: 0.0167\n",
      "Epoch 677/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 678/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 679/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 680/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 681/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 682/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 683/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 684/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 685/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 686/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 687/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 688/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 689/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 690/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 691/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 692/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 693/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 694/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 695/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 696/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0129 - val_loss: 0.0160\n",
      "Epoch 697/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 698/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0163\n",
      "Epoch 699/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 700/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 701/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 702/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 703/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 704/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 705/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 706/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 707/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 708/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 709/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 710/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 711/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 712/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 713/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 714/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0163\n",
      "Epoch 715/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 716/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 717/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 718/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 719/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 720/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 721/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 722/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 723/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 724/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 725/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 726/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 727/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 728/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 729/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 730/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 731/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 732/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0162\n",
      "Epoch 733/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 734/3000\n",
      "2572/2572 [==============================] - 0s 38us/step - loss: 0.0130 - val_loss: 0.0165\n",
      "Epoch 735/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0128 - val_loss: 0.0162\n",
      "Epoch 736/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 737/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 738/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 739/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 740/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 741/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 742/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 743/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 744/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 745/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 746/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 747/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 748/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 749/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 750/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 751/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 752/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 753/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 754/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 755/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 756/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 757/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 758/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 759/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 760/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 761/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0164\n",
      "Epoch 762/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 763/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 764/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 765/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 766/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 767/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 768/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 769/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 770/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0162\n",
      "Epoch 771/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 772/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0162\n",
      "Epoch 773/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 774/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 775/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 776/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 777/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 778/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 779/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 780/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 781/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 782/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 783/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 784/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 785/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 786/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 787/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 788/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 789/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 790/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 791/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 792/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 793/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 794/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 795/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 796/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 797/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 798/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 799/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 800/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 801/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 802/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 803/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 804/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 805/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0164\n",
      "Epoch 806/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0133 - val_loss: 0.0160\n",
      "Epoch 807/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0126 - val_loss: 0.0160\n",
      "Epoch 808/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 809/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 810/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 811/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 812/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 813/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 814/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 815/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 816/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 817/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0130 - val_loss: 0.0163\n",
      "Epoch 818/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 819/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 820/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 821/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 822/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 823/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 824/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 825/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 826/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 827/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 828/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 829/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 830/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 831/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 832/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 833/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 834/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 835/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 836/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 837/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 838/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 839/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 840/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 841/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0142 - val_loss: 0.0165\n",
      "Epoch 842/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0165\n",
      "Epoch 843/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 844/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 845/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 847/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0166\n",
      "Epoch 848/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0200 - val_loss: 0.0248\n",
      "Epoch 849/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0188 - val_loss: 0.0172\n",
      "Epoch 850/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0165\n",
      "Epoch 851/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0164\n",
      "Epoch 852/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 853/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 854/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0137 - val_loss: 0.0162\n",
      "Epoch 855/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 856/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 857/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 858/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 859/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 860/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 861/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 862/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 863/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0142 - val_loss: 0.0168\n",
      "Epoch 864/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0168\n",
      "Epoch 865/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0162\n",
      "Epoch 866/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 867/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 868/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 869/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 870/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 871/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 872/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 873/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 874/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 875/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 876/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 877/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 878/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 879/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 880/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 881/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 882/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 883/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 884/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 885/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 886/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 887/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 888/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 889/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 890/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 891/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0162\n",
      "Epoch 892/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0151 - val_loss: 0.0167\n",
      "Epoch 893/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0164\n",
      "Epoch 894/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 895/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 896/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 897/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 898/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 899/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 900/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 901/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 902/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 903/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 904/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 905/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 906/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 907/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 908/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 909/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 910/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0164\n",
      "Epoch 911/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 912/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 913/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 914/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 915/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 916/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 917/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 918/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 919/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 920/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 921/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 922/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 923/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 924/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 925/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 926/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 927/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 928/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 929/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 930/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 931/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 932/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 933/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 934/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 935/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 936/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 937/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0161\n",
      "Epoch 938/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 939/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 940/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 941/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 942/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 943/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 944/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 945/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 946/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 947/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 948/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 949/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 950/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 951/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 952/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 953/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 954/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 955/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 956/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 957/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 958/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 959/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 960/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 961/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 962/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 963/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 964/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 965/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 966/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 967/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 968/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 969/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 970/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 971/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 972/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 973/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 974/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 975/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 976/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 977/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 978/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 979/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 980/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 981/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 982/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 983/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0164\n",
      "Epoch 984/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0148 - val_loss: 0.0170\n",
      "Epoch 985/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0135 - val_loss: 0.0164\n",
      "Epoch 986/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 987/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 988/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 989/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 990/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 991/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 992/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 993/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 994/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 995/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 996/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 997/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 998/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 999/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1001/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1002/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1003/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1004/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1005/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1006/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1007/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1008/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1009/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1010/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1011/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1012/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1013/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1014/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1015/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1016/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 1017/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0189\n",
      "Epoch 1018/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0143 - val_loss: 0.0162\n",
      "Epoch 1019/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 1020/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0165\n",
      "Epoch 1021/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0155 - val_loss: 0.0172\n",
      "Epoch 1022/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0168\n",
      "Epoch 1023/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0161\n",
      "Epoch 1024/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 1025/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0160\n",
      "Epoch 1026/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 1027/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0164\n",
      "Epoch 1028/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1029/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1030/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1031/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1032/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1033/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1034/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1035/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1036/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1037/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 1038/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 1039/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1040/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1041/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1042/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1043/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1044/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1045/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1046/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1047/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1048/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1049/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1050/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0161\n",
      "Epoch 1051/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 1052/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1053/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1054/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 1055/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 1056/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1057/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1058/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1059/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1060/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1061/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1062/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1063/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1064/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1065/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1066/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1067/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1068/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1069/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1070/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 1071/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1072/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1073/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1074/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1075/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0154 - val_loss: 0.0194\n",
      "Epoch 1076/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0144 - val_loss: 0.0157\n",
      "Epoch 1077/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 1078/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 1079/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1080/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1081/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1082/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1083/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1084/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1085/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1086/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1087/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 1088/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 1089/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1090/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1091/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1092/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1093/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 1094/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 1095/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 1096/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1097/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1098/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1099/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1100/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1101/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1102/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1103/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1104/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1105/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1106/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1107/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1108/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1109/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1110/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1111/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 1112/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 1113/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 1114/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1115/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1116/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1117/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1118/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1119/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1120/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1121/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1122/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1123/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1124/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1125/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1126/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1127/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1128/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1129/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1130/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1131/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1132/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1133/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1134/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1135/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1136/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1137/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 1138/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 1139/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1140/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1141/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1142/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 1143/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1144/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1145/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1146/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 1147/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1148/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1149/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1150/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1151/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1152/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1153/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0161\n",
      "Epoch 1154/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1155/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1156/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1157/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1158/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1159/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1160/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1161/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1162/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1163/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1164/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1165/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1166/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1167/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1168/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1169/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1170/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1171/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1172/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1173/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1174/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1175/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1176/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1177/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1178/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1179/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1180/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1181/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1182/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1183/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1184/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 1185/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1186/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1187/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1188/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1189/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1190/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1191/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1192/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1193/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1194/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1195/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1196/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1197/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1198/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1199/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1200/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0159 - val_loss: 0.0195\n",
      "Epoch 1201/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0165\n",
      "Epoch 1202/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0164\n",
      "Epoch 1203/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1204/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1205/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1206/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1207/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1208/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1209/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1210/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1211/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 1212/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1213/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1214/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1215/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1216/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1217/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1218/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1219/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1220/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1221/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1222/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1223/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0159\n",
      "Epoch 1224/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1225/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1226/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1227/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1228/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1229/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1230/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1231/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1232/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1233/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1234/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1235/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1236/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1237/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1238/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1239/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1240/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1241/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1242/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 1243/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1244/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1245/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1246/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1247/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1248/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1249/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1250/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1251/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1252/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1253/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1254/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1255/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1256/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0161\n",
      "Epoch 1257/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0140 - val_loss: 0.0163\n",
      "Epoch 1258/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 1259/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1260/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1261/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1262/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1263/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1264/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1265/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1266/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1267/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1268/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1269/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1270/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1271/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1272/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1273/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1274/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1275/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1276/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1277/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1278/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1279/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1280/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1281/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1282/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 1283/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1284/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1285/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1286/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1287/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1288/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1289/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1290/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1291/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1292/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1293/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1294/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1295/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1296/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1297/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1298/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1299/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1300/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1301/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1302/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.008 - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1303/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1304/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1305/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1306/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1307/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1308/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1309/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1310/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1311/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 1312/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0166\n",
      "Epoch 1313/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0152 - val_loss: 0.0174\n",
      "Epoch 1314/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0166\n",
      "Epoch 1315/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0160\n",
      "Epoch 1316/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1317/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 1318/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 1319/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1320/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1321/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1322/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1323/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1324/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1325/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1326/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1327/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1328/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1329/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1330/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1331/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 1332/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1333/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1334/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 1335/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0135 - val_loss: 0.0160\n",
      "Epoch 1336/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 1337/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1338/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1339/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1340/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1341/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1342/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1343/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1344/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0158\n",
      "Epoch 1345/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1346/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1347/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1348/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1349/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1350/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1351/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1352/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1353/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1354/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1355/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1356/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1357/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1358/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1359/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1360/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1361/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1362/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1363/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 1364/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0136 - val_loss: 0.0166\n",
      "Epoch 1365/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0163\n",
      "Epoch 1366/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0131 - val_loss: 0.0162\n",
      "Epoch 1367/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 1368/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 1369/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1370/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 1371/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 1372/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1373/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1374/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 1375/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0143 - val_loss: 0.0168\n",
      "Epoch 1376/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0131 - val_loss: 0.0165\n",
      "Epoch 1377/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 1378/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1379/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1380/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1381/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1382/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1383/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1384/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1385/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1386/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1387/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1388/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1389/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1390/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1391/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1392/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1393/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1394/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1395/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1396/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1397/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1398/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1399/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1400/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1401/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1402/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1403/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1404/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 1405/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1406/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1407/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1408/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1409/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1410/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1411/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1412/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1413/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1414/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1415/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1416/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1417/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1418/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.008 - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1419/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1420/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1421/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1422/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1423/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1424/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1425/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1426/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1427/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1428/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1429/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1430/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0136 - val_loss: 0.0164\n",
      "Epoch 1431/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 0.0162\n",
      "Epoch 1432/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1433/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1434/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1435/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1436/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1437/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1438/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1439/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1440/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1441/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 1442/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0160\n",
      "Epoch 1443/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1444/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1445/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1446/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1447/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1448/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1449/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1450/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1451/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1452/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1453/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1454/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1455/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1456/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1457/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1458/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1459/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1460/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1461/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1462/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1463/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1464/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1465/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1466/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1467/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.010 - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1468/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1469/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1470/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1471/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1472/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1473/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1474/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1475/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 1476/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 1477/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1478/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1479/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1480/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1481/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1482/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1483/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1484/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1485/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 1486/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0134 - val_loss: 0.0161\n",
      "Epoch 1487/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 1488/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1489/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1490/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1491/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1492/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1493/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1494/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1495/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1496/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 1497/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 1498/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1499/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1500/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1501/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1502/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1503/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1504/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1505/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1506/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1507/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1508/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 1509/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1510/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1511/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1512/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1513/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1514/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1515/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1516/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1517/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1518/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1519/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1520/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1521/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1522/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1523/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1524/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1525/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1526/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1527/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1528/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0160\n",
      "Epoch 1529/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0165 - val_loss: 0.0200\n",
      "Epoch 1530/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0142 - val_loss: 0.0157\n",
      "Epoch 1531/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1532/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1533/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1534/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1535/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1536/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 1537/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1538/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1539/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1540/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1541/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1542/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1543/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1544/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1545/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1546/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1547/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1548/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1549/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1550/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1551/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1552/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1553/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1554/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1555/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1556/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 1557/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1558/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1559/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1560/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1561/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1562/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1563/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1564/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1565/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1566/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1567/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1568/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1569/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1570/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1571/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1572/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1573/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1574/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1575/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1576/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1577/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1578/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1579/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1580/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 1581/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1582/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1583/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1584/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1585/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1586/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1587/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1588/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1589/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1590/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1591/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1592/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1593/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 1594/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1595/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 1596/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1597/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 1598/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1599/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1600/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1601/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1602/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0168\n",
      "Epoch 1603/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0166 - val_loss: 0.0178\n",
      "Epoch 1604/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0173\n",
      "Epoch 1605/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0137 - val_loss: 0.0169\n",
      "Epoch 1606/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0129 - val_loss: 0.0163\n",
      "Epoch 1607/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 1608/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1609/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1610/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1611/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1612/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1613/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1614/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 1615/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1616/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1617/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1618/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1619/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1620/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1621/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1622/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1623/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 1624/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1625/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1626/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1627/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1628/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1629/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1630/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1631/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1632/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1633/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1634/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1635/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 1636/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 1637/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1638/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 1639/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0145 - val_loss: 0.0161\n",
      "Epoch 1640/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 1641/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1642/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1643/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1644/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1645/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1646/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1647/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 1648/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 1649/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1650/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1651/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1652/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1653/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1654/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1655/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1656/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1657/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1658/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1659/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1660/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1661/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1662/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1663/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1664/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1665/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1666/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1667/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1668/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1669/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1670/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1671/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1672/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1673/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1674/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1675/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1676/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 1677/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1678/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1679/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1680/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1681/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1682/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1683/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1684/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1685/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1686/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1687/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 1688/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1689/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1690/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1691/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1692/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1693/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1694/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1695/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1696/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1697/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1698/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1699/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1700/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1701/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1702/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1703/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1704/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1705/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 1706/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1707/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1708/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1709/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1710/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1711/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1712/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1713/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1714/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1715/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1716/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1717/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1718/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1719/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1720/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1721/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1722/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1723/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1724/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1725/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1726/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1727/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1728/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1729/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1730/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1731/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1732/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1733/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1734/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1735/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1736/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1737/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1738/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1739/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 1740/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1741/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1742/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1743/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1744/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 1745/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1746/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1747/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1748/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1749/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1750/3000\n",
      "2572/2572 [==============================] - 0s 34us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1751/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1752/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1753/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1754/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1755/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1756/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1757/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1758/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1759/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1760/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1761/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1762/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1763/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1764/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1765/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1766/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0128 - val_loss: 0.0160\n",
      "Epoch 1767/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 1768/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1769/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1770/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1771/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1772/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1773/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 1774/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1775/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1776/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1777/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1778/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1779/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1780/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1781/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1782/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1783/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 1784/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1785/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0133 - val_loss: 0.0160\n",
      "Epoch 1786/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 1787/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1788/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1789/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1790/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1791/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1792/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1793/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1794/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1795/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1796/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1797/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1798/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1799/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1800/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1801/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1802/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1803/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1804/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1805/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1806/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1807/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1808/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1809/3000\n",
      "2572/2572 [==============================] - 0s 43us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1810/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1811/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1812/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1813/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1814/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1815/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1816/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1817/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1818/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1819/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1820/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1821/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1822/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1823/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1824/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1825/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1826/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1827/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1828/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1829/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1830/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1831/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1832/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1833/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1834/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1835/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 1836/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1837/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1838/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1839/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1840/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1841/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1842/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1843/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 1844/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 1845/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1846/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1847/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1848/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1849/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1850/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1851/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1852/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1853/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1854/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1855/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 1856/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1857/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1858/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1859/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1860/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1861/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 1862/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0127 - val_loss: 0.0164\n",
      "Epoch 1863/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0134 - val_loss: 0.0162\n",
      "Epoch 1864/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0129 - val_loss: 0.0162\n",
      "Epoch 1865/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 1866/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 1867/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0130 - val_loss: 0.0161\n",
      "Epoch 1868/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 1869/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0131 - val_loss: 0.0161\n",
      "Epoch 1870/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 1871/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1872/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 1873/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 1874/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0129 - val_loss: 0.0159\n",
      "Epoch 1875/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 1876/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 1877/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0131 - val_loss: 0.0160\n",
      "Epoch 1878/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1879/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1880/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1881/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1882/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1883/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1884/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1885/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1886/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1887/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1888/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1889/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1890/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1891/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1892/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1893/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1894/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1895/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1896/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1897/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1898/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1899/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1900/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1901/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1902/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1903/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1904/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1905/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1906/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 1907/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1908/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1909/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1910/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1911/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1912/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1913/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 1914/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 1915/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1916/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1917/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1918/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1919/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1920/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1921/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1922/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1923/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1924/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1925/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1926/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1927/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1928/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1929/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1930/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1931/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1932/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1933/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1934/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1935/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1936/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1937/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1938/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 1939/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0129 - val_loss: 0.0161\n",
      "Epoch 1940/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 1941/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0138 - val_loss: 0.0165\n",
      "Epoch 1942/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0130 - val_loss: 0.0164\n",
      "Epoch 1943/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 1944/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 1945/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 1946/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 1947/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 1948/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1949/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1950/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1951/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1952/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1953/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1954/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0128 - val_loss: 0.0157\n",
      "Epoch 1955/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1956/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1957/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1958/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 1959/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1960/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1961/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1962/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1963/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1964/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1965/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1966/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1967/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 1968/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1969/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1970/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1971/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1972/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1973/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 1974/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 1975/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1976/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1977/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 1978/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 1979/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1980/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 1981/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1982/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1983/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1984/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1985/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1986/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1987/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1988/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1989/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 1990/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 1991/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0140 - val_loss: 0.0159\n",
      "Epoch 1992/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 1993/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 1994/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 1995/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1996/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 1997/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 1998/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 1999/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2000/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2001/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2002/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2003/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2004/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2005/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2006/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2007/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2008/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2009/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2010/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2011/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2012/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2013/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2014/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2015/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2016/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2017/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2018/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2019/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2020/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2021/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2022/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2023/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2024/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2025/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2026/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2027/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2028/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2029/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2030/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2031/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2032/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2033/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2034/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2035/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2036/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2037/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2038/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2039/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2040/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2041/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2042/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2043/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2044/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2045/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2046/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2047/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2048/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2049/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2050/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2051/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2052/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2053/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2054/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2055/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2056/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2057/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2058/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2059/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2060/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2061/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2062/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2063/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2064/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 2065/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2066/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2067/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2068/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2069/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2070/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2071/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2072/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2073/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2074/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2075/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2076/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2077/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2078/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2079/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2080/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2081/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2082/3000\n",
      "2572/2572 [==============================] - 0s 34us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2083/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2084/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2085/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2086/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 2087/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2088/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2089/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2090/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2091/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2092/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2093/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2094/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2095/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2096/3000\n",
      "2572/2572 [==============================] - 0s 41us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2097/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2098/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2099/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2100/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2101/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0156\n",
      "Epoch 2102/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2103/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2104/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2105/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2106/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2107/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2108/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2109/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2110/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2111/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2112/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2113/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2114/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2115/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2116/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2117/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2118/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2119/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2120/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2121/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2122/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2123/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 2124/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2125/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2126/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2127/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2128/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 2129/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 2130/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2131/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2132/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2133/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2134/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2135/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2136/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2137/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2138/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2139/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2140/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2141/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2142/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2143/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2144/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2145/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0155\n",
      "Epoch 2146/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2147/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2148/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2149/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2150/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2151/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2152/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2153/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2154/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2155/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2156/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2157/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2158/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2159/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2160/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2161/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2162/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2163/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2164/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2165/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2166/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2167/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2168/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2169/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.009 - 0s 10us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 2170/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0128 - val_loss: 0.0163\n",
      "Epoch 2171/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 2172/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2173/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2174/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2175/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2176/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2177/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2178/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 2179/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2180/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2181/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2182/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2183/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2184/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2185/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2186/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2187/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2188/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2189/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2190/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2191/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2192/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2193/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2194/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2195/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2196/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2197/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2198/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2199/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2200/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2201/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2202/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2203/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2204/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2205/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2206/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2207/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2208/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2209/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2210/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2211/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2212/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2213/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2214/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2215/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2216/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 2217/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0138 - val_loss: 0.0159\n",
      "Epoch 2218/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 2219/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0158\n",
      "Epoch 2220/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2221/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2222/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2223/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2224/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2225/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2226/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2227/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2228/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2229/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2230/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2231/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2232/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2233/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2234/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2235/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2236/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2237/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2238/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2239/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2240/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2241/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2242/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2243/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2244/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2245/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2246/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2247/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2248/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2249/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 2250/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2251/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2252/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2253/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 2254/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2255/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2256/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2257/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2258/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2259/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2260/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2261/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2262/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2263/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2264/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2265/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0129 - val_loss: 0.0160\n",
      "Epoch 2266/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0162\n",
      "Epoch 2267/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0130 - val_loss: 0.0161\n",
      "Epoch 2268/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2269/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2270/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2271/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2272/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2273/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2274/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2275/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2276/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2277/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2278/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 2279/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 2280/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2281/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2282/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2283/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2284/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2285/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2286/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2287/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2288/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2289/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2290/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2291/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2292/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2293/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2294/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2295/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0157\n",
      "Epoch 2296/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2297/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 2298/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0159\n",
      "Epoch 2299/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 2300/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2301/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2302/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2303/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2304/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2305/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2306/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2307/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2308/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2309/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2310/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2311/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2312/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2313/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2314/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2315/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2316/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2317/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2318/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2319/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2320/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2321/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2322/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2323/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2324/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0174\n",
      "Epoch 2325/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0236 - val_loss: 0.0269\n",
      "Epoch 2326/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0224 - val_loss: 0.0227\n",
      "Epoch 2327/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0194 - val_loss: 0.0200\n",
      "Epoch 2328/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0157 - val_loss: 0.0179\n",
      "Epoch 2329/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0141 - val_loss: 0.0168\n",
      "Epoch 2330/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0163\n",
      "Epoch 2331/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0161\n",
      "Epoch 2332/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0135 - val_loss: 0.0162\n",
      "Epoch 2333/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 2334/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 2335/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 2336/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2337/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2338/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2339/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2340/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2341/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2342/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2343/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2344/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2345/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2346/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2347/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2348/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2349/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2350/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2351/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2352/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2353/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2354/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 2355/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2356/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2357/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2358/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2359/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2360/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2361/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2362/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2363/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2364/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2365/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2366/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2367/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2368/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2369/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2370/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2371/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2372/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2373/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2374/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2375/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2376/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 2377/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 2378/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2379/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2380/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2381/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2382/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2383/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2384/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2385/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2386/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2387/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2388/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2389/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2390/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2391/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2392/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2393/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2394/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2395/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2396/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2397/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2398/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2399/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2400/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2401/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2402/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2403/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2404/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2405/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2406/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2407/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 2408/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2409/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2410/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2411/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2412/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2413/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2414/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2415/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2416/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2417/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2418/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2419/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2420/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2421/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2422/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2423/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2424/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2425/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2426/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2427/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2428/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2429/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2430/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2431/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2432/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2433/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2434/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2435/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2436/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2437/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2438/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2439/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2440/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2441/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2442/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2443/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2444/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2445/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 2446/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 2447/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2448/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2449/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2450/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2451/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2452/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2453/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2454/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2455/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2456/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2457/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2458/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2459/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2460/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2461/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2462/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2463/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2464/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 2465/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 2466/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2467/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2468/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2469/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2470/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2471/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2472/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2473/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2474/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2475/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2476/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2477/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2478/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2479/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2480/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2481/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2482/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2483/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2484/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 2485/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2486/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2487/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2488/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 2489/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2490/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 2491/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2492/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2493/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2494/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2495/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2496/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2497/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2498/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2499/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2500/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2501/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2502/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2503/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2504/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2505/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2506/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2507/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2508/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2509/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2510/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2511/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2512/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2513/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2514/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2515/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2516/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2517/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2518/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2519/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2520/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2521/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2522/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2523/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2524/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2525/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 2526/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0127 - val_loss: 0.0157\n",
      "Epoch 2527/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 2528/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2529/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2530/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2531/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2532/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2533/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2534/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2535/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2536/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2537/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2538/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2539/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2540/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2541/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2542/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2543/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0156\n",
      "Epoch 2544/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2545/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2546/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2547/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2548/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2549/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2550/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2551/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 2552/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 2553/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2554/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2555/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2556/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2557/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2558/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2559/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2560/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2561/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2562/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2563/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2564/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 2565/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0159\n",
      "Epoch 2566/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 2567/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2568/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2569/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2570/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2571/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2572/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2573/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2574/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2575/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2576/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2577/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2578/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2579/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2580/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2581/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2582/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2583/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2584/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0127 - val_loss: 0.0160\n",
      "Epoch 2585/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2586/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2587/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2588/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2589/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2590/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2591/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2592/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2593/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2594/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2595/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2596/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2597/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2598/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2599/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2600/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2601/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2602/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2603/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2604/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2605/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2606/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2607/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 2608/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2609/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2610/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2611/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2612/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2613/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2614/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2615/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2616/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2617/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2618/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2619/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2620/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2621/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2622/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2623/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2624/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2625/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2626/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2627/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2628/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2629/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2630/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2631/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2632/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2633/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2634/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2635/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2636/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2637/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2638/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2639/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2640/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2641/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2642/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2643/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2644/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 2645/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0134 - val_loss: 0.0159\n",
      "Epoch 2646/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2647/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2648/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2649/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2650/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2651/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2652/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2653/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2654/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2655/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2656/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2657/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2658/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2659/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0132 - val_loss: 0.0160\n",
      "Epoch 2660/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2661/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2662/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2663/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2664/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2665/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2666/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2667/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2668/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2669/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2670/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2671/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2672/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2673/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2674/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2675/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2676/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2677/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2678/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 2679/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0146 - val_loss: 0.0168\n",
      "Epoch 2680/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0131 - val_loss: 0.0165\n",
      "Epoch 2681/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2682/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2683/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2684/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2685/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2686/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2687/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2688/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2689/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2690/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.013 - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2691/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2692/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2693/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2694/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2695/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2696/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2697/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2698/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2699/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2700/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2701/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2702/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 2703/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2704/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2705/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2706/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2707/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2708/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2709/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2710/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2711/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2712/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2713/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2714/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2715/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2716/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2717/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2718/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2719/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2720/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2721/3000\n",
      "2572/2572 [==============================] - 0s 34us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2722/3000\n",
      "2572/2572 [==============================] - 0s 40us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2723/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2724/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2725/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2726/3000\n",
      "2572/2572 [==============================] - 0s 34us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2727/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2728/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2729/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 2730/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0128 - val_loss: 0.0159\n",
      "Epoch 2731/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2732/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0160\n",
      "Epoch 2733/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2734/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2735/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2736/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0159\n",
      "Epoch 2737/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0131 - val_loss: 0.0161\n",
      "Epoch 2738/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2739/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2740/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2741/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2742/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2743/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2744/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2745/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 2746/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2747/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2748/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2749/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2750/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2751/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2752/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2753/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2754/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2755/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2756/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2757/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2758/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2759/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2760/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2761/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2762/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2763/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2764/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2765/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2766/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2767/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2768/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2769/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2770/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2771/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2772/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 2773/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2774/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2775/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2776/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 2777/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0138 - val_loss: 0.0162\n",
      "Epoch 2778/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0126 - val_loss: 0.0162\n",
      "Epoch 2779/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 2780/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2781/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2782/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2783/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2784/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2785/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2786/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2787/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2788/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2789/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2790/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2791/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2792/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2793/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2794/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2795/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 2796/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2797/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2798/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 2799/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2800/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2801/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2802/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2803/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2804/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2805/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2806/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2807/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2808/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2809/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2810/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2811/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2812/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 2813/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2814/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2815/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2816/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2817/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0156\n",
      "Epoch 2818/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2819/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2820/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2821/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2822/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2823/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2824/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2825/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2826/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2827/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2828/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 2829/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0161\n",
      "Epoch 2830/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0132 - val_loss: 0.0162\n",
      "Epoch 2831/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0158\n",
      "Epoch 2832/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2833/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2834/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2835/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2836/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2837/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2838/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2839/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2840/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2841/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2842/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2843/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2844/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2845/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2846/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2847/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2848/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2849/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2850/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2851/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0131 - val_loss: 0.0159\n",
      "Epoch 2852/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2853/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0130 - val_loss: 0.0160\n",
      "Epoch 2854/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 2855/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2856/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2857/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2858/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2859/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2860/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2861/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2862/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2863/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0158\n",
      "Epoch 2864/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2865/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2866/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2867/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 2868/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0137 - val_loss: 0.0165\n",
      "Epoch 2869/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0160\n",
      "Epoch 2870/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 2871/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 2872/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2873/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2874/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2875/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2876/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2877/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2878/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2879/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2880/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 2881/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 2882/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0141 - val_loss: 0.0162\n",
      "Epoch 2883/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0126 - val_loss: 0.0161\n",
      "Epoch 2884/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2885/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2886/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2887/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2888/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2889/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2890/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2891/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2892/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2893/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2894/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2895/3000\n",
      "2572/2572 [==============================] - 0s 8us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 2896/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2897/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2898/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2899/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0158\n",
      "Epoch 2900/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0125 - val_loss: 0.0157\n",
      "Epoch 2901/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2902/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2903/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2904/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2905/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2906/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2907/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2908/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2909/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2910/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2911/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2912/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2913/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2914/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2915/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2916/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2917/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2918/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0125 - val_loss: 0.0159\n",
      "Epoch 2919/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2920/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2921/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2922/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2923/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2924/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2925/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2926/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2927/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2928/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2929/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2930/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2931/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2932/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2933/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2934/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2935/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2936/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2937/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2938/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0159\n",
      "Epoch 2939/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0130 - val_loss: 0.0159\n",
      "Epoch 2940/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0159\n",
      "Epoch 2941/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2942/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2943/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2944/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2945/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2946/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2947/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2948/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2949/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2950/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2951/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2952/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2953/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2954/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0123 - val_loss: 0.0158\n",
      "Epoch 2955/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2956/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2957/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2958/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2959/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0155\n",
      "Epoch 2960/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2961/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2962/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2963/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2964/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2965/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0124 - val_loss: 0.0156\n",
      "Epoch 2966/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2967/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2968/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2969/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2970/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2971/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2972/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2973/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2974/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0156\n",
      "Epoch 2975/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 2976/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0123 - val_loss: 0.0157\n",
      "Epoch 2977/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2978/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2979/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2980/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2981/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2982/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2983/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2984/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2985/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2986/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0155\n",
      "Epoch 2987/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.008 - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2988/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0122 - val_loss: 0.0157\n",
      "Epoch 2989/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2990/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2991/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0124 - val_loss: 0.0157\n",
      "Epoch 2992/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2993/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2994/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 2995/3000\n",
      "2572/2572 [==============================] - 0s 9us/step - loss: 0.0121 - val_loss: 0.0157\n",
      "Epoch 2996/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0121 - val_loss: 0.0156\n",
      "Epoch 2997/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2998/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 2999/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0120 - val_loss: 0.0156\n",
      "Epoch 3000/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0121 - val_loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc940663fd0>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(X_trainAtMes, X_trainAtMes,\n",
    "                epochs=3000,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_testAtMes, X_testAtMes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz o teste de previsão\n",
    "testeAtMes = autoencoder.predict(X_testAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1103/1103 [==============================] - 0s 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015553622506558895"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erro calculado na última época com Mean Squared Error\n",
    "# Quanto maior o erro, mais tá errando\n",
    "# Erro de teste\n",
    "autoencoder.evaluate(x=X_testAtMes, y=X_testAtMes, batch_size=attest_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2572/2572 [==============================] - 0s 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.012027385644614697"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erro de treino\n",
    "autoencoder.evaluate(x=X_trainAtMes, y=X_trainAtMes, batch_size=attrain_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044667064618857"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rede com apenas uma codificação\n",
    "# Quanto mais perto de 1, mais tá acertando\n",
    "r2_score(X_testAtMes,testeAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8198394997819024"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prevê  o treino e avalia o score dele\n",
    "trainAtMes = autoencoder.predict(X_trainAtMes)\n",
    "r2_score(X_trainAtMes,trainAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>thunder</th>\n",
       "      <th>snow</th>\n",
       "      <th>minhumidity</th>\n",
       "      <th>coolingdegreedays</th>\n",
       "      <th>maxdewptm</th>\n",
       "      <th>precipi</th>\n",
       "      <th>heatingdegreedays</th>\n",
       "      <th>...</th>\n",
       "      <th>mindewptm</th>\n",
       "      <th>minpressurem</th>\n",
       "      <th>maxtempm</th>\n",
       "      <th>meanwindspdm</th>\n",
       "      <th>hail</th>\n",
       "      <th>meandewptm</th>\n",
       "      <th>precipm</th>\n",
       "      <th>meantempm</th>\n",
       "      <th>maxhumidity</th>\n",
       "      <th>mintempm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245644</td>\n",
       "      <td>-0.275220</td>\n",
       "      <td>1.272081</td>\n",
       "      <td>-0.065902</td>\n",
       "      <td>0.039278</td>\n",
       "      <td>0.426350</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.548413</td>\n",
       "      <td>0.023162</td>\n",
       "      <td>0.959711</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.420020</td>\n",
       "      <td>-0.837408</td>\n",
       "      <td>-1.362333</td>\n",
       "      <td>0.148751</td>\n",
       "      <td>-0.000795</td>\n",
       "      <td>-0.500172</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>-1.042068</td>\n",
       "      <td>0.011201</td>\n",
       "      <td>-0.438477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003988</td>\n",
       "      <td>-0.634779</td>\n",
       "      <td>-0.506471</td>\n",
       "      <td>0.028678</td>\n",
       "      <td>0.010945</td>\n",
       "      <td>-0.419390</td>\n",
       "      <td>-0.011741</td>\n",
       "      <td>-0.480459</td>\n",
       "      <td>0.060186</td>\n",
       "      <td>0.268661</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.655368</td>\n",
       "      <td>-0.249983</td>\n",
       "      <td>0.025653</td>\n",
       "      <td>0.529141</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>-0.586956</td>\n",
       "      <td>1.004745</td>\n",
       "      <td>-0.253985</td>\n",
       "      <td>-1.556186</td>\n",
       "      <td>-0.429672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733792</td>\n",
       "      <td>-0.564272</td>\n",
       "      <td>0.085164</td>\n",
       "      <td>0.322759</td>\n",
       "      <td>0.017470</td>\n",
       "      <td>-0.003484</td>\n",
       "      <td>0.009326</td>\n",
       "      <td>0.196682</td>\n",
       "      <td>0.054570</td>\n",
       "      <td>-0.102559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112737</td>\n",
       "      <td>-0.732734</td>\n",
       "      <td>0.051164</td>\n",
       "      <td>0.521949</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.098871</td>\n",
       "      <td>0.003432</td>\n",
       "      <td>0.168401</td>\n",
       "      <td>-0.437323</td>\n",
       "      <td>0.130985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622958</td>\n",
       "      <td>-0.569795</td>\n",
       "      <td>-0.173395</td>\n",
       "      <td>0.025637</td>\n",
       "      <td>0.009409</td>\n",
       "      <td>0.926808</td>\n",
       "      <td>4.453959</td>\n",
       "      <td>1.043439</td>\n",
       "      <td>0.055636</td>\n",
       "      <td>-0.432651</td>\n",
       "      <td>...</td>\n",
       "      <td>1.178005</td>\n",
       "      <td>-0.834910</td>\n",
       "      <td>0.400691</td>\n",
       "      <td>0.315885</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>1.206024</td>\n",
       "      <td>0.303754</td>\n",
       "      <td>1.049448</td>\n",
       "      <td>-0.172797</td>\n",
       "      <td>1.172112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021076</td>\n",
       "      <td>0.387179</td>\n",
       "      <td>-0.003960</td>\n",
       "      <td>-0.034215</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>-0.501356</td>\n",
       "      <td>-0.009419</td>\n",
       "      <td>-0.476174</td>\n",
       "      <td>0.009951</td>\n",
       "      <td>0.714195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647896</td>\n",
       "      <td>0.286738</td>\n",
       "      <td>-0.156638</td>\n",
       "      <td>-0.696429</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>-0.590663</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>-0.756967</td>\n",
       "      <td>0.414724</td>\n",
       "      <td>-1.018936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       date       lat       lng   thunder      snow  minhumidity  \\\n",
       "0  0.245644 -0.275220  1.272081 -0.065902  0.039278     0.426350   \n",
       "1  0.003988 -0.634779 -0.506471  0.028678  0.010945    -0.419390   \n",
       "2  0.733792 -0.564272  0.085164  0.322759  0.017470    -0.003484   \n",
       "3  0.622958 -0.569795 -0.173395  0.025637  0.009409     0.926808   \n",
       "4  0.021076  0.387179 -0.003960 -0.034215  0.013546    -0.501356   \n",
       "\n",
       "   coolingdegreedays  maxdewptm   precipi  heatingdegreedays    ...     \\\n",
       "0          -0.000301  -0.548413  0.023162           0.959711    ...      \n",
       "1          -0.011741  -0.480459  0.060186           0.268661    ...      \n",
       "2           0.009326   0.196682  0.054570          -0.102559    ...      \n",
       "3           4.453959   1.043439  0.055636          -0.432651    ...      \n",
       "4          -0.009419  -0.476174  0.009951           0.714195    ...      \n",
       "\n",
       "   mindewptm  minpressurem  maxtempm  meanwindspdm      hail  meandewptm  \\\n",
       "0  -0.420020     -0.837408 -1.362333      0.148751 -0.000795   -0.500172   \n",
       "1  -0.655368     -0.249983  0.025653      0.529141  0.002176   -0.586956   \n",
       "2  -0.112737     -0.732734  0.051164      0.521949  0.008938    0.098871   \n",
       "3   1.178005     -0.834910  0.400691      0.315885 -0.000939    1.206024   \n",
       "4  -0.647896      0.286738 -0.156638     -0.696429  0.000920   -0.590663   \n",
       "\n",
       "    precipm  meantempm  maxhumidity  mintempm  \n",
       "0  0.004112  -1.042068     0.011201 -0.438477  \n",
       "1  1.004745  -0.253985    -1.556186 -0.429672  \n",
       "2  0.003432   0.168401    -0.437323  0.130985  \n",
       "3  0.303754   1.049448    -0.172797  1.172112  \n",
       "4  0.003162  -0.756967     0.414724 -1.018936  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeAtMes = pd.DataFrame(testeAtMes, columns=df_atmes.columns)\n",
    "testeAtMes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lng</th>\n",
       "      <th>thunder</th>\n",
       "      <th>snow</th>\n",
       "      <th>minhumidity</th>\n",
       "      <th>coolingdegreedays</th>\n",
       "      <th>maxdewptm</th>\n",
       "      <th>precipi</th>\n",
       "      <th>heatingdegreedays</th>\n",
       "      <th>...</th>\n",
       "      <th>mindewptm</th>\n",
       "      <th>minpressurem</th>\n",
       "      <th>maxtempm</th>\n",
       "      <th>meanwindspdm</th>\n",
       "      <th>hail</th>\n",
       "      <th>meandewptm</th>\n",
       "      <th>precipm</th>\n",
       "      <th>meantempm</th>\n",
       "      <th>maxhumidity</th>\n",
       "      <th>mintempm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>0.245304</td>\n",
       "      <td>-0.278542</td>\n",
       "      <td>1.264369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387243</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>-0.850316</td>\n",
       "      <td>-1.285714</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.956644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>-0.003458</td>\n",
       "      <td>-0.622581</td>\n",
       "      <td>-0.491313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.497373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.225316</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.289977</td>\n",
       "      <td>-1.615385</td>\n",
       "      <td>-0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2868</th>\n",
       "      <td>0.744022</td>\n",
       "      <td>-0.552208</td>\n",
       "      <td>0.081357</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>-0.725316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.210023</td>\n",
       "      <td>-0.384615</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2754</th>\n",
       "      <td>0.620761</td>\n",
       "      <td>-0.577880</td>\n",
       "      <td>-0.211106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.964166</td>\n",
       "      <td>4.453582</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>-0.850316</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.125</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.043356</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>1.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1691</th>\n",
       "      <td>-0.002214</td>\n",
       "      <td>0.377419</td>\n",
       "      <td>-0.004966</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.458911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.274684</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.789977</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>-1.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date       lat       lng  thunder  snow  minhumidity  \\\n",
       "2127  0.245304 -0.278542  1.264369      0.0   0.0     0.387243   \n",
       "1744 -0.003458 -0.622581 -0.491313      0.0   0.0    -0.497373   \n",
       "2868  0.744022 -0.552208  0.081357      1.0   0.0     0.118012   \n",
       "2754  0.620761 -0.577880 -0.211106      0.0   0.0     0.964166   \n",
       "1691 -0.002214  0.377419 -0.004966      0.0   0.0    -0.458911   \n",
       "\n",
       "      coolingdegreedays  maxdewptm  precipi  heatingdegreedays    ...     \\\n",
       "2127           0.000000     -0.750     0.00           1.000000    ...      \n",
       "1744           0.000000      0.000     0.04           0.166667    ...      \n",
       "2868           0.000000      0.375     0.00          -0.083333    ...      \n",
       "2754           4.453582      0.875     0.01          -0.500000    ...      \n",
       "1691           0.000000     -0.625     0.00           0.750000    ...      \n",
       "\n",
       "      mindewptm  minpressurem  maxtempm  meanwindspdm  hail  meandewptm  \\\n",
       "2127  -0.333333     -0.850316 -1.285714      0.166667   0.0      -0.500   \n",
       "1744  -1.000000     -0.225316 -0.142857      0.500000   0.0      -0.625   \n",
       "2868  -0.444444     -0.725316  0.000000      0.500000   0.0       0.125   \n",
       "2754   1.333333     -0.850316  0.428571      0.333333   0.0       1.125   \n",
       "1691  -0.333333      0.274684 -0.142857     -0.666667   0.0      -0.375   \n",
       "\n",
       "      precipm  meantempm  maxhumidity  mintempm  \n",
       "2127      0.0  -0.956644     0.000000    -0.375  \n",
       "1744      1.0  -0.289977    -1.615385    -0.375  \n",
       "2868      0.0   0.210023    -0.384615     0.250  \n",
       "2754      0.3   1.043356    -0.153846     1.125  \n",
       "1691      0.0  -0.789977     0.461538    -1.125  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testAtMes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coolingdegreedays': 0.9999269731709931,\n",
       " 'date': 0.9986667962274225,\n",
       " 'fog': 0.1270759376283358,\n",
       " 'gdegreedays': 0.9211796539804357,\n",
       " 'hail': -0.005605254812757643,\n",
       " 'heatingdegreedays': 0.9898163598771823,\n",
       " 'humidity': 0.9529698741210683,\n",
       " 'lat': 0.9998399690193895,\n",
       " 'lng': 0.9998359919305521,\n",
       " 'maxdewptm': 0.9366040776092434,\n",
       " 'maxhumidity': 0.9943205367971075,\n",
       " 'maxtempm': 0.992513997305577,\n",
       " 'meandewptm': 0.9833114234740389,\n",
       " 'meantempm': 0.9915144872675549,\n",
       " 'meanwindspdm': 0.9993288468096453,\n",
       " 'mindewptm': 0.9332439274198382,\n",
       " 'minhumidity': 0.9627545026303552,\n",
       " 'minpressurem': 0.9991588471333094,\n",
       " 'mintempm': 0.9910367081255648,\n",
       " 'precipi': 0.2700097090449586,\n",
       " 'precipm': 0.9999702741084848,\n",
       " 'rain': 0.9721542488518896,\n",
       " 'snow': 0.027996854314250696,\n",
       " 'thunder': 0.2695762130508207}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = {}\n",
    "for c in testeAtMes.columns:\n",
    "    score[c] = r2_score(X_testAtMes[c],testeAtMes[c])\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atmess.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cinput_dim = len(df_atmess.columns)\n",
    "cinput_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede com somente uma camada escondida para a base em C\n",
    "cencoding_dim1 = 17\n",
    "centrada = Input(shape=(cinput_dim,))\n",
    "cencoded1 = Dense(cencoding_dim1,activation=\"relu\")(centrada)\n",
    "cdecoded2 = Dense(cinput_dim,activation=\"linear\")(cencoded1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cautoencoder = Model(centrada,cdecoded2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "cautoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "cX_trainAtMes, cX_testAtMes = train_test_split(df_atmess, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2572 samples, validate on 1103 samples\n",
      "Epoch 1/3000\n",
      "2572/2572 [==============================] - 0s 154us/step - loss: 2.3681 - val_loss: 2.0785\n",
      "Epoch 2/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 2.1582 - val_loss: 1.9041\n",
      "Epoch 3/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 1.9908 - val_loss: 1.7620\n",
      "Epoch 4/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.8498 - val_loss: 1.6454\n",
      "Epoch 5/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.7233 - val_loss: 1.5439\n",
      "Epoch 6/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 1.6284 - val_loss: 1.4532\n",
      "Epoch 7/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.5367 - val_loss: 1.3744\n",
      "Epoch 8/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 1.4526 - val_loss: 1.3004\n",
      "Epoch 9/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 1.3735 - val_loss: 1.2283\n",
      "Epoch 10/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.2961 - val_loss: 1.1605\n",
      "Epoch 11/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.2273 - val_loss: 1.0864\n",
      "Epoch 12/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 1.1455 - val_loss: 1.0247\n",
      "Epoch 13/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 1.0851 - val_loss: 0.9677\n",
      "Epoch 14/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 1.0224 - val_loss: 0.9174\n",
      "Epoch 15/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.9706 - val_loss: 0.8661\n",
      "Epoch 16/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.9171 - val_loss: 0.8184\n",
      "Epoch 17/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.8649 - val_loss: 0.7739\n",
      "Epoch 18/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.8188 - val_loss: 0.7308\n",
      "Epoch 19/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.7759 - val_loss: 0.6883\n",
      "Epoch 20/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.7267 - val_loss: 0.6492\n",
      "Epoch 21/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.6807 - val_loss: 0.6073\n",
      "Epoch 22/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.6334 - val_loss: 0.5709\n",
      "Epoch 23/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.5941 - val_loss: 0.5355\n",
      "Epoch 24/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.5551 - val_loss: 0.5008\n",
      "Epoch 25/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.5186 - val_loss: 0.4717\n",
      "Epoch 26/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.4852 - val_loss: 0.4449\n",
      "Epoch 27/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.4540 - val_loss: 0.4220\n",
      "Epoch 28/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.4293 - val_loss: 0.3974\n",
      "Epoch 29/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.4009 - val_loss: 0.3757\n",
      "Epoch 30/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.3794 - val_loss: 0.3544\n",
      "Epoch 31/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.3569 - val_loss: 0.3351\n",
      "Epoch 32/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.3332 - val_loss: 0.3191\n",
      "Epoch 33/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.3165 - val_loss: 0.3031\n",
      "Epoch 34/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.2998 - val_loss: 0.2880\n",
      "Epoch 35/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.2824 - val_loss: 0.2748\n",
      "Epoch 36/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.2682 - val_loss: 0.2618\n",
      "Epoch 37/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2544 - val_loss: 0.2498\n",
      "Epoch 38/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.2409 - val_loss: 0.2369\n",
      "Epoch 39/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2287 - val_loss: 0.2262\n",
      "Epoch 40/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.2176 - val_loss: 0.2176\n",
      "Epoch 41/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2088 - val_loss: 0.2101\n",
      "Epoch 42/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.2016 - val_loss: 0.2028\n",
      "Epoch 43/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1932 - val_loss: 0.1959\n",
      "Epoch 44/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1863 - val_loss: 0.1895\n",
      "Epoch 45/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1800 - val_loss: 0.1834\n",
      "Epoch 46/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.1743 - val_loss: 0.1788\n",
      "Epoch 47/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1694 - val_loss: 0.1732\n",
      "Epoch 48/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1647 - val_loss: 0.1693\n",
      "Epoch 49/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1603 - val_loss: 0.1634\n",
      "Epoch 50/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1546 - val_loss: 0.1593\n",
      "Epoch 51/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1504 - val_loss: 0.1548\n",
      "Epoch 52/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1458 - val_loss: 0.1509\n",
      "Epoch 53/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1423 - val_loss: 0.1481\n",
      "Epoch 54/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1387 - val_loss: 0.1442\n",
      "Epoch 55/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1349 - val_loss: 0.1408\n",
      "Epoch 56/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1315 - val_loss: 0.1373\n",
      "Epoch 57/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1283 - val_loss: 0.1345\n",
      "Epoch 58/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1255 - val_loss: 0.1314\n",
      "Epoch 59/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1222 - val_loss: 0.1284\n",
      "Epoch 60/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.1195 - val_loss: 0.1257\n",
      "Epoch 61/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1167 - val_loss: 0.1232\n",
      "Epoch 62/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1142 - val_loss: 0.1207\n",
      "Epoch 63/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1119 - val_loss: 0.1185\n",
      "Epoch 64/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1096 - val_loss: 0.1160\n",
      "Epoch 65/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1073 - val_loss: 0.1138\n",
      "Epoch 66/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.1051 - val_loss: 0.1117\n",
      "Epoch 67/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1029 - val_loss: 0.1095\n",
      "Epoch 68/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.1008 - val_loss: 0.1077\n",
      "Epoch 69/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0992 - val_loss: 0.1055\n",
      "Epoch 70/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0970 - val_loss: 0.1034\n",
      "Epoch 71/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0949 - val_loss: 0.1017\n",
      "Epoch 72/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0932 - val_loss: 0.1001\n",
      "Epoch 73/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0916 - val_loss: 0.0983\n",
      "Epoch 74/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0899 - val_loss: 0.0968\n",
      "Epoch 75/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0883 - val_loss: 0.0952\n",
      "Epoch 76/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0868 - val_loss: 0.0937\n",
      "Epoch 77/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0853 - val_loss: 0.0923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0844 - val_loss: 0.0915\n",
      "Epoch 79/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0831 - val_loss: 0.0899\n",
      "Epoch 80/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0818 - val_loss: 0.0881\n",
      "Epoch 81/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0802 - val_loss: 0.0870\n",
      "Epoch 82/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0789 - val_loss: 0.0859\n",
      "Epoch 83/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0776 - val_loss: 0.0847\n",
      "Epoch 84/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0765 - val_loss: 0.0836\n",
      "Epoch 85/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0754 - val_loss: 0.0823\n",
      "Epoch 86/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0743 - val_loss: 0.0814\n",
      "Epoch 87/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0737 - val_loss: 0.0808\n",
      "Epoch 88/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0726 - val_loss: 0.0796\n",
      "Epoch 89/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0714 - val_loss: 0.0784\n",
      "Epoch 90/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0704 - val_loss: 0.0775\n",
      "Epoch 91/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0694 - val_loss: 0.0765\n",
      "Epoch 92/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0685 - val_loss: 0.0756\n",
      "Epoch 93/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0679 - val_loss: 0.0750\n",
      "Epoch 94/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0676 - val_loss: 0.0742\n",
      "Epoch 95/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0664 - val_loss: 0.0735\n",
      "Epoch 96/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0660 - val_loss: 0.0730\n",
      "Epoch 97/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0657 - val_loss: 0.0727\n",
      "Epoch 98/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0643 - val_loss: 0.0706\n",
      "Epoch 99/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0630 - val_loss: 0.0700\n",
      "Epoch 100/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0620 - val_loss: 0.0690\n",
      "Epoch 101/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0612 - val_loss: 0.0683\n",
      "Epoch 102/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0604 - val_loss: 0.0674\n",
      "Epoch 103/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0600 - val_loss: 0.0669\n",
      "Epoch 104/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0592 - val_loss: 0.0660\n",
      "Epoch 105/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0588 - val_loss: 0.0658\n",
      "Epoch 106/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0580 - val_loss: 0.0649\n",
      "Epoch 107/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0571 - val_loss: 0.0640\n",
      "Epoch 108/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0564 - val_loss: 0.0633\n",
      "Epoch 109/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0558 - val_loss: 0.0629\n",
      "Epoch 110/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0588 - val_loss: 0.0668\n",
      "Epoch 111/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0583 - val_loss: 0.0619\n",
      "Epoch 112/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0550 - val_loss: 0.0614\n",
      "Epoch 113/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0539 - val_loss: 0.0603\n",
      "Epoch 114/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0529 - val_loss: 0.0594\n",
      "Epoch 115/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0522 - val_loss: 0.0588\n",
      "Epoch 116/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0516 - val_loss: 0.0582\n",
      "Epoch 117/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0510 - val_loss: 0.0577\n",
      "Epoch 118/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0506 - val_loss: 0.0574\n",
      "Epoch 119/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0501 - val_loss: 0.0568\n",
      "Epoch 120/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0495 - val_loss: 0.0563\n",
      "Epoch 121/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0490 - val_loss: 0.0558\n",
      "Epoch 122/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0485 - val_loss: 0.0552\n",
      "Epoch 123/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0480 - val_loss: 0.0547\n",
      "Epoch 124/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0479 - val_loss: 0.0550\n",
      "Epoch 125/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0479 - val_loss: 0.0544\n",
      "Epoch 126/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0473 - val_loss: 0.0540\n",
      "Epoch 127/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0465 - val_loss: 0.0528\n",
      "Epoch 128/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0460 - val_loss: 0.0526\n",
      "Epoch 129/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0452 - val_loss: 0.0518\n",
      "Epoch 130/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0449 - val_loss: 0.0515\n",
      "Epoch 131/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0458 - val_loss: 0.0518\n",
      "Epoch 132/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0443 - val_loss: 0.0510\n",
      "Epoch 133/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0435 - val_loss: 0.0499\n",
      "Epoch 134/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0429 - val_loss: 0.0494\n",
      "Epoch 135/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0424 - val_loss: 0.0490\n",
      "Epoch 136/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0420 - val_loss: 0.0486\n",
      "Epoch 137/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0416 - val_loss: 0.0482\n",
      "Epoch 138/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0412 - val_loss: 0.0477\n",
      "Epoch 139/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0408 - val_loss: 0.0474\n",
      "Epoch 140/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0405 - val_loss: 0.0470\n",
      "Epoch 141/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0404 - val_loss: 0.0469\n",
      "Epoch 142/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0400 - val_loss: 0.0464\n",
      "Epoch 143/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0396 - val_loss: 0.0460\n",
      "Epoch 144/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0392 - val_loss: 0.0457\n",
      "Epoch 145/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0390 - val_loss: 0.0452\n",
      "Epoch 146/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0384 - val_loss: 0.0448\n",
      "Epoch 147/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0380 - val_loss: 0.0444\n",
      "Epoch 148/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0376 - val_loss: 0.0440\n",
      "Epoch 149/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0374 - val_loss: 0.0437\n",
      "Epoch 150/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0375 - val_loss: 0.0436\n",
      "Epoch 151/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0369 - val_loss: 0.0431\n",
      "Epoch 152/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0366 - val_loss: 0.0427\n",
      "Epoch 153/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0361 - val_loss: 0.0422\n",
      "Epoch 154/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0357 - val_loss: 0.0419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0352 - val_loss: 0.0415\n",
      "Epoch 156/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0351 - val_loss: 0.0414\n",
      "Epoch 157/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0368 - val_loss: 0.0427\n",
      "Epoch 158/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0354 - val_loss: 0.0414\n",
      "Epoch 159/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0353 - val_loss: 0.0407\n",
      "Epoch 160/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0341 - val_loss: 0.0404\n",
      "Epoch 161/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0336 - val_loss: 0.0396\n",
      "Epoch 162/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0333 - val_loss: 0.0395\n",
      "Epoch 163/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0330 - val_loss: 0.0391\n",
      "Epoch 164/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0335 - val_loss: 0.0390\n",
      "Epoch 165/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0329 - val_loss: 0.0388\n",
      "Epoch 166/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0323 - val_loss: 0.0381\n",
      "Epoch 167/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0318 - val_loss: 0.0379\n",
      "Epoch 168/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0332 - val_loss: 0.0379\n",
      "Epoch 169/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0319 - val_loss: 0.0376\n",
      "Epoch 170/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0324 - val_loss: 0.0378\n",
      "Epoch 171/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0312 - val_loss: 0.0372\n",
      "Epoch 172/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0308 - val_loss: 0.0362\n",
      "Epoch 173/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0301 - val_loss: 0.0358\n",
      "Epoch 174/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0298 - val_loss: 0.0356\n",
      "Epoch 175/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0295 - val_loss: 0.0353\n",
      "Epoch 176/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0293 - val_loss: 0.0350\n",
      "Epoch 177/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0291 - val_loss: 0.0348\n",
      "Epoch 178/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0288 - val_loss: 0.0346\n",
      "Epoch 179/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0286 - val_loss: 0.0343\n",
      "Epoch 180/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0283 - val_loss: 0.0341\n",
      "Epoch 181/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0280 - val_loss: 0.0338\n",
      "Epoch 182/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0280 - val_loss: 0.0337\n",
      "Epoch 183/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0283 - val_loss: 0.0337\n",
      "Epoch 184/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0278 - val_loss: 0.0336\n",
      "Epoch 185/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0281 - val_loss: 0.0333\n",
      "Epoch 186/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0279 - val_loss: 0.0331\n",
      "Epoch 187/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0273 - val_loss: 0.0327\n",
      "Epoch 188/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0273 - val_loss: 0.0325\n",
      "Epoch 189/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0270 - val_loss: 0.0323\n",
      "Epoch 190/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0264 - val_loss: 0.0320\n",
      "Epoch 191/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0264 - val_loss: 0.0317\n",
      "Epoch 192/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0259 - val_loss: 0.0314\n",
      "Epoch 193/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0261 - val_loss: 0.0315\n",
      "Epoch 194/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0258 - val_loss: 0.0310\n",
      "Epoch 195/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0255 - val_loss: 0.0308\n",
      "Epoch 196/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0252 - val_loss: 0.0306\n",
      "Epoch 197/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0248 - val_loss: 0.0303\n",
      "Epoch 198/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0247 - val_loss: 0.0301\n",
      "Epoch 199/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0244 - val_loss: 0.0302\n",
      "Epoch 200/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0254 - val_loss: 0.0304\n",
      "Epoch 201/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0246 - val_loss: 0.0298\n",
      "Epoch 202/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0241 - val_loss: 0.0295\n",
      "Epoch 203/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0240 - val_loss: 0.0301\n",
      "Epoch 204/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0290 - val_loss: 0.0327\n",
      "Epoch 205/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0261 - val_loss: 0.0319\n",
      "Epoch 206/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0249 - val_loss: 0.0304\n",
      "Epoch 207/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0242 - val_loss: 0.0300\n",
      "Epoch 208/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0239 - val_loss: 0.0296\n",
      "Epoch 209/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0234 - val_loss: 0.0293\n",
      "Epoch 210/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0234 - val_loss: 0.0291\n",
      "Epoch 211/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0229 - val_loss: 0.0287\n",
      "Epoch 212/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0226 - val_loss: 0.0284\n",
      "Epoch 213/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0224 - val_loss: 0.0282\n",
      "Epoch 214/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0223 - val_loss: 0.0280\n",
      "Epoch 215/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0222 - val_loss: 0.0278\n",
      "Epoch 216/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0219 - val_loss: 0.0275\n",
      "Epoch 217/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0217 - val_loss: 0.0275\n",
      "Epoch 218/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0216 - val_loss: 0.0272\n",
      "Epoch 219/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0215 - val_loss: 0.0271\n",
      "Epoch 220/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0214 - val_loss: 0.0270\n",
      "Epoch 221/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0212 - val_loss: 0.0267\n",
      "Epoch 222/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0211 - val_loss: 0.0266\n",
      "Epoch 223/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0210 - val_loss: 0.0265\n",
      "Epoch 224/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0209 - val_loss: 0.0264\n",
      "Epoch 225/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0208 - val_loss: 0.0262\n",
      "Epoch 226/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0208 - val_loss: 0.0261\n",
      "Epoch 227/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0205 - val_loss: 0.0260\n",
      "Epoch 228/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0204 - val_loss: 0.0258\n",
      "Epoch 229/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0202 - val_loss: 0.0256\n",
      "Epoch 230/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0202 - val_loss: 0.0255\n",
      "Epoch 231/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0202 - val_loss: 0.0253\n",
      "Epoch 232/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0202 - val_loss: 0.0255\n",
      "Epoch 233/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0199 - val_loss: 0.0251\n",
      "Epoch 234/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0197 - val_loss: 0.0250\n",
      "Epoch 235/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0195 - val_loss: 0.0248\n",
      "Epoch 236/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0196 - val_loss: 0.0248\n",
      "Epoch 237/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0197 - val_loss: 0.0247\n",
      "Epoch 238/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0193 - val_loss: 0.0246\n",
      "Epoch 239/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0198 - val_loss: 0.0245\n",
      "Epoch 240/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0191 - val_loss: 0.0243\n",
      "Epoch 241/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0193 - val_loss: 0.0241\n",
      "Epoch 242/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0188 - val_loss: 0.0240\n",
      "Epoch 243/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0188 - val_loss: 0.0239\n",
      "Epoch 244/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0185 - val_loss: 0.0237\n",
      "Epoch 245/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0186 - val_loss: 0.0238\n",
      "Epoch 246/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0194 - val_loss: 0.0237\n",
      "Epoch 247/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0187 - val_loss: 0.0236\n",
      "Epoch 248/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0182 - val_loss: 0.0233\n",
      "Epoch 249/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0181 - val_loss: 0.0231\n",
      "Epoch 250/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.014 - 0s 24us/step - loss: 0.0179 - val_loss: 0.0230\n",
      "Epoch 251/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0178 - val_loss: 0.0229\n",
      "Epoch 252/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0180 - val_loss: 0.0229\n",
      "Epoch 253/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0179 - val_loss: 0.0228\n",
      "Epoch 254/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0177 - val_loss: 0.0227\n",
      "Epoch 255/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0176 - val_loss: 0.0225\n",
      "Epoch 256/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0176 - val_loss: 0.0224\n",
      "Epoch 257/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0173 - val_loss: 0.0223\n",
      "Epoch 258/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0172 - val_loss: 0.0222\n",
      "Epoch 259/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0172 - val_loss: 0.0220\n",
      "Epoch 260/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0170 - val_loss: 0.0220\n",
      "Epoch 261/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0170 - val_loss: 0.0219\n",
      "Epoch 262/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 263/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0173 - val_loss: 0.0218\n",
      "Epoch 264/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0169 - val_loss: 0.0217\n",
      "Epoch 265/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0215\n",
      "Epoch 266/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0166 - val_loss: 0.0215\n",
      "Epoch 267/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0168 - val_loss: 0.0213\n",
      "Epoch 268/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0163 - val_loss: 0.0212\n",
      "Epoch 269/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 270/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0161 - val_loss: 0.0210\n",
      "Epoch 271/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0160 - val_loss: 0.0209\n",
      "Epoch 272/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0160 - val_loss: 0.0210\n",
      "Epoch 273/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0176 - val_loss: 0.0214\n",
      "Epoch 274/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0166 - val_loss: 0.0210\n",
      "Epoch 275/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0162 - val_loss: 0.0206\n",
      "Epoch 276/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0158 - val_loss: 0.0204\n",
      "Epoch 277/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0156 - val_loss: 0.0203\n",
      "Epoch 278/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 279/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0155 - val_loss: 0.0202\n",
      "Epoch 280/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0154 - val_loss: 0.0201\n",
      "Epoch 281/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0153 - val_loss: 0.0199\n",
      "Epoch 282/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0152 - val_loss: 0.0199\n",
      "Epoch 283/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0152 - val_loss: 0.0198\n",
      "Epoch 284/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0153 - val_loss: 0.0197\n",
      "Epoch 285/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0151 - val_loss: 0.0197\n",
      "Epoch 286/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0151 - val_loss: 0.0195\n",
      "Epoch 287/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0151 - val_loss: 0.0196\n",
      "Epoch 288/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0155 - val_loss: 0.0195\n",
      "Epoch 289/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0151 - val_loss: 0.0194\n",
      "Epoch 290/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0149 - val_loss: 0.0193\n",
      "Epoch 291/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0147 - val_loss: 0.0192\n",
      "Epoch 292/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0146 - val_loss: 0.0191\n",
      "Epoch 293/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0146 - val_loss: 0.0190\n",
      "Epoch 294/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0145 - val_loss: 0.0190\n",
      "Epoch 295/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0147 - val_loss: 0.0190\n",
      "Epoch 296/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0145 - val_loss: 0.0188\n",
      "Epoch 297/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0143 - val_loss: 0.0187\n",
      "Epoch 298/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0142 - val_loss: 0.0186\n",
      "Epoch 299/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0146 - val_loss: 0.0186\n",
      "Epoch 300/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0142 - val_loss: 0.0185\n",
      "Epoch 301/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0140 - val_loss: 0.0184\n",
      "Epoch 302/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0140 - val_loss: 0.0183\n",
      "Epoch 303/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0139 - val_loss: 0.0183\n",
      "Epoch 304/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0139 - val_loss: 0.0182\n",
      "Epoch 305/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0138 - val_loss: 0.0182\n",
      "Epoch 306/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0138 - val_loss: 0.0181\n",
      "Epoch 307/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0137 - val_loss: 0.0181\n",
      "Epoch 308/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0137 - val_loss: 0.0179\n",
      "Epoch 309/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 310/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0136 - val_loss: 0.0179\n",
      "Epoch 311/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0136 - val_loss: 0.0178\n",
      "Epoch 312/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0134 - val_loss: 0.0177\n",
      "Epoch 313/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 314/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 315/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 316/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0133 - val_loss: 0.0176\n",
      "Epoch 317/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0134 - val_loss: 0.0176\n",
      "Epoch 318/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0133 - val_loss: 0.0173\n",
      "Epoch 319/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 320/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0130 - val_loss: 0.0172\n",
      "Epoch 321/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0130 - val_loss: 0.0171\n",
      "Epoch 322/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0131 - val_loss: 0.0173\n",
      "Epoch 323/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0130 - val_loss: 0.0171\n",
      "Epoch 324/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0129 - val_loss: 0.0170\n",
      "Epoch 325/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0132 - val_loss: 0.0171\n",
      "Epoch 326/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0131 - val_loss: 0.0171\n",
      "Epoch 327/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0131 - val_loss: 0.0170\n",
      "Epoch 328/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0128 - val_loss: 0.0169\n",
      "Epoch 329/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0127 - val_loss: 0.0167\n",
      "Epoch 330/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0126 - val_loss: 0.0172\n",
      "Epoch 331/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0156 - val_loss: 0.0175\n",
      "Epoch 332/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0134 - val_loss: 0.0171\n",
      "Epoch 333/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0128 - val_loss: 0.0169\n",
      "Epoch 334/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0135 - val_loss: 0.0172\n",
      "Epoch 335/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0139 - val_loss: 0.0171\n",
      "Epoch 336/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0130 - val_loss: 0.0166\n",
      "Epoch 337/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0125 - val_loss: 0.0164\n",
      "Epoch 338/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0124 - val_loss: 0.0163\n",
      "Epoch 339/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 340/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0162\n",
      "Epoch 341/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0161\n",
      "Epoch 342/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0124 - val_loss: 0.0160\n",
      "Epoch 343/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0160\n",
      "Epoch 344/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 345/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0121 - val_loss: 0.0160\n",
      "Epoch 346/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0159\n",
      "Epoch 347/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0158\n",
      "Epoch 348/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0119 - val_loss: 0.0158\n",
      "Epoch 349/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0120 - val_loss: 0.0158\n",
      "Epoch 350/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 351/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0119 - val_loss: 0.0157\n",
      "Epoch 352/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0119 - val_loss: 0.0157\n",
      "Epoch 353/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0119 - val_loss: 0.0156\n",
      "Epoch 354/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0118 - val_loss: 0.0156\n",
      "Epoch 355/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0117 - val_loss: 0.0155\n",
      "Epoch 356/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 357/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0117 - val_loss: 0.0156\n",
      "Epoch 358/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0157\n",
      "Epoch 359/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0119 - val_loss: 0.0154\n",
      "Epoch 360/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0116 - val_loss: 0.0160\n",
      "Epoch 361/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0147 - val_loss: 0.0165\n",
      "Epoch 362/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0127 - val_loss: 0.0158\n",
      "Epoch 363/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0119 - val_loss: 0.0155\n",
      "Epoch 364/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0116 - val_loss: 0.0154\n",
      "Epoch 365/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 366/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0117 - val_loss: 0.0152\n",
      "Epoch 367/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0115 - val_loss: 0.0156\n",
      "Epoch 368/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0142 - val_loss: 0.0162\n",
      "Epoch 369/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0128 - val_loss: 0.0158\n",
      "Epoch 370/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0121 - val_loss: 0.0152\n",
      "Epoch 371/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0113 - val_loss: 0.0150\n",
      "Epoch 372/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 373/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 374/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0112 - val_loss: 0.0148\n",
      "Epoch 375/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0111 - val_loss: 0.0148\n",
      "Epoch 376/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0116 - val_loss: 0.0149\n",
      "Epoch 377/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0112 - val_loss: 0.0147\n",
      "Epoch 378/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0110 - val_loss: 0.0146\n",
      "Epoch 379/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0110 - val_loss: 0.0145\n",
      "Epoch 380/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0109 - val_loss: 0.0146\n",
      "Epoch 381/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 382/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 383/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0108 - val_loss: 0.0144\n",
      "Epoch 384/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0109 - val_loss: 0.0144\n",
      "Epoch 385/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0108 - val_loss: 0.0144\n",
      "Epoch 386/3000\n",
      "2572/2572 [==============================] - 0s 35us/step - loss: 0.0108 - val_loss: 0.0143\n",
      "Epoch 387/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 388/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 389/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0109 - val_loss: 0.0143\n",
      "Epoch 390/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0109 - val_loss: 0.0143\n",
      "Epoch 391/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 392/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0109 - val_loss: 0.0142\n",
      "Epoch 393/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 394/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 395/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0105 - val_loss: 0.0140\n",
      "Epoch 396/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 397/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 398/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0105 - val_loss: 0.0140\n",
      "Epoch 399/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 400/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0122 - val_loss: 0.0148\n",
      "Epoch 401/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0113 - val_loss: 0.0146\n",
      "Epoch 402/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0109 - val_loss: 0.0143\n",
      "Epoch 403/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0107 - val_loss: 0.0142\n",
      "Epoch 404/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 405/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 406/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 407/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0140\n",
      "Epoch 408/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0108 - val_loss: 0.0139\n",
      "Epoch 409/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 410/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 411/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 412/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 413/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 414/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0103 - val_loss: 0.0137\n",
      "Epoch 415/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0104 - val_loss: 0.0137\n",
      "Epoch 416/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0102 - val_loss: 0.0136\n",
      "Epoch 417/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0102 - val_loss: 0.0135\n",
      "Epoch 418/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 419/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0101 - val_loss: 0.0135\n",
      "Epoch 420/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 421/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0101 - val_loss: 0.0134\n",
      "Epoch 422/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0100 - val_loss: 0.0134\n",
      "Epoch 423/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 424/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 425/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 426/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 427/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 428/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 429/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 430/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 431/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0099 - val_loss: 0.0132\n",
      "Epoch 432/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 433/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 0.0131\n",
      "Epoch 434/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 435/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 436/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0098 - val_loss: 0.0130\n",
      "Epoch 437/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0097 - val_loss: 0.0129\n",
      "Epoch 438/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 439/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 440/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 441/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 442/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0097 - val_loss: 0.0130\n",
      "Epoch 443/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 444/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0096 - val_loss: 0.0129\n",
      "Epoch 445/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 0.0129\n",
      "Epoch 446/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 447/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 448/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 449/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 450/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 451/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0096 - val_loss: 0.0128\n",
      "Epoch 452/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0096 - val_loss: 0.0127\n",
      "Epoch 453/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0094 - val_loss: 0.0131\n",
      "Epoch 454/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 455/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 456/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 457/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0095 - val_loss: 0.0126\n",
      "Epoch 458/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0094 - val_loss: 0.0125\n",
      "Epoch 459/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0093 - val_loss: 0.0126\n",
      "Epoch 460/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 461/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0135 - val_loss: 0.0144\n",
      "Epoch 462/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 463/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0112 - val_loss: 0.0133\n",
      "Epoch 464/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 465/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0100 - val_loss: 0.0128\n",
      "Epoch 466/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0096 - val_loss: 0.0127\n",
      "Epoch 467/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0098 - val_loss: 0.0128\n",
      "Epoch 468/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0097 - val_loss: 0.0125\n",
      "Epoch 469/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 470/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 471/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0093 - val_loss: 0.0124\n",
      "Epoch 472/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0092 - val_loss: 0.0124\n",
      "Epoch 473/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0094 - val_loss: 0.0125\n",
      "Epoch 474/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 475/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 476/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 477/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 478/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0091 - val_loss: 0.0122\n",
      "Epoch 479/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0091 - val_loss: 0.0123\n",
      "Epoch 480/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 481/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 482/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0093 - val_loss: 0.0122\n",
      "Epoch 483/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 484/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 485/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 486/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 487/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0094 - val_loss: 0.0124\n",
      "Epoch 488/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 489/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0091 - val_loss: 0.0121\n",
      "Epoch 490/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 491/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 492/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 493/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 494/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 495/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0089 - val_loss: 0.0120\n",
      "Epoch 496/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0090 - val_loss: 0.0120\n",
      "Epoch 497/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 498/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0092 - val_loss: 0.0121\n",
      "Epoch 499/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0090 - val_loss: 0.0119\n",
      "Epoch 500/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 501/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 502/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 503/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 504/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 505/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 506/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 507/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 508/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0093 - val_loss: 0.0121\n",
      "Epoch 509/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 510/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 511/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0118\n",
      "Epoch 512/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0089 - val_loss: 0.0119\n",
      "Epoch 513/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 514/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 515/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 516/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0097 - val_loss: 0.0119\n",
      "Epoch 517/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0091 - val_loss: 0.0119\n",
      "Epoch 518/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 519/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 520/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 521/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 522/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 523/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 524/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 525/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 526/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 527/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 528/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 529/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 530/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 531/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 532/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0116\n",
      "Epoch 533/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 534/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 535/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 536/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 537/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 538/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0086 - val_loss: 0.0116\n",
      "Epoch 539/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0116\n",
      "Epoch 540/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0118\n",
      "Epoch 541/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0098 - val_loss: 0.0119\n",
      "Epoch 542/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0090 - val_loss: 0.0116\n",
      "Epoch 543/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 544/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 545/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0115\n",
      "Epoch 546/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 0.0117\n",
      "Epoch 547/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 548/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.007 - 0s 19us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 549/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 550/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 551/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 552/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 553/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 554/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 555/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0115\n",
      "Epoch 556/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 557/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 558/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 559/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 560/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 561/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0088 - val_loss: 0.0115\n",
      "Epoch 562/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 563/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 564/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 565/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 566/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 567/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 568/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 569/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 570/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 571/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 572/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 573/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0087 - val_loss: 0.0114\n",
      "Epoch 574/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 575/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 576/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 577/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 578/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 579/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 580/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 581/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 582/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 583/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 584/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0089 - val_loss: 0.0114\n",
      "Epoch 585/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0113\n",
      "Epoch 586/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 587/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 588/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 589/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 590/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 591/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 592/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 593/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 594/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 595/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 596/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 597/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 598/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 599/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 600/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 601/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 602/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 603/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 604/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 605/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 606/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 607/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 608/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 609/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 610/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 611/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 612/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 613/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 614/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 615/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 616/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 617/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 618/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 619/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 620/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 621/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 622/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 623/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 624/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 625/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0114\n",
      "Epoch 626/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0093 - val_loss: 0.0114\n",
      "Epoch 627/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0111\n",
      "Epoch 628/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 629/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 630/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 631/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 632/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 633/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 0.0111\n",
      "Epoch 634/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 635/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 636/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 637/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 638/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 639/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0082 - val_loss: 0.0111\n",
      "Epoch 640/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 641/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0086 - val_loss: 0.0111\n",
      "Epoch 642/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0086 - val_loss: 0.0110\n",
      "Epoch 643/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 644/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0112\n",
      "Epoch 645/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 646/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 647/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 648/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 649/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 650/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 651/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 652/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 653/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 654/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 655/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 656/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 657/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 658/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 659/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 660/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0115\n",
      "Epoch 661/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0088 - val_loss: 0.0113\n",
      "Epoch 662/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0085 - val_loss: 0.0112\n",
      "Epoch 663/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 664/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 665/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 666/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 667/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 668/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 669/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 670/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 671/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 672/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0111\n",
      "Epoch 673/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 674/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 675/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 676/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0081 - val_loss: 0.0110\n",
      "Epoch 677/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 678/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 679/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 680/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 681/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 682/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 683/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 684/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 685/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 686/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 687/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 688/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0108\n",
      "Epoch 689/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 690/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 691/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 692/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0112\n",
      "Epoch 693/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0084 - val_loss: 0.0114\n",
      "Epoch 694/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0125 - val_loss: 0.0124\n",
      "Epoch 695/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0092 - val_loss: 0.0122\n",
      "Epoch 696/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0090 - val_loss: 0.0111\n",
      "Epoch 697/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 698/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 699/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 700/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 701/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 702/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 703/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 704/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 705/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 706/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 707/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 708/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 709/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 710/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 711/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 712/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 713/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 714/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 715/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.008 - 0s 20us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 716/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 717/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 718/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 719/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 720/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 721/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0110\n",
      "Epoch 722/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 723/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 724/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 725/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 726/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 727/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 728/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 729/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 730/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 731/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 732/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 733/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 734/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 735/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 736/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 737/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 738/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 739/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0110\n",
      "Epoch 740/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 741/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 742/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 743/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0110\n",
      "Epoch 744/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 745/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 746/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 747/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 748/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 749/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 750/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 751/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 752/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 753/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 754/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 755/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 756/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 757/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 758/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 759/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 760/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 761/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 762/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0109\n",
      "Epoch 763/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 764/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 765/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 766/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0108\n",
      "Epoch 767/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0085 - val_loss: 0.0110\n",
      "Epoch 768/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0088 - val_loss: 0.0111\n",
      "Epoch 769/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 0.0108\n",
      "Epoch 770/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0121\n",
      "Epoch 771/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 772/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 0.0114\n",
      "Epoch 773/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0093 - val_loss: 0.0113\n",
      "Epoch 774/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 775/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 776/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 777/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 778/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 779/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 780/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 781/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 782/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 783/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 784/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 785/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 786/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 787/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 788/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 789/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 790/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 791/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 792/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 793/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 794/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 795/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 796/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 797/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 798/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 799/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 800/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 801/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 802/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 803/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 804/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 805/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 806/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 807/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 808/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 809/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 810/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 811/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0108\n",
      "Epoch 812/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 813/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 814/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 815/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 816/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 817/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 818/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 819/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 820/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 821/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 822/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 823/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 824/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 825/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 826/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 827/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 828/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 829/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 830/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 831/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 832/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 833/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 834/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 835/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 836/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 837/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 838/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 839/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 840/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 841/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 842/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 843/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 844/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 845/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 846/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 847/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 848/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 849/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 850/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 851/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 852/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 853/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 854/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 855/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 856/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 857/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 858/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 859/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 860/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 861/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.008 - 0s 20us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 862/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 863/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 864/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 865/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 866/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 867/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 868/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 869/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 870/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 871/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 872/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 873/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 874/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 875/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 876/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 877/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 878/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 879/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 880/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 881/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0107\n",
      "Epoch 882/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 883/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 884/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 885/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0108\n",
      "Epoch 886/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0088 - val_loss: 0.0109\n",
      "Epoch 887/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 888/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 889/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 890/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 891/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 892/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 893/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 894/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 895/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 896/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 897/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 898/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 899/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 900/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 901/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 902/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 903/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 904/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 905/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 906/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 907/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 908/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 909/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0114\n",
      "Epoch 910/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0094 - val_loss: 0.0117\n",
      "Epoch 911/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 912/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 913/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 914/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 915/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 916/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 917/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 918/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 919/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 920/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 921/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 922/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 923/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 924/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 925/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 926/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 927/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 928/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 929/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 930/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 931/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 932/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 933/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 934/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 935/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0123 - val_loss: 0.0131\n",
      "Epoch 936/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0114\n",
      "Epoch 937/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 938/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0088 - val_loss: 0.0114\n",
      "Epoch 939/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 940/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 941/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 942/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 943/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 944/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 945/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0161\n",
      "Epoch 946/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0461 - val_loss: 0.0347\n",
      "Epoch 947/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0299 - val_loss: 0.0240\n",
      "Epoch 948/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0184 - val_loss: 0.0158\n",
      "Epoch 949/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0127 - val_loss: 0.0128\n",
      "Epoch 950/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 951/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 952/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 953/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 954/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 955/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 956/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 957/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 958/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 959/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 960/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 961/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 962/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 963/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 964/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 965/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 966/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 967/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 968/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 969/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 970/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 971/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 972/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 973/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 974/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 975/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 976/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 977/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 978/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 979/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 980/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 981/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 982/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 983/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 984/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 985/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 986/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 987/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 988/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 989/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 990/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 991/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 992/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 993/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 994/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 995/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 996/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 997/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 998/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 999/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1000/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1001/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1002/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1003/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1004/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1005/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1006/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1007/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1008/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1009/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1010/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1011/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1012/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1013/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1014/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1015/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1016/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1017/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1018/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1019/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1020/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1021/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1022/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1023/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1024/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1025/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1026/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1027/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1028/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1029/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1030/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1031/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1032/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1033/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1034/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1035/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1036/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1037/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1038/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1039/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1040/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1041/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1042/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1043/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1044/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1045/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1046/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1047/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1048/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1049/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1050/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1051/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1052/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1053/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1054/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1055/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1056/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1057/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1058/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1059/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1060/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1061/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1062/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1063/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 1064/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 1065/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 1066/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1067/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1068/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1069/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1070/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1071/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1072/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1073/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1074/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1075/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1076/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1077/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1078/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1079/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1080/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1081/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1082/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1083/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1084/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1085/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1086/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1087/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1088/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1089/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1090/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1091/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1092/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1093/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1094/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1095/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1096/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1097/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1098/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1099/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1100/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1101/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1102/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1103/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1104/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 1105/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 1106/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1107/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1108/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1109/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1110/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1111/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0108\n",
      "Epoch 1112/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0138 - val_loss: 0.0161\n",
      "Epoch 1113/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1114/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 1115/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1116/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1117/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1118/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0108\n",
      "Epoch 1119/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1120/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 1121/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1122/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1123/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1124/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1125/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1126/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1127/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1128/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1129/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1130/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1131/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1132/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1133/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1134/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1135/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1136/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1137/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 1138/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 1139/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 1140/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0087 - val_loss: 0.0104\n",
      "Epoch 1141/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0108\n",
      "Epoch 1142/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0095 - val_loss: 0.0111\n",
      "Epoch 1143/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 1144/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1145/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1146/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1147/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1148/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1149/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1150/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1151/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1152/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1153/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1154/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1155/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.005 - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1156/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1157/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1158/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1159/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0108\n",
      "Epoch 1160/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0097 - val_loss: 0.0110\n",
      "Epoch 1161/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 1162/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1163/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1164/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 1165/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1166/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1167/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1168/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1169/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1170/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1171/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1172/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1173/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1174/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 1175/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1176/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1177/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1178/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1179/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1180/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1181/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1182/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 1183/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1184/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1185/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1186/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1187/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1188/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1189/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1190/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0107\n",
      "Epoch 1191/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1192/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1193/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1194/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1195/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1196/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1197/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.006 - 0s 19us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1198/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1199/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1200/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1201/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1202/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0087 - val_loss: 0.0112\n",
      "Epoch 1203/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 1204/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1205/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1206/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 1207/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1208/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1209/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1210/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 1211/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1212/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1213/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1214/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1215/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1216/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1217/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1218/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1219/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1220/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1221/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1222/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1223/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1224/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1225/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1226/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1227/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1228/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1229/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1230/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1231/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1232/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1233/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1234/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 1235/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1236/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1237/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1238/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1239/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1240/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1241/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1242/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1243/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1244/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1245/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1246/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1247/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1248/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1249/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1250/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1251/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1252/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1253/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1254/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1255/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1256/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1257/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1258/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1259/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1260/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1261/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1262/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1263/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1264/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1265/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1266/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1267/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 1268/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1269/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1270/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1271/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1272/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1273/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1274/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1275/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1276/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1277/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1278/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1279/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1280/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1281/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1282/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1283/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1284/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 1285/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1286/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1287/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1288/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1289/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1290/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1291/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1292/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1293/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1294/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1295/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1296/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1297/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1298/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1299/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1300/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1301/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1302/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1303/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1304/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1305/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1306/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1307/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1308/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1309/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1310/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1311/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 1312/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1313/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1314/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1315/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1316/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1317/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1318/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1319/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1320/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1321/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1322/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1323/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1324/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1325/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1326/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1327/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1328/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1329/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1330/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1331/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1332/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0105\n",
      "Epoch 1333/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1334/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1335/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1336/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1337/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 1338/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1339/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1340/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1341/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1342/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1343/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1344/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1345/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1346/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1347/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1348/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1349/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1350/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1351/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1352/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1353/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1354/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1355/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1356/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1357/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1358/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1359/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1360/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1361/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1362/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1363/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1364/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 1365/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0087 - val_loss: 0.0110\n",
      "Epoch 1366/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 1367/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1368/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1369/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1370/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1371/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1372/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1373/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1374/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1375/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1376/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 1377/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1378/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1379/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1380/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0106\n",
      "Epoch 1381/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 1382/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1383/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1384/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1385/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1386/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1387/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1388/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1389/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1390/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1391/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1392/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 1393/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1394/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1395/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1396/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1397/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1398/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1399/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 1400/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1401/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 1402/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1403/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1404/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1405/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1406/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1407/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1408/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1409/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1410/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1411/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1412/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1413/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1414/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1415/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1416/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1417/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1418/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 1419/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1420/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1421/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1422/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1423/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1424/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1425/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1426/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1427/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1428/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1429/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1430/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1431/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1432/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1433/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1434/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1435/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1436/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1437/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1438/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1439/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 1440/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1441/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1442/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1443/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1444/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1445/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1446/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1447/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1448/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1449/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1450/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1451/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1452/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1453/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1454/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1455/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1456/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1457/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1458/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1459/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1460/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1461/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1462/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1463/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1464/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1465/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1466/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1467/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1468/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1469/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1470/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0107\n",
      "Epoch 1471/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0088 - val_loss: 0.0113\n",
      "Epoch 1472/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 1473/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1474/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1475/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1476/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1477/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1478/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1479/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1480/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1481/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 1482/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1483/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1484/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1485/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1486/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1487/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1488/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1489/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1490/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1491/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1492/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1493/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1494/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1495/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1496/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1497/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1498/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1499/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1500/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1501/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1502/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1503/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1504/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1505/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 1506/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 1507/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 1508/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 1509/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1510/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1511/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1512/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1513/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1514/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1515/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1516/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1517/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1518/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0105\n",
      "Epoch 1519/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1520/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1521/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1522/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1523/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1524/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1525/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1526/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1527/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1528/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1529/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1530/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1531/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1532/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1533/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1534/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1535/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1536/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1537/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1538/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1539/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1540/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1541/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1542/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1543/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1544/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1545/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1546/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1547/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1548/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1549/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1550/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1551/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1552/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1553/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 1554/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1555/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1556/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1557/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1558/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1559/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1560/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1561/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1562/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1563/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1564/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1565/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1566/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1567/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1568/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1569/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1570/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1571/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1572/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1573/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1574/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1575/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 1576/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1577/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1578/3000\n",
      "2572/2572 [==============================] - 0s 10us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1579/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1580/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1581/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1582/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1583/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1584/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 1585/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 1586/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0097 - val_loss: 0.0116\n",
      "Epoch 1587/3000\n",
      "2572/2572 [==============================] - 0s 35us/step - loss: 0.0088 - val_loss: 0.0110\n",
      "Epoch 1588/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 1589/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 1590/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1591/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1592/3000\n",
      "2572/2572 [==============================] - 0s 39us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1593/3000\n",
      "2572/2572 [==============================] - 0s 37us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1594/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1595/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1596/3000\n",
      "2572/2572 [==============================] - 0s 40us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1597/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1598/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1599/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1600/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1601/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1602/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1603/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0107\n",
      "Epoch 1604/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0091 - val_loss: 0.0104\n",
      "Epoch 1605/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1606/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1607/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1608/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1609/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1610/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1611/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1612/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1613/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0123\n",
      "Epoch 1614/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0163 - val_loss: 0.0163\n",
      "Epoch 1615/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0126 - val_loss: 0.0144\n",
      "Epoch 1616/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1617/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 1618/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1619/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1620/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 1621/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1622/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1623/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1624/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1625/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1626/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1627/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1628/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1629/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1630/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1631/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1632/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1633/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1634/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1635/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1636/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1637/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1638/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1639/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1640/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1641/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1642/3000\n",
      "2572/2572 [==============================] - 0s 37us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1643/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1644/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1645/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1646/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1647/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1648/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1649/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1650/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1651/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1652/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1653/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1654/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1655/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 1656/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1657/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1658/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1659/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1660/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1661/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1662/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1663/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1664/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1665/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1666/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1667/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1668/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1669/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1670/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1671/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1672/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1673/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1674/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1675/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1676/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1677/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1678/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1679/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1680/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1681/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1682/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1683/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 1684/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1685/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1686/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1687/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1688/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1689/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1690/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1691/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1692/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1693/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1694/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1695/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1696/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1697/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1698/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1699/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1700/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1701/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1702/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1703/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1704/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1705/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1706/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1707/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1708/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1709/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1710/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1711/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1712/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1713/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1714/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1715/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1716/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1717/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1718/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1719/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1720/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1721/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1722/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1723/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1724/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1725/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1726/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1727/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1728/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 1729/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1730/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1731/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1732/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1733/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1734/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1735/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1736/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1737/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1738/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1739/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1740/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1741/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1742/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1743/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1744/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1745/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1746/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0105\n",
      "Epoch 1747/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0109\n",
      "Epoch 1748/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 1749/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1750/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1751/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 1752/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 1753/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 1754/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 1755/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1756/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1757/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1758/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1759/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1760/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 1761/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1762/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1763/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1764/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1765/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1766/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1767/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1768/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1769/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1770/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1771/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1772/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1773/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1774/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1775/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1776/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1777/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1778/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1779/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1780/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1781/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1782/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1783/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 1784/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1785/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1786/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1787/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1788/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1789/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1790/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1791/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1792/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1793/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1794/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1795/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1796/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.006 - 0s 22us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1797/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1798/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1799/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1800/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 1801/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1802/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1803/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1804/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1805/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1806/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1807/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 1808/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 1809/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1810/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0107\n",
      "Epoch 1811/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1812/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1813/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1814/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1815/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1816/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1817/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1818/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1819/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1820/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1821/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1822/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1823/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1824/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1825/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1827/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1828/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1829/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1830/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1831/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1832/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1833/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1834/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1835/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1836/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1837/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1838/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1839/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1840/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1841/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1842/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1843/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1844/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1845/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1846/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1847/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1848/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1849/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1850/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1851/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1852/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1853/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1854/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1855/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1856/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1857/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1858/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1859/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1860/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1861/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1862/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1863/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1864/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1865/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1866/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1867/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1868/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1869/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1870/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1871/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1872/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1873/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 1874/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0106\n",
      "Epoch 1875/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0084 - val_loss: 0.0107\n",
      "Epoch 1876/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 1877/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 1878/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1879/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1880/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1881/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1882/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1883/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1884/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1885/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1886/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1887/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1888/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1889/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1890/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1891/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1892/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1893/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0105\n",
      "Epoch 1894/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0087 - val_loss: 0.0106\n",
      "Epoch 1895/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 1896/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1897/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1898/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1899/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1900/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1901/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1902/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1903/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1904/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 1905/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1906/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1907/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 1908/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1909/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1910/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1911/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1912/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1913/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 1914/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 1915/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1916/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1917/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1918/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1919/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1920/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 1921/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1922/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 1923/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 1924/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 1925/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 1926/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1927/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1928/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1929/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1930/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1931/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1932/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1933/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1934/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1935/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1936/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1937/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1938/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1939/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1940/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1941/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1942/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1943/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1944/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 1945/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1946/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1947/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1948/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1949/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1950/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1951/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1952/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1953/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 1954/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 1955/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 1956/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0112\n",
      "Epoch 1957/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0089 - val_loss: 0.0111\n",
      "Epoch 1958/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0090 - val_loss: 0.0115\n",
      "Epoch 1959/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 1960/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1961/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1962/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1963/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 1964/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1965/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1966/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1967/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1968/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1969/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1970/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1971/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1972/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1973/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 1974/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 1975/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1976/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1977/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1978/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1979/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 1980/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 1981/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1982/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1983/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 1984/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 1985/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 1986/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0119 - val_loss: 0.0132\n",
      "Epoch 1987/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0089 - val_loss: 0.0109\n",
      "Epoch 1988/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 0.0106\n",
      "Epoch 1989/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 1990/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 1991/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 1992/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 1993/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 1994/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1995/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 1996/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1997/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 1998/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 1999/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2000/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 2001/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0089 - val_loss: 0.0106\n",
      "Epoch 2002/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 2003/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2004/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2005/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2006/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2007/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2008/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2009/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2010/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2011/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2012/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2013/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2014/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2015/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2016/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2017/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2018/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2019/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2020/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2021/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2022/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2023/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2024/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2025/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2026/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2027/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2028/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2029/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2030/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2031/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2032/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2033/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2034/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 2035/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0088 - val_loss: 0.0108\n",
      "Epoch 2036/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0089 - val_loss: 0.0108\n",
      "Epoch 2037/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 2038/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2039/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2040/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 2041/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 2042/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2043/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2044/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2045/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0081 - val_loss: 0.0106\n",
      "Epoch 2046/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 2047/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2048/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2049/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2050/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2051/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2052/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2053/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2054/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2055/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2056/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 2057/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2058/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2059/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 2060/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2061/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2062/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2063/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2064/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2065/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2066/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2067/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2068/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2069/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2070/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2071/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2072/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2073/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2074/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2075/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2076/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2077/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2078/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2079/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2080/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2081/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2082/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2083/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 2084/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0120 - val_loss: 0.0149\n",
      "Epoch 2085/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 2086/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0115\n",
      "Epoch 2087/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 2088/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 2089/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 2090/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2091/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2092/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2093/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2094/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2095/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2096/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2097/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2098/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2099/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2100/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2101/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2102/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2103/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2104/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2105/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2106/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2107/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2108/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 2109/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2110/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2111/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2112/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2113/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2114/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2115/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2116/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2117/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2118/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2119/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2120/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2121/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2122/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2123/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2124/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2125/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2126/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2127/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2128/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2129/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2130/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0114\n",
      "Epoch 2131/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0124 - val_loss: 0.0126\n",
      "Epoch 2132/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0095 - val_loss: 0.0112\n",
      "Epoch 2133/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 2134/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2135/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2136/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2137/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2138/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2139/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2140/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2141/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2142/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2143/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2144/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2145/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2146/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2147/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2148/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2149/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2150/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2151/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2152/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.007 - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2153/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2154/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0105\n",
      "Epoch 2155/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 2156/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 2157/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0087 - val_loss: 0.0105\n",
      "Epoch 2158/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 2159/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0108\n",
      "Epoch 2160/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2161/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2162/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 2163/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2164/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2165/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2166/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0104\n",
      "Epoch 2167/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0083 - val_loss: 0.0108\n",
      "Epoch 2168/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2169/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2170/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 2171/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0086 - val_loss: 0.0106\n",
      "Epoch 2172/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2173/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2174/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2175/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2176/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2177/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2178/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2179/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2180/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2181/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2182/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2183/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2184/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2185/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2186/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2187/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2188/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2189/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2190/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2191/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2192/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2193/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2194/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2195/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2196/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2197/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2198/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2199/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2200/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2201/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2202/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2203/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2204/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2205/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2206/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2207/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2208/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2209/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2210/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2211/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2212/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2213/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2214/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2215/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2216/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2217/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2218/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2219/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2220/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2221/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2222/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2223/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2224/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2225/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2226/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2227/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2228/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2229/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2230/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2231/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2232/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2233/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2234/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2235/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2236/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2237/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 2238/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0085 - val_loss: 0.0103\n",
      "Epoch 2239/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2240/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2241/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2242/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2243/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2244/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2245/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2246/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2247/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0083 - val_loss: 0.0106\n",
      "Epoch 2248/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2249/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 2250/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2251/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2252/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2253/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2254/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2255/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2256/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2257/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2258/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2259/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2260/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 2261/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2262/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2263/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2264/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2265/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2266/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2267/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2268/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2269/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2270/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2271/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2272/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2273/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2274/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2275/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2276/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2277/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2278/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2279/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2280/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2281/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2282/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2283/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2284/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2285/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2286/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2287/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2288/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2289/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2290/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2291/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2292/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2293/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2294/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2295/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2296/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2297/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2298/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2299/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2300/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2301/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2302/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2303/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2304/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2305/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2306/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2307/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0106\n",
      "Epoch 2308/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 2309/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 2310/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2311/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2312/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2313/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2314/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2315/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2316/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2317/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2318/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2319/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2320/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2321/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2322/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2323/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2324/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2325/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2326/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2327/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2328/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2329/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2330/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2331/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2332/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2333/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2334/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2335/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0106\n",
      "Epoch 2336/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0089 - val_loss: 0.0110\n",
      "Epoch 2337/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 2338/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0083 - val_loss: 0.0107\n",
      "Epoch 2339/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 2340/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 2341/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 2342/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2343/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2344/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2345/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2346/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2347/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2348/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2349/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2350/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2351/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2352/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2353/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2354/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2355/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2356/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 2357/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0104\n",
      "Epoch 2358/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 2359/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 2360/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0085 - val_loss: 0.0106\n",
      "Epoch 2361/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0106\n",
      "Epoch 2362/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2363/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2364/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2365/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2366/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2367/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2368/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2369/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2370/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2371/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2372/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0073 - val_loss: 0.0102\n",
      "Epoch 2373/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2374/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2375/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2376/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2377/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2378/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2379/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2380/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2381/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2382/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2383/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2384/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2385/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2386/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2387/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2388/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 2389/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2390/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2391/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2392/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2393/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2394/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2395/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2396/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2397/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2398/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0107\n",
      "Epoch 2399/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0086 - val_loss: 0.0108\n",
      "Epoch 2400/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0082 - val_loss: 0.0109\n",
      "Epoch 2401/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 2402/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2403/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2404/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2405/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2406/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2407/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2408/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2409/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2410/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2411/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2412/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2413/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2414/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2415/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2416/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2417/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2418/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2419/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2420/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2421/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2422/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2423/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2424/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2425/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2426/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2427/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2428/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2429/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2430/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2431/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2432/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2433/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2434/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2435/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2436/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2437/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2438/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2439/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2440/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2441/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2442/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2443/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2444/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2445/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2446/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2447/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2448/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2449/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2450/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2451/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2452/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2453/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2454/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2455/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2456/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2457/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2458/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2459/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2460/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2461/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2462/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2463/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2464/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2465/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2466/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2467/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2468/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2469/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2470/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2471/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2472/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2473/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2474/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2475/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2476/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2477/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2478/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2479/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2480/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2481/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2482/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2483/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2484/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2485/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2486/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2487/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 2488/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 2489/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 2490/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2491/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2492/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2493/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2494/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2495/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2496/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2497/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2498/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2499/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2500/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2501/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2502/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2503/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2504/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2505/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2506/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2507/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2508/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2509/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2510/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2511/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0134\n",
      "Epoch 2512/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0213 - val_loss: 0.0196\n",
      "Epoch 2513/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0171 - val_loss: 0.0167\n",
      "Epoch 2514/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0126 - val_loss: 0.0132\n",
      "Epoch 2515/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 2516/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0085 - val_loss: 0.0108\n",
      "Epoch 2517/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 2518/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0128\n",
      "Epoch 2519/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0223 - val_loss: 0.0209\n",
      "Epoch 2520/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0161 - val_loss: 0.0149\n",
      "Epoch 2521/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0132 - val_loss: 0.0132\n",
      "Epoch 2522/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0117 - val_loss: 0.0129\n",
      "Epoch 2523/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 2524/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 2525/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 2526/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 2527/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2528/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2529/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2530/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2531/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2532/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2533/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2534/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2535/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2536/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2537/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2538/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2539/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2540/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2541/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 2542/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2543/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2544/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2545/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2546/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2547/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2548/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2549/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2550/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2551/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2552/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2553/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2554/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2555/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2556/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2557/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 2558/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2559/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2560/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2561/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2562/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2563/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2564/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2565/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2566/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2567/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2568/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2569/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2570/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2571/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2572/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2573/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0078 - val_loss: 0.0101\n",
      "Epoch 2574/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2575/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2576/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2577/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2578/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2579/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2580/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2581/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2582/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2583/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2584/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2585/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2586/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2587/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2588/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2589/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2590/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2591/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2592/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2593/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2594/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2595/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2596/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2597/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2598/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2599/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2600/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2601/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2602/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2603/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2604/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2605/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2606/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2607/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2608/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2609/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2610/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2611/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2612/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2613/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2614/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2615/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2616/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2617/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.013 - 0s 24us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2618/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2619/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2620/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2621/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2622/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2623/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2624/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2625/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2626/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2627/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2628/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2629/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2630/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2631/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2632/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2633/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0103\n",
      "Epoch 2634/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 2635/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2636/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2637/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0083 - val_loss: 0.0103\n",
      "Epoch 2638/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2639/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2640/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2641/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2642/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2643/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 2644/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 2645/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 2646/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2647/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2648/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2649/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2650/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2651/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2652/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2653/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2654/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2655/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2656/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2657/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2658/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2659/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2660/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2661/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2662/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2663/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2664/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2665/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2666/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2667/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2668/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2669/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2670/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2671/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2672/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2673/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2674/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2675/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2676/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2677/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2678/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.005 - 0s 20us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 2679/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2680/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2681/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2682/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2683/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2684/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2685/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2686/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2687/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2688/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2689/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2690/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2691/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2692/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2693/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0073 - val_loss: 0.0104\n",
      "Epoch 2694/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0088 - val_loss: 0.0104\n",
      "Epoch 2695/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0104\n",
      "Epoch 2696/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2697/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2698/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2699/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2700/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2701/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2702/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2703/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2704/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2705/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2706/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2707/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2708/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2709/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0073 - val_loss: 0.0101\n",
      "Epoch 2710/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2711/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2712/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2713/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2714/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2715/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2716/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2717/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2718/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2719/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2720/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2721/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2722/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2723/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2724/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2725/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2726/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2727/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 2728/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2729/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2730/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2731/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2732/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2733/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2734/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2735/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2736/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0105\n",
      "Epoch 2737/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 2738/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2739/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2740/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2741/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2742/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2743/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2744/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2745/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2746/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2747/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2748/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2749/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2750/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2751/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2752/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.006 - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2753/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2754/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2755/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2756/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2757/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2758/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2759/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2760/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2761/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2762/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2763/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2764/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2765/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2766/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2767/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2768/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2769/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2770/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2771/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2772/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2773/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2774/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2775/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2776/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2777/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2778/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2779/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 2780/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2781/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2782/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2783/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2784/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2785/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2786/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2787/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2788/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2789/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2790/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2791/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2792/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2793/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2794/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2795/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2796/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 2797/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0104\n",
      "Epoch 2798/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0103\n",
      "Epoch 2799/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2800/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2801/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2802/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2803/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2804/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2805/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2806/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0077 - val_loss: 0.0104\n",
      "Epoch 2807/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2808/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2809/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2810/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2811/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2812/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 2813/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 2814/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2815/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2816/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2817/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2818/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2819/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2820/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2821/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2822/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2823/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2824/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2825/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2826/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2827/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2828/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2829/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2830/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2831/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2832/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2833/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2834/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2835/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2836/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2837/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2838/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2839/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2840/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2841/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2842/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2843/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2844/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2845/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0102\n",
      "Epoch 2846/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0104\n",
      "Epoch 2847/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 2848/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 2849/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2850/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2851/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2852/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2853/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2854/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2855/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2856/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0079 - val_loss: 0.0103\n",
      "Epoch 2857/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2858/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2859/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2860/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2861/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 2862/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2863/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0102\n",
      "Epoch 2864/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2865/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.006 - 0s 12us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2866/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2867/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2868/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 2869/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 2870/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0080 - val_loss: 0.0103\n",
      "Epoch 2871/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 2872/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 2873/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 2874/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0084 - val_loss: 0.0105\n",
      "Epoch 2875/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2876/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2877/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2878/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2879/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 2880/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0103\n",
      "Epoch 2881/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 2882/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2883/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2884/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2885/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2886/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2887/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2888/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2889/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2890/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2891/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2892/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2893/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2894/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 2895/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2896/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2897/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2898/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2899/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2900/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2901/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2902/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2903/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2904/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2905/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2906/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 2907/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0104\n",
      "Epoch 2908/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 2909/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0088 - val_loss: 0.0105\n",
      "Epoch 2910/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 2911/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2912/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 2913/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2914/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2915/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2916/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2917/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0102\n",
      "Epoch 2918/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2919/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 2920/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2921/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0080 - val_loss: 0.0102\n",
      "Epoch 2922/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2923/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2924/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2925/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2926/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2927/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2928/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2929/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2930/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2931/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2932/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2933/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2934/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2935/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2936/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 2937/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2938/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2939/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2940/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2941/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2942/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2943/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2944/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0105\n",
      "Epoch 2945/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 2946/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0090 - val_loss: 0.0110\n",
      "Epoch 2947/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 2948/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 2949/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0081 - val_loss: 0.0105\n",
      "Epoch 2950/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0079 - val_loss: 0.0107\n",
      "Epoch 2951/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0089 - val_loss: 0.0107\n",
      "Epoch 2952/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0080 - val_loss: 0.0106\n",
      "Epoch 2953/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 2954/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 2955/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0076 - val_loss: 0.0103\n",
      "Epoch 2956/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2957/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2958/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2959/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2960/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2961/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2962/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2963/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2964/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0081 - val_loss: 0.0103\n",
      "Epoch 2965/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 2966/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2967/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2968/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2969/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2970/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2971/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0073 - val_loss: 0.0100\n",
      "Epoch 2972/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2973/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2974/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2975/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2976/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2977/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2978/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2979/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2980/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0102\n",
      "Epoch 2981/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2982/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2983/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2984/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2985/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0101\n",
      "Epoch 2986/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2987/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2988/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2989/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2990/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2991/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2992/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 2993/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2994/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 2995/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2996/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0074 - val_loss: 0.0100\n",
      "Epoch 2997/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0074 - val_loss: 0.0101\n",
      "Epoch 2998/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0100\n",
      "Epoch 2999/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0075 - val_loss: 0.0101\n",
      "Epoch 3000/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0074 - val_loss: 0.0101\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc940301b50>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cautoencoder.fit(cX_trainAtMes, cX_trainAtMes,\n",
    "                epochs=3000,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                validation_data=(cX_testAtMes, cX_testAtMes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz o teste de previsão\n",
    "ctesteAtMes = cautoencoder.predict(cX_testAtMes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1103/1103 [==============================] - 0s 4us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010065305046737194"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cautoencoder.evaluate(x=cX_testAtMes, y=cX_testAtMes, batch_size=attest_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "2572/2572 [==============================] - 0s 2us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.007400162052363157"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cautoencoder.evaluate(x=cX_trainAtMes, y=cX_trainAtMes, batch_size=attrain_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715807738377704"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(cX_testAtMes,ctesteAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8854110513401364"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctrainAtMes = cautoencoder.predict(cX_trainAtMes)\n",
    "r2_score(cX_trainAtMes,ctrainAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coolingdegreedays': 0.9998123616725636,\n",
       " 'date': 0.9996084503089951,\n",
       " 'fog': 0.3004772470865118,\n",
       " 'gdegreedays': 0.922980090729923,\n",
       " 'hail': -0.0293132666238054,\n",
       " 'heatingdegreedays': 0.9908893234765521,\n",
       " 'humidity': 0.9590538167321245,\n",
       " 'lat': 0.9998823771842899,\n",
       " 'lng': 0.9998883614924007,\n",
       " 'maxdewptm': 0.9742784921467367,\n",
       " 'maxhumidity': 0.9953889642176091,\n",
       " 'maxpressurei': 0.9970121000389225,\n",
       " 'maxpressurem': 0.9962020386070761,\n",
       " 'maxtempm': 0.9947737523694579,\n",
       " 'maxwspdi': 0.9981255433791353,\n",
       " 'maxwspdm': 0.9985256532421832,\n",
       " 'meandewptm': 0.9832302464069954,\n",
       " 'meanpressurei': 0.9922346089183278,\n",
       " 'meanpressurem': 0.9922651276624006,\n",
       " 'meantempm': 0.9912559868765137,\n",
       " 'meanwdird': 0.9950320885772248,\n",
       " 'meanwindspdi': 0.9963916585449674,\n",
       " 'meanwindspdm': 0.9972495599826557,\n",
       " 'mindewptm': 0.9619002744825621,\n",
       " 'minhumidity': 0.9654617956970301,\n",
       " 'minpressurei': 0.9974155468981395,\n",
       " 'minpressurem': 0.9970938318989202,\n",
       " 'mintempm': 0.9932407481464907,\n",
       " 'minwspdi': 0.9982222445389052,\n",
       " 'minwspdm': 0.9952354796665436,\n",
       " 'precipi': 0.26965741248833697,\n",
       " 'precipm': 0.9999500606796473,\n",
       " 'rain': 0.9798757045458607,\n",
       " 'snow': 0.022083100445123183,\n",
       " 'thunder': 0.27994630180464597}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctesteAtMes = pd.DataFrame(ctesteAtMes, columns=df_atmess.columns)\n",
    "cscore = {}\n",
    "for c in ctesteAtMes.columns:\n",
    "    cscore[c] = r2_score(cX_testAtMes[c],ctesteAtMes[c])\n",
    "cscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('hail', -0.0293132666238054)\n",
      "('thunder', 0.27994630180464597)\n",
      "('snow', 0.022083100445123183)\n",
      "('fog', 0.3004772470865118)\n",
      "('precipi', 0.26965741248833697)\n"
     ]
    }
   ],
   "source": [
    "for a in cscore:\n",
    "    if(cscore[a] < 0.9):\n",
    "        print(a,cscore[a])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3675"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = len(df_atmes)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(batch_shape=(attrain_dim, input_dim))\n",
    "h = Dense(encoding_dim1, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(attrain_dim, latent_dim),\n",
    "                              mean=0.)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_h = Dense(encoding_dim1, activation='relu')\n",
    "decoder_mean = Dense(input_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2572"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrain_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2572 samples, validate on 1103 samples\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [1103,2] vs. [2572,2]\n\t [[{{node lambda_2/mul}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lambda_2/Exp, lambda_2/random_normal/RandomStandardNormal)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-21466f71fdb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2577\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         validation_data=(X_testAtMes, X_testAtMes))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.pyc\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [1103,2] vs. [2572,2]\n\t [[{{node lambda_2/mul}} = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lambda_2/Exp, lambda_2/random_normal/RandomStandardNormal)]]"
     ]
    }
   ],
   "source": [
    "vae.fit(X_trainAtMes, X_trainAtMes,\n",
    "        shuffle=True,\n",
    "        epochs=50,\n",
    "        batch_size=2577,\n",
    "        validation_data=(X_testAtMes, X_testAtMes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
