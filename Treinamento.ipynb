{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Lambda, Input, Dense, Dropout\n",
    "from keras.models import Model\n",
    "#from keras import backend as K\n",
    "#from keras import regularizers\n",
    "from pandas.plotting import scatter_matrix\n",
    "#import argparse\n",
    "#import os\n",
    "from keras.losses import mse#, binary_crossentropy\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atmes = pd.read_csv(\"americanToadPadraoMes.csv\")\n",
    "#df_gfmes = pd.read_csv(\"greenFrogPadraoMes.csv\")\n",
    "#df_spmes = pd.read_csv(\"springPeeperPadraoMes.csv\")\n",
    "#df_atest = pd.read_csv(\"americanToadPadraoEstacao.csv\")\n",
    "#df_gfest = pd.read_csv(\"greenFrogPadraoEstacao.csv\")\n",
    "#df_spest = pd.read_csv(\"springPeeperPadraoEstacao.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_spmes = pd.read_csv(\"springPeeperPadraoMes.csv\")\n",
    "plt.scatter(df_spmes[\"lat\"], df_spmes[\"lng\"],marker=\".\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_gfest = pd.read_csv(\"greenFrogPadraoEstacao.csv\")\n",
    "plt.scatter(df_gfest[\"lat\"], df_gfest[\"lng\"],marker=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Longitude')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df_atmes[\"lat\"], df_atmes[\"lng\"],marker=\".\",alpha='0.3',color=\"green\")\n",
    "plt.xlabel('Latitude')\n",
    "plt.ylabel(\"Longitude\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_atmes.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(df_atmes.columns)\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede com duas camadas decodificadas e batch_normalizzation\n",
    "encoding_dim1 = input_dim//2\n",
    "entrada = Input(shape=(input_dim,))\n",
    "batch1 = BatchNormalization()(entrada)\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(batch1)\n",
    "dp2 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(encoding_dim1,activation=\"relu\")(dp2)\n",
    "batch2 = BatchNormalization()(encoded2)\n",
    "decoded = Dense(input_dim,activation=\"sigmoid\")(batch2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com duas camadas decodificadas\n",
    "encoding_dim1 = input_dim//2\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "dp2 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(encoding_dim1,activation=\"relu\")(dp2)\n",
    "decoded = Dense(input_dim,activation=\"sigmoid\")(encoded2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com somente uma camada escondida\n",
    "encoding_dim1 = input_dim//2\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "decoded = Dense(input_dim,activation=\"sigmoid\")(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o modelo para a rede anteriormente montada\n",
    "autoencoder = Model(entrada,decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compila o modelo com o método otimizador e a funlção de erro utilizadas\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa as base de treino e teste\n",
    "X_trainAtMes, X_testAtMes = train_test_split(df_atmes, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = len(df_atmes)//10\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attest_dim = len(X_testAtMes)//10\n",
    "attest_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2572 samples, validate on 1103 samples\n",
      "Epoch 1/3000\n",
      "2572/2572 [==============================] - 2s 884us/step - loss: 0.1456 - val_loss: 0.1430\n",
      "Epoch 2/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.1396 - val_loss: 0.1366\n",
      "Epoch 3/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.1343 - val_loss: 0.1305\n",
      "Epoch 4/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.1300 - val_loss: 0.1269\n",
      "Epoch 5/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.1255 - val_loss: 0.1228\n",
      "Epoch 6/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.1209 - val_loss: 0.1191\n",
      "Epoch 7/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.1173 - val_loss: 0.1154\n",
      "Epoch 8/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.1137 - val_loss: 0.1110\n",
      "Epoch 9/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.1098 - val_loss: 0.1070\n",
      "Epoch 10/3000\n",
      "2572/2572 [==============================] - 0s 28us/step - loss: 0.1064 - val_loss: 0.1025\n",
      "Epoch 11/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.1028 - val_loss: 0.0987\n",
      "Epoch 12/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0993 - val_loss: 0.0949\n",
      "Epoch 13/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0963 - val_loss: 0.0913\n",
      "Epoch 14/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0930 - val_loss: 0.0874\n",
      "Epoch 15/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0895 - val_loss: 0.0839\n",
      "Epoch 16/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0857 - val_loss: 0.0805\n",
      "Epoch 17/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0824 - val_loss: 0.0768\n",
      "Epoch 18/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0793 - val_loss: 0.0731\n",
      "Epoch 19/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0755 - val_loss: 0.0696\n",
      "Epoch 20/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0723 - val_loss: 0.0665\n",
      "Epoch 21/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0687 - val_loss: 0.0627\n",
      "Epoch 22/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0653 - val_loss: 0.0590\n",
      "Epoch 23/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0617 - val_loss: 0.0550\n",
      "Epoch 24/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0584 - val_loss: 0.0515\n",
      "Epoch 25/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0552 - val_loss: 0.0482\n",
      "Epoch 26/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0522 - val_loss: 0.0453\n",
      "Epoch 27/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0491 - val_loss: 0.0427\n",
      "Epoch 28/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0462 - val_loss: 0.0400\n",
      "Epoch 29/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0433 - val_loss: 0.0374\n",
      "Epoch 30/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0406 - val_loss: 0.0352\n",
      "Epoch 31/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0381 - val_loss: 0.0332\n",
      "Epoch 32/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0360 - val_loss: 0.0314\n",
      "Epoch 33/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0339 - val_loss: 0.0296\n",
      "Epoch 34/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0324 - val_loss: 0.0279\n",
      "Epoch 35/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0304 - val_loss: 0.0265\n",
      "Epoch 36/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0289 - val_loss: 0.0252\n",
      "Epoch 37/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0274 - val_loss: 0.0240\n",
      "Epoch 38/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0260 - val_loss: 0.0230\n",
      "Epoch 39/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0252 - val_loss: 0.0220\n",
      "Epoch 40/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0239 - val_loss: 0.0210\n",
      "Epoch 41/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0232 - val_loss: 0.0204\n",
      "Epoch 42/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0223 - val_loss: 0.0197\n",
      "Epoch 43/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0214 - val_loss: 0.0192\n",
      "Epoch 44/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0209 - val_loss: 0.0186\n",
      "Epoch 45/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0203 - val_loss: 0.0181\n",
      "Epoch 46/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0199 - val_loss: 0.0176\n",
      "Epoch 47/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0194 - val_loss: 0.0172\n",
      "Epoch 48/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0189 - val_loss: 0.0168\n",
      "Epoch 49/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0184 - val_loss: 0.0165\n",
      "Epoch 50/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0181 - val_loss: 0.0161\n",
      "Epoch 51/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0178 - val_loss: 0.0158\n",
      "Epoch 52/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0173 - val_loss: 0.0156\n",
      "Epoch 53/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0172 - val_loss: 0.0154\n",
      "Epoch 54/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0168 - val_loss: 0.0150\n",
      "Epoch 55/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0165 - val_loss: 0.0148\n",
      "Epoch 56/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0162 - val_loss: 0.0145\n",
      "Epoch 57/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0161 - val_loss: 0.0142\n",
      "Epoch 58/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0159 - val_loss: 0.0140\n",
      "Epoch 59/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0156 - val_loss: 0.0139\n",
      "Epoch 60/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0153 - val_loss: 0.0138\n",
      "Epoch 61/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0153 - val_loss: 0.0137\n",
      "Epoch 62/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0149 - val_loss: 0.0135\n",
      "Epoch 63/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0148 - val_loss: 0.0133\n",
      "Epoch 64/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 65/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0145 - val_loss: 0.0129\n",
      "Epoch 66/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0145 - val_loss: 0.0128\n",
      "Epoch 67/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0143 - val_loss: 0.0126\n",
      "Epoch 68/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0140 - val_loss: 0.0125\n",
      "Epoch 69/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0139 - val_loss: 0.0124\n",
      "Epoch 70/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0137 - val_loss: 0.0122\n",
      "Epoch 71/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0136 - val_loss: 0.0121\n",
      "Epoch 72/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0136 - val_loss: 0.0119\n",
      "Epoch 73/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0134 - val_loss: 0.0118\n",
      "Epoch 74/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 75/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0131 - val_loss: 0.0115\n",
      "Epoch 76/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 77/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0128 - val_loss: 0.0113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 79/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0127 - val_loss: 0.0111\n",
      "Epoch 80/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 81/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 82/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0124 - val_loss: 0.0108\n",
      "Epoch 83/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 84/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 85/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 86/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 87/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 88/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 89/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 90/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 91/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 92/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 93/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 94/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 95/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 96/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 97/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 98/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 99/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 100/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 101/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 102/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 103/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 104/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 105/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0105 - val_loss: 0.0089\n",
      "Epoch 106/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0104 - val_loss: 0.0088\n",
      "Epoch 107/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 108/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0103 - val_loss: 0.0087\n",
      "Epoch 109/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 110/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 111/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0101 - val_loss: 0.0085\n",
      "Epoch 112/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 113/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0100 - val_loss: 0.0084\n",
      "Epoch 114/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0100 - val_loss: 0.0083\n",
      "Epoch 115/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 116/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0099 - val_loss: 0.0082\n",
      "Epoch 117/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0097 - val_loss: 0.0081\n",
      "Epoch 118/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0099 - val_loss: 0.0081\n",
      "Epoch 119/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0098 - val_loss: 0.0080\n",
      "Epoch 120/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0095 - val_loss: 0.0080\n",
      "Epoch 121/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 122/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 123/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0095 - val_loss: 0.0078\n",
      "Epoch 124/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0094 - val_loss: 0.0077\n",
      "Epoch 125/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0093 - val_loss: 0.0077\n",
      "Epoch 126/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 127/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 128/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 129/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0091 - val_loss: 0.0075\n",
      "Epoch 130/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0091 - val_loss: 0.0074\n",
      "Epoch 131/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0090 - val_loss: 0.0074\n",
      "Epoch 132/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 133/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0089 - val_loss: 0.0073\n",
      "Epoch 134/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0088 - val_loss: 0.0072\n",
      "Epoch 135/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 136/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0071\n",
      "Epoch 137/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0089 - val_loss: 0.0071\n",
      "Epoch 138/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 139/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 140/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 141/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 142/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 143/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 144/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 145/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0084 - val_loss: 0.0067\n",
      "Epoch 146/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 147/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0083 - val_loss: 0.0066\n",
      "Epoch 148/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 149/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0082 - val_loss: 0.0065\n",
      "Epoch 150/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 151/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0064\n",
      "Epoch 152/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 153/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 154/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0081 - val_loss: 0.0063\n",
      "Epoch 156/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 157/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 158/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 159/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 160/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 161/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0077 - val_loss: 0.0060\n",
      "Epoch 162/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 163/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 164/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0077 - val_loss: 0.0059\n",
      "Epoch 165/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0076 - val_loss: 0.0059\n",
      "Epoch 166/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 167/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 168/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0058\n",
      "Epoch 169/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0075 - val_loss: 0.0058\n",
      "Epoch 170/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0076 - val_loss: 0.0057\n",
      "Epoch 171/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0074 - val_loss: 0.0057\n",
      "Epoch 172/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 173/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0073 - val_loss: 0.0057\n",
      "Epoch 174/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 175/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0072 - val_loss: 0.0056\n",
      "Epoch 176/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0070 - val_loss: 0.0055\n",
      "Epoch 177/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0071 - val_loss: 0.0055\n",
      "Epoch 178/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 179/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 180/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 181/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 182/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Epoch 183/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 184/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 185/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 186/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 187/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 188/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 189/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0068 - val_loss: 0.0052\n",
      "Epoch 190/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 191/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 192/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 193/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0069 - val_loss: 0.0052\n",
      "Epoch 194/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 195/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 196/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 197/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 198/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 199/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0067 - val_loss: 0.0051\n",
      "Epoch 200/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0065 - val_loss: 0.0050\n",
      "Epoch 201/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 202/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 203/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 204/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 205/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 206/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 207/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 208/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 209/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 210/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 211/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0065 - val_loss: 0.0049\n",
      "Epoch 212/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 213/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 214/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 215/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 216/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 217/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 218/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 219/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 220/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 221/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 222/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 223/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 224/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 225/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 226/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 227/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 228/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 229/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 230/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 231/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0063 - val_loss: 0.0046\n",
      "Epoch 232/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 233/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 234/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 235/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 236/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 237/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 238/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 239/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 240/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 241/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 242/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 243/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 244/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 245/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 246/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 247/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 248/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 249/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 250/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 251/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 252/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 253/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 254/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 255/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 256/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 257/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 258/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 259/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 260/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 261/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 262/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 263/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 264/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 265/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 266/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 267/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 268/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 269/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 270/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 271/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 272/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0059 - val_loss: 0.0039\n",
      "Epoch 273/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 274/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 275/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 276/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 277/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 278/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 279/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 280/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 281/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 282/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 283/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 284/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 285/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 286/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 287/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 288/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 289/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 290/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 291/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 292/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 293/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 294/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 295/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 296/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 297/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 298/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 299/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 300/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.005 - 0s 19us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 301/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 302/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 303/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 304/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 305/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 306/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 307/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 308/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 309/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 310/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 311/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 312/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 313/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 314/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 315/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 316/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 317/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 318/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 319/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 320/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 321/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 322/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 323/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 324/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 325/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 326/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 327/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 328/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 329/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 330/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 331/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 332/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 333/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 334/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 335/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 336/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 337/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 338/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 339/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 340/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 341/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 342/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 343/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 344/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 345/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 346/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 347/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 348/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 349/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 350/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 351/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 352/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 353/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 354/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 355/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 356/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 357/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 358/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 359/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 360/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 361/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 362/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 363/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 364/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 365/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 366/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 367/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 368/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 369/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 370/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 371/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 372/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 373/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 374/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 375/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 376/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 377/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 378/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 379/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 380/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 381/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 382/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 383/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 384/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 385/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 386/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 387/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 388/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 389/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 390/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 391/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 392/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 393/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 394/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 395/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 396/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 397/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 398/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 399/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 400/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 401/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 402/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 403/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 404/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 405/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 406/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 407/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 408/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 409/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 410/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 411/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 412/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 413/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 414/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 415/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 416/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 417/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 418/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 419/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 420/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 421/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 422/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 423/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 424/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 425/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 426/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 427/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 428/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 429/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 430/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 431/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 432/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 433/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 434/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 435/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 436/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 437/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 438/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 439/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 440/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 441/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 442/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 443/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 444/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 445/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 446/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 447/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 448/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 449/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 450/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 451/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 452/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 453/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 454/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 455/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 456/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 457/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 458/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 459/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 460/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 461/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 462/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 463/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 464/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 465/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 466/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 467/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 468/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 469/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 470/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 471/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 472/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 473/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 474/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 475/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 476/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 477/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 478/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 479/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 480/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 481/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 482/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 483/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 484/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 485/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 486/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 487/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 488/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 489/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 490/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 491/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 492/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 493/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 494/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 495/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 496/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 497/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 498/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 499/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 500/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 501/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 502/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 503/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 504/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 505/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 506/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 507/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 508/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 509/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 510/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 511/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 512/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 513/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 514/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 515/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 516/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 517/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 518/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 519/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 520/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 521/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 522/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 523/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 524/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 525/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 526/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 527/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 528/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 529/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 530/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0048 - val_loss: 0.0029\n",
      "Epoch 531/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 532/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 533/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 534/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 535/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 536/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 537/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 538/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 539/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 540/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 541/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 542/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 543/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 544/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 545/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 546/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 547/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 548/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 549/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 550/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 551/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 552/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 553/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 554/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 555/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 556/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 557/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 558/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 559/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 560/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 561/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 562/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 563/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 564/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 565/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 566/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 567/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 568/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 569/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 570/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 571/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 572/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 573/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 574/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 575/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 576/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 577/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 578/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 579/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 580/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 581/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 582/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 583/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 584/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 585/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 586/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 587/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 588/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 589/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 590/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 591/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 592/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 593/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 594/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 595/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 596/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 597/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 598/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 599/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 600/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 601/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 602/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 603/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 604/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 605/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 606/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 607/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 608/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 609/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 610/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 611/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 612/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 613/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 614/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 615/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 616/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 617/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 618/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 619/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 620/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 621/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 622/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 623/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 624/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 625/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 626/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 627/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 628/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 629/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 630/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 631/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 632/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 633/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 634/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 635/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 636/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 637/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 638/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 639/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 640/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 641/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 642/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 643/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 644/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 645/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 646/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 647/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 648/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 649/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 650/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 651/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.004 - 0s 18us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 652/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 653/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 654/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 655/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 656/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 657/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 658/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 659/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 660/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 661/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 662/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 663/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 664/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 665/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 666/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 667/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 668/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 669/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 670/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 671/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 672/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 673/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 674/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 675/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 676/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 677/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 678/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 679/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 680/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 681/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 682/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 683/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 684/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 685/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 686/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 687/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 688/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 689/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 690/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 691/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 692/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 693/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 694/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 695/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 696/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 697/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 698/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 699/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 700/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 701/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 702/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 703/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 704/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 705/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 706/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 707/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 708/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 709/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 710/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 711/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 712/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 713/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 714/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 715/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 716/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 717/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 718/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 719/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 720/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 721/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 722/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 723/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 724/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 725/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 726/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 727/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 728/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 729/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 730/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 731/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 732/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 733/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 734/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 735/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 736/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 737/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 738/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 739/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 740/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 741/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 742/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 743/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 744/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 745/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 746/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 747/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 748/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 749/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 750/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 751/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 752/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 753/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 754/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 755/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 756/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 757/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 758/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 759/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 760/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 761/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 762/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 763/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 764/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 765/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 766/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 767/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 768/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 769/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 770/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 771/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 772/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 773/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 774/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 775/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 776/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 777/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 778/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 779/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 780/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 781/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 782/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 783/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 784/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 785/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 786/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 787/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 788/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 789/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 790/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 791/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 792/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 793/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 794/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 795/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 796/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 797/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 798/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 799/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 800/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 801/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 802/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 803/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 804/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 805/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 806/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 807/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 808/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 809/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 810/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 811/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 812/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 813/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 814/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 815/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 816/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 817/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 818/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 819/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 820/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 821/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 822/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 823/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 824/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 825/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 826/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 827/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 828/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 829/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 830/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 831/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 832/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 833/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 834/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 835/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 836/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 837/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 838/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 839/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 840/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 841/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 842/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 843/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 844/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 845/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 846/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 847/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 848/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 849/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 850/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 851/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 852/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 853/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 854/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 855/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 856/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 857/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 858/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 859/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 860/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 861/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 862/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 863/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 864/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 865/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 866/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 867/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 868/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 869/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 870/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 871/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 872/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 873/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 874/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 875/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 876/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 877/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 878/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 879/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 880/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 881/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 882/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 883/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 884/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 885/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 886/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 887/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 888/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 889/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 890/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 891/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 892/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 893/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 894/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 895/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 896/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.005 - 0s 19us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 897/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 898/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 899/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 900/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 901/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 902/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 903/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 904/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 905/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 906/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 907/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 908/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 909/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 910/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 911/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 912/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 913/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 914/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 915/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 916/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 917/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 918/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 919/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 920/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 921/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 922/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 923/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 924/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 925/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 926/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 927/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 928/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 929/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 930/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 931/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 932/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 933/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 934/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 935/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 936/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 937/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 938/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 939/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 940/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 941/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 942/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 943/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 944/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 945/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 946/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 947/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 948/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 949/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 950/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 951/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 952/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 953/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 954/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 955/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 956/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 957/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 958/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 959/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 960/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 961/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 962/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 963/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 964/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 965/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 966/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 967/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 968/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 969/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 970/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 971/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 972/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 973/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 974/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 975/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 976/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 977/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 978/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 979/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 980/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 981/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 982/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 983/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 984/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 985/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 986/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 987/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 988/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 989/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 990/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 991/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 992/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 993/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 994/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 995/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 996/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 997/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 998/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 999/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1000/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1001/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 1002/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1003/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1004/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1005/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1006/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1007/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1008/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1009/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1010/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1011/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1012/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1013/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1014/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1015/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1016/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1017/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1018/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1019/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 1020/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1021/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1022/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1023/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1024/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 1025/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1026/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1027/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1028/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1029/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1030/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1031/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1032/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1033/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1034/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1035/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1036/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1037/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1038/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1039/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1040/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1041/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1042/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1043/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1044/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1045/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1046/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1047/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1048/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1049/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1050/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 1051/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 1052/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 1053/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 1054/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 1055/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 1056/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 1057/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 1058/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 1059/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1060/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1061/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1062/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1063/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1064/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1065/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1066/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1067/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1068/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1069/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1070/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1071/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1072/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1073/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1074/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1075/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1076/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1077/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1078/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1079/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1080/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1081/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1082/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1083/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1084/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1085/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1086/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1087/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1088/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1089/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1090/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1091/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1092/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1093/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1094/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1095/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1096/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1097/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1098/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1099/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1100/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1101/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1102/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1103/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1104/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1105/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1106/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1107/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1108/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 1109/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1110/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1111/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1112/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1113/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1114/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1115/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1116/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1117/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1118/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1119/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1120/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1121/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1122/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1123/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1124/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1125/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1126/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1127/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1128/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1129/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 1130/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1131/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1132/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1133/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1134/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1135/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1136/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1137/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1138/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1139/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1140/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1141/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1142/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1143/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1144/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1145/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1146/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1147/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1148/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1149/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1150/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1151/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 1152/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1153/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1154/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1155/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1156/3000\n",
      "2572/2572 [==============================] - 0s 12us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1157/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1158/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 1159/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1160/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1161/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1162/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1163/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1164/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 1165/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1166/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1167/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1168/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 1169/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 1170/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1171/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1172/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1173/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1174/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1175/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1176/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1177/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1178/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1179/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1180/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1181/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1182/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1183/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 1184/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1185/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1186/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1187/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1188/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1189/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1190/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1191/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1192/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1193/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1194/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1195/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1196/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1197/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1198/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1199/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1200/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 1201/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1202/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1203/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1204/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1205/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1206/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1207/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1208/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1209/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1210/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1211/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1212/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1213/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1214/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1215/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1216/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1217/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1218/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1219/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1220/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1221/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1222/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1223/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1224/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1225/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1226/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1227/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1228/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1229/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1230/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1231/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1232/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1233/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1234/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1235/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1236/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1237/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 1238/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1239/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1240/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1241/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1242/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1243/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1244/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1245/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1246/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1247/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1248/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1249/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1250/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1251/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1252/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1253/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1254/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1255/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1256/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1257/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1258/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1259/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1260/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1261/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1262/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1263/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1264/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1265/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1266/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1267/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1268/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1269/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1270/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1271/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1272/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1273/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1274/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1275/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1276/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1277/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1278/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1279/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1280/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1281/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1282/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1283/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1284/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1285/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1286/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1287/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1288/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1289/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1290/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1291/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1292/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1293/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1294/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 1295/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1296/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1297/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1298/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1299/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1300/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1301/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1302/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1303/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 1304/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1305/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1306/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1307/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1308/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1309/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1310/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1311/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1312/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1313/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1314/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1315/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1316/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1317/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1318/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1319/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1320/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1321/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1322/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1323/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1324/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 1325/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1326/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1327/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1328/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1329/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1330/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1331/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1332/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1333/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1334/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1335/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1336/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1337/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1338/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1339/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1340/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1341/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1342/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1343/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1344/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1345/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 1346/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1347/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1348/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1349/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1350/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1351/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1352/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1353/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1354/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1355/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1356/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1357/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1358/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1359/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1360/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1361/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1362/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1363/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1364/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1365/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1366/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1367/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1368/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1369/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1370/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1371/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1372/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1373/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1374/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1375/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1376/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1377/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1378/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1379/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1380/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1381/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1382/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1383/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1384/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1385/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1386/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1387/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1388/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1389/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1390/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1391/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1392/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1393/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1394/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1395/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1396/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1397/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1398/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1399/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1400/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1401/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1402/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1403/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1404/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1405/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1406/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1407/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1408/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1409/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1410/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1411/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1412/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1413/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1414/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1415/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1416/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1417/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1418/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1419/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1420/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1421/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1422/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1423/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1424/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1425/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1426/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 1427/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1428/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1429/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1430/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1431/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1432/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1433/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1434/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1435/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1436/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1437/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1438/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1439/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1440/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1441/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1442/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1443/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1444/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1445/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1446/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1447/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1448/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1449/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1450/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1451/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1452/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1453/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1454/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1455/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1456/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1457/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1458/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1459/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1460/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1461/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 1462/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1463/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1464/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1465/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1466/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1467/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1468/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1469/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1470/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1471/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1472/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1473/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1474/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1475/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1476/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1477/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1478/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1479/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1480/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1481/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1482/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1483/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1484/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1485/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1486/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1487/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1488/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1489/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1490/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1491/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1492/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1493/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1494/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1495/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 1496/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1497/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1498/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1499/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1500/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1501/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1502/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1503/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1504/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1505/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1506/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1507/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1508/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1509/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1510/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1511/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1512/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1513/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1514/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1515/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1516/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1517/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1518/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1519/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1520/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1521/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1522/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1523/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1524/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1525/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1526/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1527/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1528/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1529/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1530/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1531/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1532/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1533/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1534/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1535/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1536/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1537/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1538/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1539/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1540/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1541/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1542/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1543/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 1544/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1545/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1546/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1547/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1548/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1549/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 1550/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1551/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1552/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1553/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1554/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1555/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1556/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1557/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1558/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1559/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1560/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1561/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1562/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1563/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1564/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1565/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1566/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1567/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1568/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1569/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1570/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1571/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1572/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1573/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1574/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1575/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1576/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1577/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1578/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1579/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1580/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1581/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1582/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1583/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1584/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1585/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1586/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1587/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1588/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1589/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1590/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1591/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1592/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1593/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1594/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1595/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1596/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1597/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1598/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1599/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1600/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1601/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1602/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1603/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1604/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1605/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1606/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1607/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1608/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1609/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1610/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1611/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1612/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1613/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1614/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1615/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1616/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1617/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1618/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 1619/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1620/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1621/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1622/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1623/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1624/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1625/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1626/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1627/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1628/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1629/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1630/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1631/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1632/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1633/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1634/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1635/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1636/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1637/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1638/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1639/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1640/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1641/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1642/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1643/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1644/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1645/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1646/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1647/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1648/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1649/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1650/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1651/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1652/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1653/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1654/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1655/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1656/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1657/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1658/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1659/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1660/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1661/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1662/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1663/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1664/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1665/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1666/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1667/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1668/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1669/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1670/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1671/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1672/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1673/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1674/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1675/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1676/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1677/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1678/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1679/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1680/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1681/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1682/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1683/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1684/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1685/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1686/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1687/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 1688/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1689/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1690/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1691/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1692/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1693/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1694/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1695/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1696/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1697/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1698/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1699/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1700/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1701/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1702/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1703/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1704/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1705/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1706/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1707/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1708/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1709/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1710/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1711/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1712/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1713/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1714/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1715/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1716/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1717/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1718/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1719/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1720/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1721/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1722/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 1723/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1724/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1725/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1726/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1727/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1728/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1729/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1730/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1731/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1732/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1733/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1734/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1735/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1736/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1737/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1738/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1739/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1740/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1741/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1742/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1743/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1744/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1745/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1746/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1747/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1748/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1749/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1750/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1751/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1752/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1753/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1754/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1755/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1756/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1757/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1758/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1759/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1760/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1761/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1762/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1763/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1764/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1765/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1766/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1767/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1768/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1769/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1770/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1771/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1772/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1773/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1774/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1775/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1776/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1777/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1778/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1779/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1780/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1781/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1782/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1783/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1784/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1785/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1786/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1787/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1788/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1789/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1790/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1791/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1792/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1793/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1794/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1795/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1796/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1797/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1798/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1799/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1800/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1801/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1802/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1803/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1804/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1805/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1806/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1807/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1808/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1809/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1810/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1811/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1812/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1813/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1814/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1815/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1816/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1817/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1818/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1819/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1820/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1821/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1822/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1823/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1824/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1825/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1826/3000\n",
      "2572/2572 [==============================] - 0s 11us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1827/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1828/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1829/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1830/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1831/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1832/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1833/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1834/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1835/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1836/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1837/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1838/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1839/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1840/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1841/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1842/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1843/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1844/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1845/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1846/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1847/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1848/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1849/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1850/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1851/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1852/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1853/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1854/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1855/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1856/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1857/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1858/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1859/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1860/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1861/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1862/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1863/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1864/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1865/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1866/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1867/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1868/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1869/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1870/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1871/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1872/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1873/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1874/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1875/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1876/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1877/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1878/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1879/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1880/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1881/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1882/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1883/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 1884/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 1885/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 1886/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 1887/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1888/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1889/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1890/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1891/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1892/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1893/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1894/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1895/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 1896/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 1897/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1898/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1899/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1900/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1901/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1902/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1903/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1904/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1905/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1906/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1907/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1908/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1909/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1910/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1911/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1912/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1913/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1914/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1915/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1916/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1917/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1918/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1919/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1920/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1921/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1922/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 1923/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 1924/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1925/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1926/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1927/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1928/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1929/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1930/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1931/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1932/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1933/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1934/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1935/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1936/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1937/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1938/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1939/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1940/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1941/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1942/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 1943/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1944/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1945/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1946/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1947/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1948/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1949/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1950/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1951/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1952/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1953/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1954/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1955/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1956/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1957/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1958/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1959/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1960/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 1961/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1962/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1963/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1964/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1965/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1966/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1967/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1968/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1969/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1970/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1971/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1972/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1973/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1974/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 1975/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1976/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1977/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1978/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1979/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1980/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1981/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1982/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1983/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1984/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1985/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1986/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1987/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1988/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 1989/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1990/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1991/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1992/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 1993/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1994/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1995/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1996/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 1997/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 1998/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 1999/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2000/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2001/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2002/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2003/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2004/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2005/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2006/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2007/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2008/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2009/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2010/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2011/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2012/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2013/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2014/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2015/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2016/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2017/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2018/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2019/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2020/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2021/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2022/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2023/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2024/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2025/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2026/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2027/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2028/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2029/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2030/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2031/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2032/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2033/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2034/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2035/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2036/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2037/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2038/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2039/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2040/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2041/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2042/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2043/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2044/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2045/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2046/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2047/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2048/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2049/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2050/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 2051/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2052/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2053/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2054/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2055/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2056/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2057/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2058/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2059/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2060/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2061/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2062/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2063/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 2064/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2065/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2066/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2067/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2068/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2069/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2070/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2071/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2072/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2073/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2074/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2075/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2076/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2077/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2078/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2079/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2080/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2081/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2082/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2083/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2084/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2085/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2086/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2087/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2088/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2089/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2090/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2091/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2092/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2093/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2094/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2095/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2096/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2097/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2098/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2099/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2100/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2101/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2102/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2103/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2104/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2105/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2106/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2107/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2108/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2109/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2110/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 2111/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2112/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2113/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2114/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2115/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2116/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2117/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2118/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2119/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2120/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2121/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2122/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2123/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2124/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2125/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2126/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2127/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2128/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2129/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2130/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2131/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2132/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2133/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2134/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2135/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2136/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2137/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2138/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2139/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2140/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2141/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2142/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2143/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2144/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2145/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2146/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2147/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2148/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2149/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2150/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2151/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2152/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2153/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2154/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2155/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2156/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2157/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2158/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2159/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2160/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2161/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2162/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2163/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2164/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2165/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2166/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2167/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2168/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2169/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2170/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2171/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2172/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2173/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2174/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2175/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2176/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2177/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2178/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2179/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2180/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2181/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2182/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2183/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2184/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2185/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2186/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2187/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2188/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2189/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2190/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2191/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2192/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2193/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2194/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2195/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2196/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2197/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2198/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2199/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2200/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2201/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2202/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2203/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2204/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2205/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 2206/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2207/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2208/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2209/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2210/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 2211/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2212/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2213/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2214/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2215/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2216/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2217/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2218/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2219/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2220/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2221/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2222/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2223/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2224/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2225/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2226/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 2227/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2228/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2229/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2230/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2231/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2232/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2233/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2234/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2235/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2236/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2237/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2238/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2239/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2240/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2241/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2242/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2243/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2244/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2245/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2246/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2247/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2248/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2249/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2250/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2251/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2252/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2253/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2254/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2255/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2256/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2257/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2258/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2259/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2260/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2261/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2262/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2263/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2264/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2265/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 2266/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2267/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2268/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2269/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2270/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2271/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2272/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2273/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2274/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2275/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2276/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2277/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2278/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2279/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2280/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2281/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2282/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2283/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2284/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2285/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2286/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2287/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2288/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2289/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2290/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2291/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2292/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2293/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2294/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2295/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2296/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2297/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2298/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2299/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2300/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2301/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2302/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2303/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2304/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2305/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2306/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2307/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2308/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2309/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2310/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2311/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2312/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2313/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2314/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2315/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2316/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2317/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2318/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2319/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2320/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2321/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2322/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2323/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2324/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2325/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2326/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2327/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2328/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2329/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2330/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2331/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2332/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2333/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2334/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2335/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2336/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2337/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2338/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2339/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2340/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2341/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2342/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2343/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2344/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2345/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2346/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2347/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2348/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2349/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2350/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2351/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2352/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2353/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2354/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2355/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2356/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2357/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2358/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2359/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2360/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2361/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2362/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2363/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2364/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2365/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2366/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2367/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2368/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2369/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2370/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2371/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2372/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2373/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2374/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2375/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2376/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2377/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2378/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2379/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2380/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2381/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2382/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2383/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2384/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2385/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2386/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2387/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2388/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2389/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2390/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2391/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2392/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2393/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2394/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2395/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2396/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2397/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2398/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2399/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2400/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2401/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2402/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2403/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2404/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2405/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2406/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2407/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2408/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2409/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2410/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2411/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2412/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2413/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2414/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2415/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2416/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2417/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2418/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2419/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2420/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2421/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2422/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2423/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2424/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2425/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2426/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2427/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2428/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2429/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2430/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2431/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2432/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2433/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2434/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2435/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2436/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2437/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2438/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2439/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2440/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2441/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2442/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2443/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2444/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2445/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2446/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2447/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2448/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2449/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2450/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2451/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2452/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2453/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2454/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2455/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2456/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2457/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2458/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2459/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2460/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2461/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2462/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2463/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2464/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2465/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2466/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2467/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2468/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2469/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2470/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2471/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2472/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2473/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2474/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2475/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2476/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2477/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2478/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2479/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2480/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2481/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2482/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2483/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2484/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2485/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2486/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2487/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2488/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2489/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 2490/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2491/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2492/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2493/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2494/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2495/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2496/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2497/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2498/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2499/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2500/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2501/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2502/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2503/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2504/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2505/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2506/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2507/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2508/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2509/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2510/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2511/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2512/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2513/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2514/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2515/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2516/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2517/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2518/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2519/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2520/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2521/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2522/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2523/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2524/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2525/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2526/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2527/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2528/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2529/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2530/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2531/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2532/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2533/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2534/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2535/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2536/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2537/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2538/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2539/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2540/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2541/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2542/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2543/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2544/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2545/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2546/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2547/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2548/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2549/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2550/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2551/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2552/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2553/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2554/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2555/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2556/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2557/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2558/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2559/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 2560/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2561/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2562/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2563/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2564/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2565/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2566/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2567/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2568/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2569/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2570/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2571/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2572/3000\n",
      "2572/2572 [==============================] - 0s 13us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2573/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2574/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2575/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2576/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2577/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2578/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2579/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2580/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2581/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2582/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2583/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2584/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2585/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2586/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2587/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2588/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2589/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2590/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2591/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2592/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2593/3000\n",
      "2572/2572 [==============================] - 0s 36us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2594/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2595/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2596/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2597/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2598/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2599/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2600/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2601/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2602/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2603/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2604/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2605/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2606/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2607/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2608/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2609/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2610/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2611/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2612/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2613/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2614/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2615/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2616/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2617/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2618/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2619/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2620/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2621/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2622/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2623/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2624/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2625/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2626/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2627/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2628/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2629/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2630/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2631/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2632/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2633/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2634/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2635/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2636/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2637/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2638/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2639/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2640/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2641/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2642/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2643/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2644/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2645/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2646/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2647/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2648/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2649/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2650/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2651/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2652/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2653/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2654/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2655/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2656/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2657/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2658/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2659/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2660/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2661/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2662/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2663/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2664/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2665/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2666/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2667/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2668/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2669/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2670/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2671/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2672/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2673/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2674/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2675/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2676/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2677/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2678/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2679/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2680/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2681/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2682/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2683/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2684/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2685/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2686/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2687/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 2688/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2689/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2690/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2691/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2692/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2693/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2694/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2695/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2696/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2697/3000\n",
      "2572/2572 [==============================] - ETA: 0s - loss: 0.003 - 0s 14us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2698/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2699/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2700/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2701/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2702/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2703/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2704/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2705/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2706/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2707/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2708/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2709/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2710/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2711/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2712/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2713/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2714/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2715/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2716/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2717/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2718/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2719/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2720/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2721/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2722/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2723/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2724/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2725/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2726/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2727/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2728/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2729/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2730/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2731/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2732/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2733/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2734/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2735/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0037 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2736/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2737/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2738/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2739/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2740/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 2741/3000\n",
      "2572/2572 [==============================] - 0s 29us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2742/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2743/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2744/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2745/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2746/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2747/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2748/3000\n",
      "2572/2572 [==============================] - 0s 35us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2749/3000\n",
      "2572/2572 [==============================] - 0s 33us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2750/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2751/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2752/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2753/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 2754/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2755/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2756/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2757/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2758/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2759/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2760/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2761/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2762/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2763/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2764/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2765/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2766/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2767/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2768/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2769/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2770/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2771/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2772/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2773/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2774/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2775/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2776/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2777/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2778/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2779/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2780/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 2781/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2782/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2783/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2784/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2785/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2786/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2787/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2788/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2789/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2790/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2791/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2792/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2793/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2794/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2795/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2796/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2797/3000\n",
      "2572/2572 [==============================] - 0s 30us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2798/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2799/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2800/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2801/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2802/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2803/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2804/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2805/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2806/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2807/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2808/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2809/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2810/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2811/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2812/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2813/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2814/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2815/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2816/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2817/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2818/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2819/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2820/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2821/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2822/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2823/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2824/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2825/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2826/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2827/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2828/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2829/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2830/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2831/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2832/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2833/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2834/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2835/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2836/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2837/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2838/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2839/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2840/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2841/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2842/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2843/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2844/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2845/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2846/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2847/3000\n",
      "2572/2572 [==============================] - 0s 31us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2848/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2849/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2850/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2851/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2852/3000\n",
      "2572/2572 [==============================] - 0s 32us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2853/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2854/3000\n",
      "2572/2572 [==============================] - 0s 27us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2855/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2856/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2857/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2858/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2859/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2860/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2861/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2862/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2863/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2864/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2865/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2866/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2867/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2868/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2869/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2870/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 2871/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2872/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 2873/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2874/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2875/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2876/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2877/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2878/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2879/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2880/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2881/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2882/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2883/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2884/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2885/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2886/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2887/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2888/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2889/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2890/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2891/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2892/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2893/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2894/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2895/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2896/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2897/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2898/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2899/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2900/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2901/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2902/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2903/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2904/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2905/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2906/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2907/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2908/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2909/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2910/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2911/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2912/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2913/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2914/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2915/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2916/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2917/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2918/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2919/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2920/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2921/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2922/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2923/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2924/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2925/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2926/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2927/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2928/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2929/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2930/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 2931/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2932/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2933/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2934/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2935/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2936/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2937/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2938/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2939/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 2940/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2941/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2942/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2943/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2944/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2945/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2946/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2947/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2948/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2949/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2950/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2951/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2952/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2953/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2954/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2955/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2956/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2957/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2958/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2959/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2960/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2961/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2962/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2963/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2964/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2965/3000\n",
      "2572/2572 [==============================] - 0s 25us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2966/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2967/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2968/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2969/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2970/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2971/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2972/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2973/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2974/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2975/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2976/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2977/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2978/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2979/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2980/3000\n",
      "2572/2572 [==============================] - 0s 24us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2981/3000\n",
      "2572/2572 [==============================] - 0s 14us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2982/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2983/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2984/3000\n",
      "2572/2572 [==============================] - 0s 20us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2985/3000\n",
      "2572/2572 [==============================] - 0s 21us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2986/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2987/3000\n",
      "2572/2572 [==============================] - 0s 15us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2988/3000\n",
      "2572/2572 [==============================] - 0s 26us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2989/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 2990/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 2991/3000\n",
      "2572/2572 [==============================] - 0s 18us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 2992/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2993/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2994/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2995/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 2996/3000\n",
      "2572/2572 [==============================] - 0s 22us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2997/3000\n",
      "2572/2572 [==============================] - 0s 16us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 2998/3000\n",
      "2572/2572 [==============================] - 0s 17us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 2999/3000\n",
      "2572/2572 [==============================] - 0s 19us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 3000/3000\n",
      "2572/2572 [==============================] - 0s 23us/step - loss: 0.0034 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "# Treina a rede\n",
    "# EarlyStopping para o treinamento se ver que não tá mais melhorando\n",
    "# History é para plotar gráficos de erro\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)\n",
    "history = autoencoder.fit(X_trainAtMes, X_trainAtMes,\n",
    "                epochs=3000,\n",
    "                batch_size=batch,\n",
    "                shuffle=True,\n",
    "                validation_data=(X_testAtMes, X_testAtMes))#,\n",
    "                #callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'],color='r',label=\"loss\")\n",
    "plt.plot(history.history['val_loss'],label=\"val_loss\")\n",
    "plt.xlabel(u\"Épocas\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.rc('font', size=12)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz a previsão para a base de teste\n",
    "testeAtMes = autoencoder.predict(X_testAtMes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103/1103 [==============================] - 0s 12us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0017540591613981443"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula o erro (MSE) para o teste\n",
    "autoencoder.evaluate(x=X_testAtMes, y=X_testAtMes, batch_size=attest_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2572/2572 [==============================] - 0s 6us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0017638078988372228"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Calcula o erro (MSE) para o treino\n",
    "autoencoder.evaluate(x=X_trainAtMes, y=X_trainAtMes, batch_size=batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8343913686629032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula o score (R^2 ajustado) para o teste\n",
    "r2 = r2_score(X_testAtMes,testeAtMes)\n",
    "1 - (1-r2) * (len(testeAtMes) -1) / (len(testeAtMes) - encoding_dim1 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8332236933914259"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula o score (R^2 ajustado) para o treino\n",
    "trainAtMes = autoencoder.predict(X_trainAtMes)\n",
    "r2 = r2_score(X_trainAtMes,trainAtMes)\n",
    "1 - (1-r2) * (len(trainAtMes) -1) / (len(trainAtMes) - encoding_dim1 -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coolingdegreedays': 0.9263064582791256,\n",
       " 'date': 0.8109144862835137,\n",
       " 'fog': 0.99916242052217,\n",
       " 'gdegreedays': 0.9514503626071784,\n",
       " 'hail': 0.9848275265828609,\n",
       " 'heatingdegreedays': 0.9193211481421264,\n",
       " 'humidity': 0.8938105502310492,\n",
       " 'lat': 0.9188566814918294,\n",
       " 'lng': 0.5150983629065636,\n",
       " 'maxdewptm': 0.9075173135633335,\n",
       " 'maxhumidity': 0.8453102198604088,\n",
       " 'maxpressurem': 0.8413754580067568,\n",
       " 'maxtempm': 0.8585874157549639,\n",
       " 'maxwspdm': 0.42959077938115486,\n",
       " 'meandewptm': 0.9565933007793124,\n",
       " 'meanpressurem': 0.8998949726172687,\n",
       " 'meantempm': 0.9596976582151732,\n",
       " 'meanwdird': 0.9603473459198595,\n",
       " 'meanwindspdm': 0.5522392573048716,\n",
       " 'mindewptm': 0.898313587532328,\n",
       " 'minhumidity': 0.8994333696747624,\n",
       " 'minpressurem': 0.8495658150485013,\n",
       " 'mintempm': 0.8838589741256887,\n",
       " 'minwspdm': 0.6450656424355381,\n",
       " 'precipm': 0.06015805084069248,\n",
       " 'rain': 0.9993771795211083,\n",
       " 'snow': 0.997664691673045,\n",
       " 'thunder': 0.9986192932601069}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcula o score para todas as features separadamente\n",
    "testeAtMes = pd.DataFrame(testeAtMes, columns=df_atmes.columns)\n",
    "score = {}\n",
    "for c in testeAtMes.columns:\n",
    "    score[c] = r2_score(X_testAtMes[c],testeAtMes[c])\n",
    "    # R² ajustado com k igual ao número de neurônios na camada decodificada\n",
    "    score[c] = 1 - (1-score[c]) * (len(testeAtMes) -1) / (len(testeAtMes) - encoding_dim1 -1)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('precipm', 0.06015805084069248)\n",
      "('maxwspdm', 0.42959077938115486)\n",
      "('lng', 0.5150983629065636)\n",
      "('meanwindspdm', 0.5522392573048716)\n",
      "('minwspdm', 0.6450656424355381)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bads = []\n",
    "values = []\n",
    "rank = []\n",
    "rankv = []\n",
    "# Ranqueia\n",
    "for b in sorted(score, key = score.get):\n",
    "    rank.append(b)\n",
    "    rankv.append(score[b])\n",
    "    \n",
    "# Separa as ruins\n",
    "for a in sorted(score, key = score.get):\n",
    "    if(score[a] < 0.8):\n",
    "        print(a,score[a])\n",
    "        bads.append(a)\n",
    "        values.append(score[a])\n",
    "        rank.remove(a)\n",
    "        rankv.remove(score[a])\n",
    "\n",
    "# Plota gráfico de barras horizontais\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.rc('font', size=15)\n",
    "plt.rc('axes', titlesize=22)\n",
    "plt.title(u\"Ranking de Reconstrução\")\n",
    "plt.legend()\n",
    "plt.xlabel(u\"Adjusted R²\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.barh(bads,values,color='r')\n",
    "plt.barh(rank,rankv,color='green')\n",
    "plt.savefig('ranking_reconstrucao.svg', format=\"svg\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in bads:\n",
    "    df_atmes.drop(b,axis=1,inplace=True)\n",
    "df_atmes.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plota matriz de dispersão\n",
    "# Cada célula é um scatter entra duas features, sendo a diagonal principal um histograma\n",
    "scatter_matrix(df_atmes)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Plota matriz de correlação\n",
    "# Quanto mais correlacionadas duas features, mais forte é a cor de interseção entre elas\n",
    "# crescem justas na mesma direção = bem correlacionadas\n",
    "# crescem em direções opostas = mal correlacionadas\n",
    "correlations = df_atmes.corr()\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(correlations, vmin=-1, vmax=1)\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,cinput_dim,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "ax.set_xticklabels(df_atmes.columns)\n",
    "ax.set_yticklabels(df_atmes.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com somente uma camada escondida e Dropout\n",
    "encoding_dim1 = 12\n",
    "entrada = Input(shape=(input_dim,))\n",
    "dp1 = Dropout(0.3)(entrada)\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(dp1)\n",
    "dp2 = Dropout(0.3)(encoded1)\n",
    "decoded2 = Dense(input_dim,activation=\"sigmoid\")(dp2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com 3 camadas escondidas e DropOut\n",
    "encoding_dim1 = 12\n",
    "encoding_dim2 = 6\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "dpen1 = Dropout(0.1)(encoded1)\n",
    "encoded2 = Dense(encoding_dim2,activation=\"relu\")(dpen1)\n",
    "dpen2 = Dropout(0.1)(encoded2)\n",
    "decoded1 = Dense(encoding_dim1,activation=\"relu\")(dpen2) #sigmoid antes\n",
    "decoded2 = Dense(input_dim,activation=\"sigmoid\")(decoded1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Rede com somente uma camada escondida\n",
    "encoding_dim1 = 12\n",
    "entrada = Input(shape=(input_dim,))\n",
    "encoded1 = Dense(encoding_dim1,activation=\"relu\")(entrada)\n",
    "decoded2 = Dense(input_dim,activation=\"linear\")(encoded1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Codificador e Decodificador\n",
    "codificador = Model(entrada,encoded)\n",
    "cod = Input(shape=(encoding_dim,))\n",
    "dec = autoencoder.layers[-1]\n",
    "decodificador = Model(cod,dec(cod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "batch_size = len(df_atmes)\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x = Input(batch_shape=(attrain_dim, input_dim))\n",
    "h = Dense(encoding_dim1, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim)(h)\n",
    "z_log_sigma = Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(attrain_dim, latent_dim),\n",
    "                              mean=0.)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
    "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "decoder_h = Dense(encoding_dim1, activation='relu')\n",
    "decoder_mean = Dense(input_dim, activation='sigmoid')\n",
    "h_decoded = decoder_h(z)\n",
    "x_decoded_mean = decoder_mean(h_decoded)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# end-to-end autoencoder\n",
    "vae = Model(x, x_decoded_mean)\n",
    "\n",
    "# encoder, from inputs to latent space\n",
    "encoder = Model(x, z_mean)\n",
    "\n",
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "_h_decoded = decoder_h(decoder_input)\n",
    "_x_decoded_mean = decoder_mean(_h_decoded)\n",
    "generator = Model(decoder_input, _x_decoded_mean)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def vae_loss(x, x_decoded_mean):\n",
    "    xent_loss = binary_crossentropy(x, x_decoded_mean)\n",
    "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
    "    return xent_loss + kl_loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "vae.compile(optimizer='rmsprop', loss=vae_loss)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "attrain_dim"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "vae.fit(X_trainAtMes, X_trainAtMes,\n",
    "        shuffle=True,\n",
    "        epochs=50,\n",
    "        batch_size=2577,\n",
    "        validation_data=(X_testAtMes, X_testAtMes))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "x_test_encoded = encoder.predict(x_test, batch_size=batch_size)\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(x_test_encoded[:, 0], x_test_encoded[:, 1], c=y_test)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
